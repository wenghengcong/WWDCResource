1
00:00:16,750 --> 00:00:23,023 line:0
（图像和图形最佳实践
演讲219）


2
00:00:24,925 --> 00:00:26,059 line:-1
大家好


3
00:00:26,126 --> 00:00:28,595 line:-1
欢迎来到图像和图形最佳实践


4
00:00:28,896 --> 00:00:31,064 line:-1
我叫Kyle 我在UIKit工作


5
00:00:31,565 --> 00:00:33,800 line:-1
今天我将与你分享关于如何


6
00:00:33,867 --> 00:00:35,802 line:-1
在你的app中高效使用图形内容的


7
00:00:35,869 --> 00:00:38,438 line:-1
一些技术以及策略


8
00:00:39,773 --> 00:00:41,642 line:-1
我们将浏览整个框架栈


9
00:00:41,708 --> 00:00:45,212 line:-2
首先 我们将从UIImage
和UIImageView开始


10
00:00:45,279 --> 00:00:47,915 line:-1
这些都是UIKit的高级工具


11
00:00:47,981 --> 00:00:50,184 line:-1
用于在你的app中使用图形内容


12
00:00:51,084 --> 00:00:55,022 line:-2
接着我们将重点关注
如何在你的app中


13
00:00:55,088 --> 00:00:57,191 line:-2
使用UIKit最优地
进行自定义绘图


14
00:00:57,991 --> 00:00:59,993 line:-1
最后 我们将简要地介绍一下


15
00:01:00,060 --> 00:01:04,031 line:-1
如何将先进的CPU和GPU技术


16
00:01:04,096 --> 00:01:05,364 line:-1
集成到你的app中


17
00:01:06,667 --> 00:01:09,036 line:-1
在整个演讲中 我们将主要关注


18
00:01:09,102 --> 00:01:15,509 line:-2
如何使用设备上的两个稀缺资源
内存和CPU


19
00:01:16,109 --> 00:01:19,580 line:-2
我们倾向于将这些东西视为
具有各自独立的数量


20
00:01:19,646 --> 00:01:22,049 line:-2
它们在调试导航栏中
有各自独立的跟踪指标


21
00:01:22,115 --> 00:01:25,485 line:-2
它们在工具app中
拥有各自独立的工具


22
00:01:25,853 --> 00:01:27,888 line:-2
但实际上
它们错综复杂地联系在一起


23
00:01:29,356 --> 00:01:34,328 line:-2
很明显
当你的app使用更多的CPU时


24
00:01:34,895 --> 00:01:37,464 line:-2
将会对电池寿命和
app的响应能力


25
00:01:37,831 --> 00:01:39,700 line:-1
具有负面的影响


26
00:01:40,601 --> 00:01:44,304 line:-2
但可能不那么明显的是
随着你的app


27
00:01:44,671 --> 00:01:48,208 line:-1
和系统上的其他app消耗更多内存


28
00:01:48,275 --> 00:01:51,245 line:-1
也会导致更高的CPU使用率


29
00:01:51,612 --> 00:01:55,983 line:-2
这对电池寿命和性能
有进一步的不利影响


30
00:01:56,049 --> 00:01:59,319 line:-2
因此 我们将重点关注
如何改进对这些资源的使用


31
00:02:01,688 --> 00:02:03,757 line:-1
讨论这个问题还能有什么


32
00:02:03,824 --> 00:02:06,793 line:-2
比一个需要处理大量
图像内容的app


33
00:02:06,860 --> 00:02:09,329 line:-2
更好的背景呢
比如Photos app


34
00:02:10,163 --> 00:02:11,865 line:-1
你看 我们正在这里编辑一张照片


35
00:02:12,332 --> 00:02:15,269 line:-2
正如我之前提到的
UIImages、UIKits


36
00:02:15,335 --> 00:02:18,605 line:-1
都是用于处理图像数据的高级类


37
00:02:18,672 --> 00:02:22,643 line:-2
我们用一个UIImage
代表这个富内容


38
00:02:23,577 --> 00:02:27,447 line:-2
我们倾向于将app中的图形内容
分为两类


39
00:02:27,514 --> 00:02:30,651 line:-2
富内容 如这张照片
以及图标


40
00:02:31,351 --> 00:02:34,087 line:-2
UIImage也是
UIKit中的数据类型


41
00:02:34,154 --> 00:02:37,991 line:-2
用来表示某些事物
例如显示在此按钮中的图标


42
00:02:39,893 --> 00:02:41,762 line:-1
如前所述


43
00:02:42,362 --> 00:02:45,599 line:-2
UIImageView
是UIKit提供


44
00:02:45,666 --> 00:02:47,134 line:-1
用于显示UIImage的类


45
00:02:50,337 --> 00:02:52,139 line:-1
若采用经典的MVC模型进行类比


46
00:02:52,506 --> 00:02:55,409 line:-1
UIImage可以被看作模型对象


47
00:02:55,475 --> 00:02:58,679 line:-2
当然 正如名称所暗示
UIImageView是一个视图


48
00:02:59,513 --> 00:03:02,449 line:-1
而这些对象作为模型和视图


49
00:03:02,516 --> 00:03:04,251 line:-1
肩负着其在经典模型中的责任


50
00:03:04,918 --> 00:03:07,855 line:-1
UIImage负责加载图片内容


51
00:03:08,355 --> 00:03:11,825 line:-2
UIImageView
负责显示和渲染它


52
00:03:13,460 --> 00:03:15,529 line:-1
现在 我们可以将其理解为


53
00:03:15,596 --> 00:03:17,097 line:-1
我们建立的简单关系


54
00:03:17,164 --> 00:03:18,532 line:-1
这是一种单向关系


55
00:03:19,166 --> 00:03:22,035 line:-1
但实际情况却比这复杂一点


56
00:03:23,136 --> 00:03:26,006 line:-1
除了渲染是一个连续的过程


57
00:03:26,073 --> 00:03:27,508 line:-1
而不是一次性事件之外


58
00:03:28,242 --> 00:03:32,412 line:-1
这里的理解其实有一个隐藏的阶段


59
00:03:32,479 --> 00:03:34,581 line:-1
对衡量app的性能至关重要


60
00:03:35,115 --> 00:03:36,750 line:-1
这个阶段被称为解码


61
00:03:37,818 --> 00:03:39,686 line:-1
但为了讨论解码


62
00:03:39,753 --> 00:03:42,189 line:-2
我首先需要讨论
一个叫做“缓冲区”的概念


63
00:03:43,590 --> 00:03:45,859 line:-1
缓冲区只是一段连续的内存区域


64
00:03:46,360 --> 00:03:48,195 line:-1
但我们倾向于使用术语“缓冲区”


65
00:03:48,262 --> 00:03:52,065 line:-1
来表示由一系列元素组成的内存


66
00:03:52,533 --> 00:03:56,470 line:-2
这些元素具有相同尺寸
并通常具有相同的内部结构


67
00:03:57,838 --> 00:04:00,440 line:-2
而我们关注的重点
是其中一种非常重要的缓冲区


68
00:04:01,008 --> 00:04:02,042 line:-1
即图像缓冲区


69
00:04:02,409 --> 00:04:04,211 line:-1
我们用这个术语


70
00:04:04,278 --> 00:04:07,781 line:-2
来表示一种特定缓冲区
它保存了某些图像在内存中的表示


71
00:04:08,815 --> 00:04:10,484 line:-1
此缓冲区的每个元素


72
00:04:10,551 --> 00:04:15,889 line:-2
描述了图像中
每个像素的颜色和透明度


73
00:04:17,057 --> 00:04:20,494 line:-1
因此这个缓冲区在内存中的大小


74
00:04:20,560 --> 00:04:23,997 line:-1
与它包含的图像大小成正比


75
00:04:25,332 --> 00:04:30,404 line:-2
缓冲区的一个特别重要的例子
是帧缓冲区


76
00:04:31,338 --> 00:04:34,708 line:-1
帧缓冲区负责在你的app中


77
00:04:34,775 --> 00:04:35,709 line:-1
保存实际渲染后的输出


78
00:04:36,910 --> 00:04:39,680 line:-2
因此 当你的app更新
其视图层次结构时


79
00:04:40,013 --> 00:04:44,551 line:-2
UIKit将重新渲染app的窗口
及其所有子视图


80
00:04:44,952 --> 00:04:46,220 line:-1
到帧缓冲区中


81
00:04:47,187 --> 00:04:50,591 line:-1
该帧缓冲区提供每个像素的颜色信息


82
00:04:50,657 --> 00:04:52,092 line:-1
显示硬件将读取这些信息


83
00:04:52,159 --> 00:04:55,095 line:-1
以便点亮显示器上对应的像素


84
00:04:55,529 --> 00:04:58,198 line:-1
（图像缓冲区）


85
00:04:58,265 --> 00:05:00,801 line:-1
最后一部分以固定的时间间隔发生


86
00:05:01,835 --> 00:05:05,439 line:-2
它可能以每秒60帧的频率发生
即每1/60秒发生一次


87
00:05:05,772 --> 00:05:08,509 line:-2
或在配备ProMotion
Display的iPad上


88
00:05:08,575 --> 00:05:11,945 line:-2
它的速度可以达到
每1/120秒发生一次


89
00:05:13,814 --> 00:05:16,950 line:-2
如果你的app中没有任何改变
则显示硬件


90
00:05:17,017 --> 00:05:19,653 line:-1
会将它上次看到的相同的数据


91
00:05:19,720 --> 00:05:20,921 line:-1
从帧缓冲区中取出


92
00:05:21,788 --> 00:05:23,390 line:-1
但是当你改变


93
00:05:24,091 --> 00:05:26,460 line:-1
app中视图的内容


94
00:05:26,527 --> 00:05:29,963 line:-2
例如 你为图像视图指定
一个新的UIImage


95
00:05:31,064 --> 00:05:34,001 line:-2
UIKit将重新渲染
你的app窗口


96
00:05:34,067 --> 00:05:35,135 line:-1
并将其放入帧缓冲区


97
00:05:35,836 --> 00:05:38,605 line:-1
下一次显示硬件从帧缓冲区中取出时


98
00:05:38,672 --> 00:05:40,107 line:-1
它将会得到你的新内容


99
00:05:41,842 --> 00:05:45,979 line:-2
现在 你可以将图像缓冲区
与另一种“数据缓冲区”进行对比


100
00:05:46,046 --> 00:05:48,815 line:-1
这只是一种包含一系列字节的缓冲区


101
00:05:49,917 --> 00:05:54,588 line:-2
在我们的例子中 我们关心的是
包含图像文件的数据缓冲区


102
00:05:54,655 --> 00:05:56,523 line:-1
也许我们已经从网络上下载了


103
00:05:56,590 --> 00:05:58,125 line:-1
或者我们从磁盘加载它们


104
00:05:58,192 --> 00:05:59,626 line:-1
（数据缓冲区）


105
00:05:59,693 --> 00:06:03,897 line:-2
包含图像文件的数据缓冲区
通常以某些元数据开头


106
00:06:03,964 --> 00:06:06,967 line:-2
这些元数据描述了
存储在数据缓冲区中的图像大小


107
00:06:07,935 --> 00:06:10,103 line:-1
然后 包含图像数据本身


108
00:06:10,170 --> 00:06:14,508 line:-2
图像数据以某种形式编码
如JPEG压缩或PNG


109
00:06:16,143 --> 00:06:19,379 line:-1
这意味着该元数据后面的字节


110
00:06:19,646 --> 00:06:23,851 line:-2
实际上并不直接描述图像中
像素的任何内容


111
00:06:26,987 --> 00:06:30,490 line:-2
因此 我们可以深入了解一下
我们设置的这条管道


112
00:06:30,958 --> 00:06:32,626 line:-1
这里有一个UIImageView


113
00:06:32,693 --> 00:06:34,795 line:-2
并且我们已经突出显示了
帧缓冲区的区域


114
00:06:34,862 --> 00:06:38,165 line:-1
这块区域将由图像视图进行渲染填充


115
00:06:38,699 --> 00:06:41,034 line:-2
我们已经为这个图像视图
分配了一个UIImage


116
00:06:41,101 --> 00:06:42,236 line:-1
（管道实战）


117
00:06:42,302 --> 00:06:45,606 line:-2
它有一个表示图像文件内容的
数据缓冲区


118
00:06:45,672 --> 00:06:48,509 line:-1
其可能是从网络下载或从磁盘读取的


119
00:06:49,343 --> 00:06:54,348 line:-2
但我们需要用每个像素的数据
来填充帧缓冲区


120
00:06:55,382 --> 00:06:56,517 line:-1
为了做到这一点


121
00:06:57,184 --> 00:07:00,087 line:-2
UIImage将分配
一个图像缓冲区


122
00:07:00,587 --> 00:07:03,257 line:-1
其大小等于包含在数据缓冲区中的


123
00:07:03,323 --> 00:07:04,858 line:-1
图像的大小


124
00:07:05,526 --> 00:07:07,728 line:-1
并执行称为解码的操作


125
00:07:08,428 --> 00:07:13,133 line:-2
这将JPEG或PNG
或其他编码的图像数据


126
00:07:13,534 --> 00:07:16,436 line:-1
转换为每个像素的图像信息


127
00:07:17,604 --> 00:07:20,007 line:-2
然后 取决于我们的图像视图
的内容模式


128
00:07:20,741 --> 00:07:22,876 line:-2
当UIKit要求
图像视图进行渲染时


129
00:07:23,810 --> 00:07:28,015 line:-2
它会在将数据复制到帧缓冲区
的过程中


130
00:07:28,382 --> 00:07:30,184 line:-2
对来自图像缓冲区的数据
进行复制和缩放


131
00:07:32,486 --> 00:07:34,288 line:-1
现在 解码阶段


132
00:07:34,721 --> 00:07:38,058 line:-2
是CPU密集型的
特别是对于大型图像


133
00:07:38,559 --> 00:07:43,163 line:-2
因此 不是每次UIKit要求
图像视图渲染时都执行一次这个过程


134
00:07:43,964 --> 00:07:48,702 line:-2
UIImage绑定在图像缓冲区上
所以它只执行一次这个过程


135
00:07:49,469 --> 00:07:53,273 line:-2
因此 你的app
对于每个被解码的图像


136
00:07:53,340 --> 00:07:56,543 line:-1
都可能会持续存在大量的内存分配


137
00:07:56,610 --> 00:07:57,911 line:-1
（解码注意事项）


138
00:07:57,978 --> 00:08:00,247 line:-1
正如我前面提到的那样


139
00:08:00,314 --> 00:08:03,016 line:-2
这种内存分配与输入图像的大小
成正比


140
00:08:03,083 --> 00:08:05,219 line:-1
而与帧缓冲区中实际渲染的


141
00:08:05,285 --> 00:08:07,154 line:-1
图像视图的大小没有必然联系


142
00:08:08,255 --> 00:08:11,258 line:-2
而这会对性能
产生一些相当不利的后果


143
00:08:12,426 --> 00:08:16,597 line:-1
app地址空间中的大块内存分配


144
00:08:16,663 --> 00:08:19,099 line:-1
可能会迫使其他相关内容


145
00:08:19,166 --> 00:08:22,135 line:-1
远离它想要引用的内容


146
00:08:22,202 --> 00:08:23,537 line:-1
这种情况被称为碎片


147
00:08:23,604 --> 00:08:25,839 line:-1
（滥用内存的后果）


148
00:08:25,906 --> 00:08:30,110 line:-2
最终 如果你的app开始
占用越来越多的内存


149
00:08:30,410 --> 00:08:31,812 line:-1
操作系统将会介入


150
00:08:31,879 --> 00:08:35,616 line:-1
并开始透明地压缩物理内存的内容


151
00:08:36,717 --> 00:08:39,419 line:-1
CPU需要参与这个操作


152
00:08:39,720 --> 00:08:42,890 line:-2
因此 除了你自己的app
对CPU资源的使用


153
00:08:43,357 --> 00:08:47,394 line:-2
你可能会增加你无法控制的
全局CPU使用率


154
00:08:48,962 --> 00:08:52,799 line:-2
最终 你的app可能会
消耗过多的物理内存


155
00:08:53,100 --> 00:08:55,869 line:-1
以至于操作系统需要启动终止进程


156
00:08:56,403 --> 00:08:59,306 line:-1
它将从低优先级的后台进程开始


157
00:09:00,140 --> 00:09:03,243 line:-2
最终 如果你的app消耗了
达到特定数量的内存


158
00:09:03,610 --> 00:09:05,646 line:-1
你的app本身可能会被终止


159
00:09:06,313 --> 00:09:07,681 line:-1
而其中被终止的后台进程


160
00:09:07,748 --> 00:09:09,783 line:-1
可能正代表用户执行某些重要工作


161
00:09:09,850 --> 00:09:12,553 line:-2
因此 它们可能一终止就立即
重新启动


162
00:09:13,587 --> 00:09:15,155 line:-1
所以 即使你的app


163
00:09:15,455 --> 00:09:18,025 line:-1
可能只会在短时间内消耗内存


164
00:09:18,425 --> 00:09:22,963 line:-2
它也可能对CPU使用率
产生深远的影响


165
00:09:24,064 --> 00:09:27,401 line:-2
因此 我们希望减少app的
内存使用量


166
00:09:27,467 --> 00:09:31,104 line:-2
我们可以用一种称为向下采样的技术
来实现这一目标


167
00:09:32,739 --> 00:09:36,910 line:-2
现在 我们来看一下
图像渲染管道的更多细节


168
00:09:36,977 --> 00:09:40,480 line:-2
包括我们要在其中显示图像的
图像视图


169
00:09:40,547 --> 00:09:44,384 line:-1
实际上比要显示的图像小的这一事实


170
00:09:44,985 --> 00:09:47,788 line:-2
通常
Core Animation框架


171
00:09:47,855 --> 00:09:50,290 line:-1
在渲染阶段


172
00:09:50,357 --> 00:09:51,692 line:-1
将负责缩小该图像


173
00:09:52,259 --> 00:09:55,696 line:-2
但我们可以通过使用这种下采样技术
来节省一些内存


174
00:09:56,063 --> 00:09:59,733 line:-2
本质上 我们要做的就是捕捉
该缩小的操作


175
00:10:00,734 --> 00:10:02,269 line:-1
并将其放入缩略图的对象中


176
00:10:03,270 --> 00:10:08,609 line:-1
最终我们将会降低内存开销


177
00:10:08,675 --> 00:10:11,278 line:-2
因为我们将有一个较小的
解码图像缓冲区


178
00:10:12,713 --> 00:10:15,749 line:-2
这样 我们设置了一个图像源
创建了一个缩略图


179
00:10:16,350 --> 00:10:19,987 line:-2
然后将解码图像缓冲区
捕获到UIImage中


180
00:10:20,053 --> 00:10:22,489 line:-2
并将该UIImage
分配给我们的图像视图


181
00:10:23,423 --> 00:10:25,492 line:-1
接着 我们就可以丢弃原来的


182
00:10:25,559 --> 00:10:26,927 line:-1
包含我们图片的数据缓冲区


183
00:10:26,994 --> 00:10:30,063 line:-1
其结果是我们的app


184
00:10:30,130 --> 00:10:31,231 line:-1
将具有一个更小的长期内存占用足迹


185
00:10:31,598 --> 00:10:34,968 line:-2
执行该操作的代码有几个步骤
我会带你们过一遍这个流程


186
00:10:35,035 --> 00:10:37,838 line:-1
我不打算讲述非常低级的细节


187
00:10:37,905 --> 00:10:39,573 line:-1
但我会重点介绍一些重要的部分


188
00:10:40,374 --> 00:10:42,809 line:-2
首先 我们要创建一个
CGImageSource对象


189
00:10:44,178 --> 00:10:47,748 line:-2
CGImageSourceCreate
可以接受一个选项字典参数


190
00:10:47,814 --> 00:10:49,783 line:-1
我们这里要传递的重要选项参数


191
00:10:49,850 --> 00:10:51,985 line:-1
是这个ShouldCache标志


192
00:10:52,052 --> 00:10:54,254 line:-2
这就告诉了
Core Graphics框架


193
00:10:54,321 --> 00:10:55,822 line:-1
我们只是在创建一个对象


194
00:10:55,889 --> 00:11:00,694 line:-2
来表示存储在该URL的
文件中的信息


195
00:11:01,728 --> 00:11:04,531 line:-1
不要立即解码这个图像


196
00:11:04,598 --> 00:11:06,200 line:-1
只需创建一个表示它的对象


197
00:11:06,266 --> 00:11:08,769 line:-1
我们将需要来自此URL的信息


198
00:11:11,104 --> 00:11:14,875 line:-2
然后 我们将在水平和垂直轴上
进行计算


199
00:11:14,942 --> 00:11:16,376 line:-1
该计算基于期望的图片大小


200
00:11:16,443 --> 00:11:18,946 line:-1
以及我们要渲染的像素和点大小


201
00:11:19,847 --> 00:11:22,015 line:-1
这是以像素为单位的较大维度


202
00:11:22,683 --> 00:11:24,117 line:-1
计算这些信息


203
00:11:24,718 --> 00:11:27,454 line:-2
然后为我们的缩略图
创建一个选项字典


204
00:11:28,255 --> 00:11:30,057 line:-1
这里列出了几个选项


205
00:11:30,123 --> 00:11:32,926 line:-2
你可以在文档中
查看这些选项的具体含义


206
00:11:32,993 --> 00:11:37,097 line:-2
但非常重要的是
这个CacheImmediately选项


207
00:11:38,465 --> 00:11:41,668 line:-2
通过在这里传递这个选项
我们告诉Core Graphics


208
00:11:41,735 --> 00:11:44,171 line:-1
当我要求你创建缩略图时


209
00:11:44,238 --> 00:11:48,509 line:-2
这就是你应该为我创建
解码图像缓冲区的确切时刻


210
00:11:49,610 --> 00:11:50,911 line:-1
因此我们可以确切地控制


211
00:11:50,978 --> 00:11:53,080 line:-1
何时调用CPU来进行解码


212
00:11:56,016 --> 00:12:00,220 line:-2
接着我们创建缩略图
即我们拿到所返回的CGImage


213
00:12:00,687 --> 00:12:02,189 line:-1
将其包装在UIImage中


214
00:12:02,256 --> 00:12:03,924 line:-2
从我们在此编写的
辅助函数中返回


215
00:12:05,993 --> 00:12:09,196 line:-2
为了让你了解这项技术
为我们节省的开销数量


216
00:12:09,796 --> 00:12:11,765 line:-1
我们只在这里显示全屏图像


217
00:12:11,832 --> 00:12:14,434 line:-2
这是一张大小为
3000 x 2000像素的照片


218
00:12:14,501 --> 00:12:15,836 line:-1
如果我们不做优化


219
00:12:15,903 --> 00:12:19,606 line:-2
只是将UIImageView放入
Storyboard并将图片分配给它


220
00:12:20,007 --> 00:12:24,144 line:-2
这个app占用了31.5兆
却没有做任何事情


221
00:12:25,879 --> 00:12:27,814 line:-1
现在 使用这种下采样技术


222
00:12:27,881 --> 00:12:31,652 line:-2
并且只创建一个实际显示大小的
图像缓冲区


223
00:12:32,152 --> 00:12:33,921 line:-1
我们可以得到这个app的


224
00:12:33,987 --> 00:12:36,390 line:-2
内存使用情况
其降至18.4兆


225
00:12:36,857 --> 00:12:39,726 line:-1
这大大减少了内存使用量


226
00:12:44,331 --> 00:12:46,567 line:-2
谢谢大家 但你们都应该
因在自己的app中


227
00:12:46,633 --> 00:12:48,468 line:-1
使用此技术而得到掌声


228
00:12:49,770 --> 00:12:52,739 line:-2
你可以想象这对于一个
需要在屏幕上的


229
00:12:52,806 --> 00:12:56,276 line:-2
一小块空间里显示大量
可能很大输入图像


230
00:12:56,844 --> 00:12:58,779 line:-1
的app来说有多么重要


231
00:12:59,446 --> 00:13:00,514 line:-1
例如Camera Roll


232
00:13:02,616 --> 00:13:05,519 line:-2
你可以使用UICollectionView
来实现这样的视图


233
00:13:05,586 --> 00:13:08,422 line:-2
因此我们为indexPath中
item实现了单元格


234
00:13:09,089 --> 00:13:11,859 line:-1
并且我们使用之前写的辅助函数


235
00:13:11,925 --> 00:13:15,863 line:-2
将图像向下采样使之缩小到
当单元格实际放在屏幕上时


236
00:13:15,929 --> 00:13:18,165 line:-1
它们将要显示的大小


237
00:13:19,733 --> 00:13:22,135 line:-1
你认为这是一件很好的事情 对吧？


238
00:13:22,202 --> 00:13:25,339 line:-2
我们实际上减少了内存的使用量
而不是允许系统中存在


239
00:13:25,405 --> 00:13:27,007 line:-1
这些大的内存区域


240
00:13:27,407 --> 00:13:30,511 line:-2
不幸的是 这并不能解决我们的
另一个问题


241
00:13:30,577 --> 00:13:34,314 line:-2
这些问题在可滚动视图 比如
表视图和集合视图中是很常见的


242
00:13:35,415 --> 00:13:37,084 line:-1
你可能曾经见过这种情况


243
00:13:37,150 --> 00:13:40,487 line:-2
你在app中滚动页面
而在滚动过程中页面发生了粘连


244
00:13:41,188 --> 00:13:42,422 line:-1
这里发生的情况是


245
00:13:42,823 --> 00:13:48,529 line:-2
当我们滚动页面时
CPU相对比较空闲


246
00:13:49,096 --> 00:13:50,130 line:-1
或它所做的工作


247
00:13:50,197 --> 00:13:54,902 line:-2
可以在显示硬件需要帧缓冲的
下一个副本之前完成


248
00:13:55,536 --> 00:13:59,473 line:-2
所以当帧缓冲区被更新时
我们能够看到流动的效果


249
00:13:59,540 --> 00:14:02,342 line:-1
并且显示硬件能够及时获得新帧


250
00:14:03,310 --> 00:14:06,013 line:-1
但现在 我们即将显示另一行图像


251
00:14:06,346 --> 00:14:09,583 line:-2
在将单元格交回
UICollectionView之前


252
00:14:10,350 --> 00:14:12,553 line:-2
我们要求Core Graphics
解码这些图像


253
00:14:13,453 --> 00:14:15,155 line:-1
这将会花费很长的CPU时间


254
00:14:16,356 --> 00:14:19,726 line:-1
以至于我们不得不重新渲染帧缓冲区


255
00:14:20,861 --> 00:14:23,063 line:-1
但显示器硬件按固定的时间间隔运行


256
00:14:23,830 --> 00:14:27,467 line:-2
因此 从用户的角度来看
app好像卡住了一样


257
00:14:27,534 --> 00:14:29,203 line:-1
在可滚动视图中进行解码


258
00:14:29,269 --> 00:14:30,671 line:-1
我们完成了对图像的解码


259
00:14:30,737 --> 00:14:33,740 line:-2
我们可以将单元格提供给
UICollectionView


260
00:14:35,042 --> 00:14:36,944 line:-1
和以前一样 动画继续


261
00:14:37,878 --> 00:14:39,413 line:-1
刚刚在那里看到了一个粘连


262
00:14:40,881 --> 00:14:42,049 line:-1
现在 除了这种行为


263
00:14:42,115 --> 00:14:45,085 line:-1
明显的响应性后果


264
00:14:45,886 --> 00:14:49,523 line:-1
其对电池寿命有更细微的不利影响


265
00:14:50,390 --> 00:14:54,895 line:-2
因为iOS非常擅长管理
当CPU需求相对平稳持续时


266
00:14:55,562 --> 00:14:59,266 line:-1
对电池的电量需求


267
00:14:59,733 --> 00:15:01,568 line:-1
然而我们在这里可以看到峰值


268
00:15:02,035 --> 00:15:04,905 line:-1
当新行即将进入滚动视图时


269
00:15:05,973 --> 00:15:10,310 line:-2
我们会看到较高的CPU使用率
然后再回到较低的水平


270
00:15:12,279 --> 00:15:16,950 line:-2
我们可以使用两种技术
来平滑我们的CPU使用率


271
00:15:17,584 --> 00:15:18,819 line:-1
第一个是预取


272
00:15:19,753 --> 00:15:23,190 line:-1
如果你想知道更多关于预取的知识


273
00:15:23,257 --> 00:15:26,894 line:-2
可以观看今年WWDC中的演讲
“CollectionView一览”


274
00:15:27,461 --> 00:15:28,862 line:-1
这里的基本思想


275
00:15:28,929 --> 00:15:33,267 line:-2
是预取允许CollectionView
告知我们的数据源


276
00:15:33,700 --> 00:15:37,905 line:-2
它当前不需要一个单元格
但它将在不久的将来需要


277
00:15:37,971 --> 00:15:40,607 line:-2
因此如果你有任何工作要做
也许现在就可以提前开始


278
00:15:41,375 --> 00:15:44,044 line:-2
这允许我们随时间推移
分摊CPU使用率


279
00:15:45,279 --> 00:15:47,848 line:-2
因此我们减少了CPU使用的
峰值大小


280
00:15:49,650 --> 00:15:52,653 line:-2
我们可以使用的另一种技术
是在后台执行工作


281
00:15:53,287 --> 00:15:55,155 line:-1
既然我们已经随时间分散了工作量


282
00:15:55,222 --> 00:15:57,858 line:-2
我们也可以将这些工作
分散到可用的CPU上


283
00:16:01,595 --> 00:16:02,829 line:-1
这样做的效果


284
00:16:02,896 --> 00:16:05,399 line:-1
是你的app具有更强的响应能力


285
00:16:05,732 --> 00:16:08,035 line:-1
并且该设备具有更长的电池寿命


286
00:16:09,570 --> 00:16:11,071 line:-1
为了在这里进行实际演示


287
00:16:11,438 --> 00:16:15,542 line:-1
我们已经在数据源上实现了预取方法


288
00:16:16,610 --> 00:16:18,412 line:-1
它将会调用我们的辅助函数


289
00:16:18,645 --> 00:16:21,248 line:-2
来生成我们将要在
CollectionView单元格中


290
00:16:21,849 --> 00:16:25,485 line:-1
所显示图片的下采样版本


291
00:16:27,254 --> 00:16:31,925 line:-2
它通过将工作分派到
其中一个全局异步队列来完成此任务


292
00:16:33,727 --> 00:16:35,195 line:-1
很好 我们的工作正在后台进行


293
00:16:35,262 --> 00:16:36,697 line:-1
这就是我们想要做的


294
00:16:37,564 --> 00:16:40,200 line:-1
但这里有一个潜在的缺陷


295
00:16:40,734 --> 00:16:43,737 line:-2
这是一个我们喜欢称之为
线程爆炸的现象


296
00:16:44,505 --> 00:16:47,908 line:-2
当我们要求系统去做
比CPU能够做的工作


297
00:16:48,408 --> 00:16:50,444 line:-1
更多的工作时就会发生这种情况


298
00:16:51,411 --> 00:16:53,447 line:-1
如果我们要显示大量的图像


299
00:16:53,514 --> 00:16:55,282 line:-1
比如同时显示6张或8张图片


300
00:16:55,616 --> 00:16:58,018 line:-2
但是我们在只有两个CPU的
设备上运行


301
00:16:58,619 --> 00:17:00,921 line:-1
我们不能一次完成所有这些工作


302
00:17:00,988 --> 00:17:03,457 line:-2
我们无法在不存在的CPU上
进行并行处理


303
00:17:03,524 --> 00:17:04,958 line:-1
（线程爆炸）


304
00:17:05,025 --> 00:17:06,159 line:-1
现在 为了避免


305
00:17:06,627 --> 00:17:09,762 line:-2
向一个全局队列中
异步的分配任务时发生死锁


306
00:17:10,263 --> 00:17:15,569 line:-2
GCD将创建新线程来捕捉
我们要求它所做的工作


307
00:17:16,236 --> 00:17:18,438 line:-1
然后 CPU将花费大量时间


308
00:17:18,505 --> 00:17:20,040 line:-1
在这些线程之间进行切换


309
00:17:20,339 --> 00:17:23,109 line:-1
尝试在所有工作上取得我们


310
00:17:23,176 --> 00:17:25,244 line:-1
要求操作系统为我们做的渐进式进展


311
00:17:25,712 --> 00:17:27,146 line:-1
在这些线程之间不停切换


312
00:17:27,214 --> 00:17:29,016 line:-1
实际上是相当大的开销


313
00:17:31,351 --> 00:17:34,688 line:-1
如果有一个或多个CPU有机会


314
00:17:34,755 --> 00:17:38,058 line:-1
一次处理完图片 效果会更好


315
00:17:39,193 --> 00:17:43,297 line:-2
因此 我们将借鉴去年的
“现代化中心调度GCD用法”


316
00:17:43,764 --> 00:17:46,300 line:-1
演讲中所提出的一项技术


317
00:17:46,733 --> 00:17:47,935 line:-1
我们将同步一些工作


318
00:17:48,001 --> 00:17:50,771 line:-2
抱歉 不是同步
我们要序列化一些工作


319
00:17:52,940 --> 00:17:57,444 line:-2
因此 我们现在不是简单地
将工作分派到全局异步队列之一


320
00:17:58,178 --> 00:17:59,880 line:-1
而是创建一个串行队列


321
00:18:01,148 --> 00:18:03,817 line:-1
并且在预取方法的实现中


322
00:18:05,285 --> 00:18:07,588 line:-1
我们异步地将工作分派到该队列


323
00:18:07,888 --> 00:18:10,090 line:-1
它的确意味着单个图像的加载


324
00:18:10,157 --> 00:18:12,860 line:-1
可能要比以前晚才能开始取得进展


325
00:18:13,560 --> 00:18:16,430 line:-1
但这也意味着CPU将花费更少时间


326
00:18:17,064 --> 00:18:19,166 line:-1
在它可以做的小任务之间来回切换


327
00:18:19,967 --> 00:18:21,468 line:-1
（图片来源）


328
00:18:21,535 --> 00:18:24,571 line:-2
我们显示的这些图像
可能来自多个地方


329
00:18:25,105 --> 00:18:27,241 line:-1
它们可能是随app附带的


330
00:18:28,141 --> 00:18:30,177 line:-2
在这种情况下
它们可以存储在图像素材中


331
00:18:30,544 --> 00:18:33,180 line:-2
或者可能存储在一个文件中
而不是我们的程序包中


332
00:18:33,881 --> 00:18:35,349 line:-1
或者它们可能来自网络


333
00:18:35,983 --> 00:18:37,651 line:-1
或者是在app的


334
00:18:37,718 --> 00:18:40,587 line:-1
文档目录的文档中


335
00:18:41,188 --> 00:18:42,656 line:-1
它们可以存储在缓存中


336
00:18:43,690 --> 00:18:46,260 line:-1
但是对于你的app所附带的图片


337
00:18:46,527 --> 00:18:50,030 line:-2
我们强烈建议你使用
图像素材来存储


338
00:18:51,198 --> 00:18:52,733 line:-1
这其中有很多原因


339
00:18:54,535 --> 00:18:58,238 line:-2
图像素材针对基于名称和
基于特征的查找进行了优化


340
00:18:58,639 --> 00:19:01,608 line:-1
在素材目录中查找图片资源


341
00:19:01,675 --> 00:19:04,611 line:-2
会比搜索具有特定命名格式的
磁盘上的文件要快得多


342
00:19:04,678 --> 00:19:06,813 line:-1
（预置图像素材）


343
00:19:06,880 --> 00:19:10,551 line:-1
素材目录运行时在管理


344
00:19:10,617 --> 00:19:12,219 line:-1
缓冲区大小方面也非常智能


345
00:19:13,854 --> 00:19:16,723 line:-1
还有一些与运行时性能无关的特性


346
00:19:17,090 --> 00:19:18,992 line:-1
是图像素材独有的


347
00:19:19,059 --> 00:19:21,261 line:-1
包括针对不同设备瘦身的功能


348
00:19:21,328 --> 00:19:24,264 line:-1
这意味着你的app只下载


349
00:19:24,331 --> 00:19:26,700 line:-1
与其所运行的设备相关的图像资源


350
00:19:27,334 --> 00:19:28,468 line:-1
还有矢量图形功能


351
00:19:30,904 --> 00:19:33,607 line:-2
矢量图形是iOS 11中
引入的一项功能


352
00:19:33,674 --> 00:19:37,077 line:-1
你可以在图像素材编辑器中


353
00:19:37,144 --> 00:19:39,246 line:-2
选中“保留矢量数据”
复选框来启用它


354
00:19:40,180 --> 00:19:44,318 line:-2
其效果是如果你的图像
在图像视图的渲染中


355
00:19:44,384 --> 00:19:47,120 line:-1
大于或小于图像的原始大小


356
00:19:47,454 --> 00:19:48,522 line:-1
它也不会变得模糊


357
00:19:49,356 --> 00:19:52,659 line:-2
这种图像实际上是从矢量图形
重新栅格化的


358
00:19:52,726 --> 00:19:54,528 line:-1
因此它具有很好的边缘清晰度


359
00:19:55,762 --> 00:19:58,198 line:-2
我们在操作系统中的一个地方
使用了这种技术


360
00:19:58,265 --> 00:20:01,368 line:-2
若你在Accessibility
设置中调整动态类型


361
00:20:01,768 --> 00:20:03,270 line:-1
到一个非常大的尺寸


362
00:20:03,570 --> 00:20:06,673 line:-1
然后点击并按住标签栏中的项目


363
00:20:07,007 --> 00:20:09,977 line:-1
将会出现一个小HUD


364
00:20:10,043 --> 00:20:12,846 line:-2
显示当前你的手指所按住
物体的放大视图


365
00:20:14,081 --> 00:20:18,151 line:-2
因此如果你希望你的图片在这样的
情境下看起来效果更好


366
00:20:18,752 --> 00:20:21,655 line:-1
那就选中图像素材管理器中的


367
00:20:21,722 --> 00:20:23,790 line:-1
“保留向量插图”复选框


368
00:20:23,857 --> 00:20:25,993 line:-2
抱歉 应该是
“保留矢量数据”复选框


369
00:20:26,793 --> 00:20:29,930 line:-2
它的工作方式与我们之前看到的
管道非常相似


370
00:20:30,664 --> 00:20:34,601 line:-2
只是这里不是一个解码阶段
而是一个栅格化阶段


371
00:20:34,668 --> 00:20:37,137 line:-1
其负责获取矢量数据


372
00:20:37,204 --> 00:20:40,941 line:-2
并将其转换为可复制到
帧缓冲区的位图数据


373
00:20:41,008 --> 00:20:42,910 line:-1
（矢量图形管道）


374
00:20:43,277 --> 00:20:44,978 line:-1
（矢量图形优化）


375
00:20:45,045 --> 00:20:46,847 line:-1
如果我们必须为你的app中


376
00:20:46,914 --> 00:20:50,817 line:-2
所有矢量图形进行这项操作
我们会消耗更多的CPU资源


377
00:20:50,884 --> 00:20:52,653 line:-1
因此我们在这里做了一个优化


378
00:20:53,153 --> 00:20:56,657 line:-2
如果你有一张选中了
“保留矢量数据”的图像


379
00:20:57,291 --> 00:20:59,626 line:-1
但你以正常尺寸渲染它


380
00:21:01,195 --> 00:21:06,600 line:-2
实际上素材目录编译器已经生成了
那个图片的预栅格化版本


381
00:21:06,667 --> 00:21:08,936 line:-1
并将其存储在素材目录中


382
00:21:09,436 --> 00:21:11,939 line:-1
因此并不需要做复杂的数学运算


383
00:21:12,005 --> 00:21:14,908 line:-1
来将矢量图形栅格化为位图


384
00:21:15,209 --> 00:21:18,846 line:-2
我们可以直接解码
存储在素材目录中的图像


385
00:21:19,580 --> 00:21:22,149 line:-1
并将其直接渲染到帧缓冲区中


386
00:21:24,952 --> 00:21:29,489 line:-1
如果你计划以几种固定大小呈现图像


387
00:21:29,556 --> 00:21:33,093 line:-1
比如你有一个小图标和一个大图标


388
00:21:33,794 --> 00:21:37,130 line:-2
你不需要依赖
“保留矢量数据”复选框


389
00:21:37,731 --> 00:21:41,034 line:-1
只需创建这两种你预先确定好


390
00:21:41,101 --> 00:21:43,070 line:-1
需要渲染的尺寸的图片素材


391
00:21:44,972 --> 00:21:46,907 line:-1
这将允许在编译期


392
00:21:47,741 --> 00:21:52,212 line:-2
调用CPU对你的图片进行栅格化
从而达到优化的效果


393
00:21:52,613 --> 00:21:55,649 line:-2
而不是每次将图像复制到帧缓冲区时
都进行计算


394
00:21:58,285 --> 00:22:01,755 line:-2
我们已经看到了如何使用
UIImage和UIImageView


395
00:22:02,823 --> 00:22:05,926 line:-2
但你的app所做的图形工作
不止这些


396
00:22:05,993 --> 00:22:08,862 line:-1
有时 app在运行时绘制内容


397
00:22:12,299 --> 00:22:13,800 line:-1
这种情况的例子


398
00:22:14,268 --> 00:22:17,704 line:-1
可以在如Photos app中的


399
00:22:17,771 --> 00:22:19,506 line:-1
编辑视图中看到


400
00:22:21,275 --> 00:22:27,414 line:-2
这个UIButton显示了一个图标
并且UIButton可以直接使用UIImageView


401
00:22:28,549 --> 00:22:32,085 line:-2
但是UIButton在这里不支持
这个Live按钮的风格


402
00:22:32,152 --> 00:22:35,322 line:-2
以实现点击
以启用或禁用Live Photo


403
00:22:36,223 --> 00:22:38,392 line:-2
因此我们自己将不得不
在这里做一些工作


404
00:22:39,326 --> 00:22:42,863 line:-2
这里一个可能的实现是
继承UIView


405
00:22:43,397 --> 00:22:44,765 line:-1
并实现draw方法


406
00:22:45,399 --> 00:22:49,236 line:-2
这里的这个实现绘制一个
黄色的roundRect


407
00:22:49,469 --> 00:22:51,538 line:-2
绘制一些文字
并在其上绘制一个图像


408
00:22:53,640 --> 00:22:55,342 line:-1
出于若干原因


409
00:22:56,210 --> 00:22:57,344 line:-1
我们并不推荐这种方法


410
00:22:58,078 --> 00:23:03,417 line:-2
我们将这个视图子类与
UIImageView进行比较


411
00:23:04,318 --> 00:23:08,155 line:-2
你可能已经知道
每个UIView实际上都是


412
00:23:08,222 --> 00:23:10,657 line:-2
依赖Core Animation
运行时的CALayer实现的


413
00:23:11,692 --> 00:23:14,928 line:-2
对于我们的图像视图
图像视图创建…


414
00:23:14,995 --> 00:23:17,831 line:-1
要求图像创建解码图像缓冲区


415
00:23:19,032 --> 00:23:22,236 line:-2
然后 将解码后的图像
交给CALayer


416
00:23:22,736 --> 00:23:24,271 line:-1
用作其所在层的内容


417
00:23:24,338 --> 00:23:26,139 line:-2
（自定义绘图
与UIIMAGEVIEW）


418
00:23:26,206 --> 00:23:28,442 line:-2
对于我们重写draw得到的
自定义视图


419
00:23:29,810 --> 00:23:31,578 line:-1
它们很相似 但略有不同


420
00:23:31,645 --> 00:23:34,047 line:-1
负责创建图像缓冲区


421
00:23:34,414 --> 00:23:36,617 line:-1
来保存我们draw方法的内容


422
00:23:37,317 --> 00:23:40,053 line:-2
以及我们视图的层
执行draw函数


423
00:23:40,621 --> 00:23:43,524 line:-1
并填充该图像缓冲区的内容


424
00:23:43,590 --> 00:23:45,759 line:-1
这些内容接着根据显示硬件的需要


425
00:23:46,226 --> 00:23:47,928 line:-1
被复制到帧缓冲区中


426
00:23:52,766 --> 00:23:54,935 line:-1
（后备存储器存储开销）


427
00:23:55,002 --> 00:23:56,904 line:-1
为了解这将产生多大的开销


428
00:23:56,970 --> 00:23:59,072 line:-1
以及为什么我们不应该寻求


429
00:23:59,139 --> 00:24:00,374 line:-1
实现这个UI的替代方法


430
00:24:01,575 --> 00:24:03,510 line:-1
我们在此使用的后备存储器


431
00:24:03,944 --> 00:24:06,813 line:-2
即连接到CALayer
的图像缓冲区


432
00:24:06,880 --> 00:24:09,783 line:-2
其大小与我们正在显示的
视图大小成正比


433
00:24:11,118 --> 00:24:14,121 line:-2
我们在iOS 12中引入了
一项新功能和优化


434
00:24:14,988 --> 00:24:19,092 line:-1
即后备存储器中元素的大小


435
00:24:19,493 --> 00:24:21,528 line:-1
实际上会动态增长


436
00:24:21,595 --> 00:24:24,264 line:-1
取决于你是否绘制任何有颜色的内容


437
00:24:24,331 --> 00:24:25,532 line:-1
以及该颜色的内容


438
00:24:25,599 --> 00:24:28,468 line:-1
是在标准色彩范围之内或之外


439
00:24:28,969 --> 00:24:33,173 line:-2
因此如果你使用扩展的SRGB颜色
绘制广色域内容


440
00:24:33,874 --> 00:24:36,176 line:-1
则后备存储器实际上会比


441
00:24:37,077 --> 00:24:38,512 line:-1
仅使用0到1范围内的颜色


442
00:24:38,579 --> 00:24:42,049 line:-1
的后备存储器大


443
00:24:43,951 --> 00:24:46,053 line:-1
在之前的iOS版本中


444
00:24:46,119 --> 00:24:49,556 line:-2
你可以通过设置CALayer的
内容格式属性


445
00:24:49,623 --> 00:24:51,225 line:-2
来作为对Core Animation
的一个提示


446
00:24:51,291 --> 00:24:55,195 line:-2
即我知道我不需要在这个视图中
支持广色域内容


447
00:24:55,262 --> 00:24:58,298 line:-2
或我知道我需要在这个视图中
支持广色域内容


448
00:24:58,966 --> 00:25:01,502 line:-1
如果你这样做 你实际上将会禁用


449
00:25:02,102 --> 00:25:05,038 line:-1
我们在iOS 12中引入的优化


450
00:25:05,405 --> 00:25:08,709 line:-2
因此 请检查
layerWillDraw的实现


451
00:25:08,775 --> 00:25:11,478 line:-1
确保你不会意外关闭这项优化


452
00:25:11,545 --> 00:25:14,348 line:-2
该优化能够使你的运行
在iOS 12上的代码受益无穷


453
00:25:17,651 --> 00:25:20,053 line:-1
但我们可以做得比仅仅提示我们


454
00:25:20,120 --> 00:25:23,557 line:-2
是否需要一个支持广色域的
后备存储器更好


455
00:25:23,857 --> 00:25:26,293 line:-1
我们实际上可以减少


456
00:25:26,360 --> 00:25:27,628 line:-1
app所需的后备存储器总量


457
00:25:27,995 --> 00:25:32,199 line:-2
我们可以通过将这个较大的视图
重构为较小的子视图来实现这一点


458
00:25:32,933 --> 00:25:36,336 line:-2
并且减少或消除
重写draw函数的地方


459
00:25:36,403 --> 00:25:38,205 line:-1
（减少后备存储器的使用）


460
00:25:38,272 --> 00:25:40,974 line:-1
这将帮助我们消除


461
00:25:41,041 --> 00:25:42,242 line:-1
内存中图像数据的重复副本


462
00:25:42,876 --> 00:25:46,146 line:-2
并且这将允许我们利用
UIView的优化属性


463
00:25:46,213 --> 00:25:47,714 line:-1
其不需实现后备存储器


464
00:25:50,918 --> 00:25:53,120 line:-2
因此 正如我所提到的
重写draw方法


465
00:25:53,187 --> 00:25:56,223 line:-2
将需要创建一个后备存储器
以与CALayer一起使用


466
00:25:57,357 --> 00:25:59,726 line:-1
但是即使你不重写draw方法


467
00:25:59,793 --> 00:26:01,395 line:-2
UIView中的一些属性
仍然可以工作


468
00:26:01,795 --> 00:26:04,731 line:-1
例如设置UIView的背景颜色


469
00:26:04,798 --> 00:26:09,102 line:-2
并不需要创建后备存储器
除非你使用的是图案颜色


470
00:26:09,503 --> 00:26:11,305 line:-1
因此我建议不要在UIView中


471
00:26:11,371 --> 00:26:13,440 line:-1
使用具有背景颜色属性的图案颜色


472
00:26:15,142 --> 00:26:17,244 line:-2
而应该创建
一个UIImageView


473
00:26:17,811 --> 00:26:22,115 line:-2
将你的图像分配到该图像视图并使用
UIImageView中的函数


474
00:26:22,616 --> 00:26:24,651 line:-1
恰当地设置平铺参数


475
00:26:27,921 --> 00:26:31,058 line:-1
当我们想要剪切圆角矩形的角时


476
00:26:32,226 --> 00:26:34,995 line:-2
我们希望使用CALayer的
cornerRadius属性


477
00:26:35,829 --> 00:26:39,900 line:-2
因为Core Animation
能够渲染削角


478
00:26:40,167 --> 00:26:42,436 line:-1
而不需要额外的内存分配


479
00:26:43,437 --> 00:26:46,139 line:-2
如果我们改用更强大的
maskView


480
00:26:46,206 --> 00:26:47,574 line:-1
或maskLayer属性


481
00:26:48,308 --> 00:26:51,411 line:-2
我们最终需要额外分配
内存来存储该mask


482
00:26:53,680 --> 00:26:57,618 line:-1
如果你有更复杂透明区域的背景


483
00:26:58,151 --> 00:27:00,687 line:-2
并且不能通过cornerRadius属性
进行设置


484
00:27:00,754 --> 00:27:02,823 line:-2
你应该考虑使用
UIImageView


485
00:27:03,857 --> 00:27:06,026 line:-1
将这些信息存储在你的素材目录中


486
00:27:06,093 --> 00:27:07,995 line:-1
或在运行时渲染它


487
00:27:08,295 --> 00:27:10,531 line:-1
并将其作为图像提供给图像视图


488
00:27:10,597 --> 00:27:12,533 line:-2
而不应该使用maskView
或maskLayer


489
00:27:15,202 --> 00:27:18,372 line:-2
最后
对于该Live Photo图标


490
00:27:19,540 --> 00:27:24,378 line:-2
UIImageView
能够对单色图稿进行着色


491
00:27:24,444 --> 00:27:26,647 line:-1
而不需要额外的内存分配


492
00:27:28,182 --> 00:27:30,651 line:-1
你要做的第一件事是勾选…


493
00:27:30,717 --> 00:27:31,618 line:-1
不是勾选复选框


494
00:27:31,685 --> 00:27:34,555 line:-1
而是在图片素材编辑器中


495
00:27:34,621 --> 00:27:37,157 line:-2
将渲染模式属性设置为
always template


496
00:27:37,724 --> 00:27:40,861 line:-2
或在UIImageView上调用
withRenderingMode函数


497
00:27:41,261 --> 00:27:43,797 line:-2
来创建一个渲染模式为
always template的UIImage


498
00:27:44,898 --> 00:27:48,435 line:-2
然后将该图像分配给图像视图
并将该图像视图的tintColor


499
00:27:48,869 --> 00:27:51,004 line:-1
设置为你想要图像渲染的颜色


500
00:27:52,172 --> 00:27:55,442 line:-2
在UIImage将图像渲染到
帧缓冲区的过程中


501
00:27:55,509 --> 00:27:59,947 line:-1
它会在该复制操作中使用纯色


502
00:28:00,514 --> 00:28:03,650 line:-1
而不需要持有一个


503
00:28:03,884 --> 00:28:05,419 line:-1
app了纯色图像的单独副本


504
00:28:07,988 --> 00:28:10,991 line:-2
UIKit提供的视图中
内置了另一项优化


505
00:28:11,358 --> 00:28:17,764 line:-2
UILabel可以在显示单色文本时
比显示彩色文本或表情符号时


506
00:28:18,332 --> 00:28:20,367 line:-1
减少75%的内存使用


507
00:28:21,835 --> 00:28:24,605 line:-2
如果你想更详细地了解
此优化的工作原理


508
00:28:24,671 --> 00:28:27,908 line:-2
以及如何将其app于
UIView的自定义子类


509
00:28:28,408 --> 00:28:30,744 line:-1
可以参考“iOS内存深潜”演讲


510
00:28:31,378 --> 00:28:34,982 line:-2
其详细介绍了这种名为A8的
后备存储器格式


511
00:28:38,318 --> 00:28:42,523 line:-1
有时候 你想渲染存储在内存中


512
00:28:42,956 --> 00:28:45,425 line:-1
图像缓冲区中的图像


513
00:28:46,093 --> 00:28:49,897 line:-2
UIKit为此提供的类
是UIGraphicsImageRenderer


514
00:28:50,898 --> 00:28:55,369 line:-2
还有另一个更旧的函数
UIGraphicsBeginImageContext


515
00:28:55,435 --> 00:28:58,972 line:-2
但请不要使用它
因为只有图形图像渲染


516
00:28:59,039 --> 00:29:02,176 line:-1
能够正确渲染广色域内容


517
00:29:02,242 --> 00:29:03,844 line:-1
（屏外绘制）


518
00:29:03,911 --> 00:29:07,314 line:-2
你可以在app中
使用UIGraphicsImageRenderer


519
00:29:07,381 --> 00:29:09,183 line:-1
渲染到屏幕外的地方


520
00:29:09,249 --> 00:29:12,886 line:-2
然后使用UIImageView
在屏幕上进行高效显示


521
00:29:15,088 --> 00:29:17,491 line:-2
与我们在CALayer
后备存储器中


522
00:29:17,824 --> 00:29:20,494 line:-1
引入的优化类似


523
00:29:20,561 --> 00:29:23,697 line:-2
我们也使
UIGraphicsImageRenderer


524
00:29:23,764 --> 00:29:26,867 line:-1
能够动态增长其图像缓冲区的大小


525
00:29:26,934 --> 00:29:31,038 line:-1
这取决于你在操作块中执行的操作


526
00:29:33,974 --> 00:29:37,811 line:-2
如果你在iOS 12之前的
操作系统上运行代码


527
00:29:38,145 --> 00:29:39,746 line:-2
你可以使用
UIGraphicsImageRendererFormat


528
00:29:39,813 --> 00:29:40,948 line:-1
中的


529
00:29:41,014 --> 00:29:44,384 line:-2
prefersExtendedRange属性
来告诉UIKit


530
00:29:44,451 --> 00:29:46,954 line:-1
你是否计划绘制广色域内容


531
00:29:50,524 --> 00:29:52,860 line:-1
但这里有一个中间地带


532
00:29:53,393 --> 00:29:57,431 line:-2
如果你主要将图像渲染
到图形图像渲染器中


533
00:29:58,232 --> 00:30:00,567 line:-1
该图像可能使用


534
00:30:00,634 --> 00:30:05,105 line:-1
超出SRGB色域的色彩空间值


535
00:30:06,073 --> 00:30:09,243 line:-1
但实际上并不需要更大的元素


536
00:30:09,309 --> 00:30:10,444 line:-1
来存储这些信息


537
00:30:10,944 --> 00:30:12,646 line:-1
UIImage有一个可以用来获取一个预构建的


538
00:30:13,113 --> 00:30:15,649 line:-2
UIGraphicsImageRendererFormat
对象的


539
00:30:15,716 --> 00:30:21,088 line:-2
image renderer format属性
该对象用于在重新渲染图像时


540
00:30:21,154 --> 00:30:22,656 line:-1
进行最优化存储


541
00:30:26,960 --> 00:30:28,362 line:-1
最后我们将谈一些


542
00:30:28,428 --> 00:30:31,999 line:-1
有关如何在你的app中集成


543
00:30:32,065 --> 00:30:35,068 line:-2
我们在iOS中提供的先进
CPU和GPU技术的话题


544
00:30:37,504 --> 00:30:40,440 line:-2
如果你需要使用
Core Image


545
00:30:40,507 --> 00:30:44,945 line:-1
对你的图片实时进行大量的高级处理


546
00:30:45,012 --> 00:30:45,913 line:-1
（高级图像效果）


547
00:30:45,979 --> 00:30:48,182 line:-2
Core Image
是这样一个框架


548
00:30:48,248 --> 00:30:51,285 line:-1
它允许你创建处理图像的配方


549
00:30:51,652 --> 00:30:54,521 line:-1
并在CPU或GPU上进行处理


550
00:30:55,722 --> 00:31:00,360 line:-2
如果你从CIImage创建一个
UIImage并将其交给UIImageView


551
00:31:00,727 --> 00:31:05,232 line:-2
UIImageView将负责
在GPU上执行该配方


552
00:31:06,733 --> 00:31:07,701 line:-1
这非常高效 并且它可以


553
00:31:07,768 --> 00:31:10,771 line:-2
保持CPU空闲从而能够
在你的app中执行其他工作


554
00:31:12,139 --> 00:31:14,775 line:-2
为了使用它
像平常一样创建你的CIImage


555
00:31:15,209 --> 00:31:17,778 line:-2
然后调用UIImage
CIImage初始程序


556
00:31:18,512 --> 00:31:19,746 line:-1
（高级图像处理）


557
00:31:19,813 --> 00:31:21,481 line:-1
iOS上还有其他用于处理和渲染


558
00:31:21,548 --> 00:31:25,052 line:-1
图形内容的高级框架


559
00:31:25,319 --> 00:31:29,823 line:-2
包括Metal Vision
和Accelerate


560
00:31:31,158 --> 00:31:35,195 line:-2
这些框架中常见的数据类型之一
是CVPixelBuffer


561
00:31:36,563 --> 00:31:40,801 line:-2
这是一种数据类型
其用来表示在CPU或GPU上


562
00:31:40,868 --> 00:31:43,437 line:-2
正在使用的缓冲区
或尚未使用的缓冲区


563
00:31:44,605 --> 00:31:46,340 line:-1
构建这些像素缓冲区之一时


564
00:31:46,740 --> 00:31:48,575 line:-1
确保使用最好的初始化程序


565
00:31:48,642 --> 00:31:51,678 line:-1
即最接近你手头表述的那个


566
00:31:52,746 --> 00:31:55,115 line:-1
不要展开任何解码工作


567
00:31:55,182 --> 00:31:58,051 line:-1
这些工作已经由现有的


568
00:31:58,118 --> 00:32:00,287 line:-2
UIImage
或CGImage实现完成


569
00:32:01,688 --> 00:32:04,791 line:-2
在CPU和GPU之间移动数据时
要格外小心


570
00:32:04,858 --> 00:32:07,427 line:-2
这样你就不会仅在两者之间
进行权衡工作


571
00:32:07,494 --> 00:32:10,097 line:-1
实际上你可以让它们并行执行


572
00:32:11,598 --> 00:32:14,201 line:-2
最后请关注一下
Accelerate框架


573
00:32:14,668 --> 00:32:17,337 line:-1
如何正确格式化待处理缓冲区的


574
00:32:17,771 --> 00:32:20,207 line:-2
Accelerate
和simd演讲


575
00:32:22,809 --> 00:32:24,845 line:-1
总结一下几个关键点


576
00:32:25,879 --> 00:32:28,615 line:-1
在表视图和集合视图中实现预取


577
00:32:28,682 --> 00:32:31,485 line:-2
以便可以事先完成一些工作
并避免粘连


578
00:32:33,120 --> 00:32:37,724 line:-2
确保你没有关闭UIKit提供的
任何优化


579
00:32:37,791 --> 00:32:41,361 line:-2
这些优化可以减少与视图关联的
后备存储器大小


580
00:32:42,095 --> 00:32:43,764 line:-1
（总结）


581
00:32:43,830 --> 00:32:46,266 line:-1
如果你将图像与app捆绑在一起


582
00:32:46,333 --> 00:32:48,168 line:-1
将其存储在素材目录中


583
00:32:49,102 --> 00:32:51,905 line:-2
不要将其存储在与你的app
相关联的文件中


584
00:32:53,841 --> 00:32:56,743 line:-2
最后 如果你以不同大小
渲染相同的图标


585
00:32:57,578 --> 00:33:00,514 line:-2
不要过分依赖
“保留矢量数据”复选框


586
00:33:03,183 --> 00:33:06,353 line:0
欲了解更多信息
有许多相关的演讲


587
00:33:06,420 --> 00:33:12,025 line:0
包括一个调查性能问题的演讲


588
00:33:12,726 --> 00:33:16,230 line:0
明天和星期五我们还会有实验室讨论


589
00:33:16,296 --> 00:33:18,665 line:0
如果你有任何问题
请来实验室找我们


590
00:33:19,833 --> 00:33:20,901 line:-1
感谢你的收看

