1
00:00:16,783 --> 00:00:22,089 line:0
（用Metal框架加速机器学习
演讲609）


2
00:00:29,830 --> 00:00:31,265 line:-1
大家下午好


3
00:00:31,698 --> 00:00:34,668 line:-2
欢迎来到“Metal框架
加速机器学习”


4
00:00:35,469 --> 00:00:37,171 line:-1
我是Anna Tikhonova


5
00:00:37,237 --> 00:00:39,306 line:-1
我是GPU软件团队的工程师


6
00:00:42,943 --> 00:00:44,678 line:-1
Metal性能着色器框架


7
00:00:44,745 --> 00:00:45,979 line:-1
是基于Metal而建立


8
00:00:46,580 --> 00:00:48,949 line:-1
为GPU提供更快速的原语


9
00:00:49,016 --> 00:00:51,785 line:-1
并已为iOS和macOS优化


10
00:00:52,819 --> 00:00:55,155 line:-1
我们提供的原语包括图像处理


11
00:00:55,455 --> 00:00:57,558 line:-1
线性代数和机器学习


12
00:00:58,625 --> 00:01:02,396 line:-2
我们曾讲过大量有关推理的内容
在往年的WWDC演讲中


13
00:01:02,796 --> 00:01:04,364 line:-1
这里我只是再强调一下


14
00:01:06,433 --> 00:01:09,369 line:-1
今年新增的训练支持


15
00:01:09,570 --> 00:01:11,038 line:-1
iOS和macOS


16
00:01:15,909 --> 00:01:16,810 line:-1
谢谢


17
00:01:18,612 --> 00:01:21,315 line:0
还有更快速的光线追踪


18
00:01:21,381 --> 00:01:22,282 line:0
添加到了平台


19
00:01:22,649 --> 00:01:26,353 line:0
我们为此做过一整场专题演讲
就在本周初


20
00:01:26,653 --> 00:01:29,122 line:0
主题是
“Metal框架加速光线追踪”


21
00:01:30,057 --> 00:01:33,293 line:-1
演讲的视频很快就会上线


22
00:01:34,294 --> 00:01:37,331 line:-1
今天演讲的主要内容是关于机器学习


23
00:01:37,764 --> 00:01:39,099 line:-1
特别是训练


24
00:01:42,102 --> 00:01:43,871 line:-1
我提过训练和推断


25
00:01:44,705 --> 00:01:47,307 line:0
深度学习算法由这两个阶段构成


26
00:01:47,608 --> 00:01:49,510 line:0
第一个阶段是训练阶段


27
00:01:50,511 --> 00:01:53,213 line:0
举个例子 比如训练一个模型


28
00:01:53,714 --> 00:01:55,749 line:0
对图像分类


29
00:01:56,183 --> 00:01:58,519 line:0
比如猫、狗、长颈鹿等等


30
00:01:59,987 --> 00:02:03,156 line:0
那么为了训练模型能识别猫


31
00:02:03,223 --> 00:02:06,493 line:0
就要输入大量标签为猫的图片


32
00:02:07,060 --> 00:02:10,097 line:0
再以同样的方法
输入兔子和其他动物的图片


33
00:02:10,163 --> 00:02:11,999 line:0
让模型去识别


34
00:02:14,101 --> 00:02:17,337 line:0
训练的计算量很大而且是很耗时的


35
00:02:17,404 --> 00:02:18,505 line:0
迭代进程


36
00:02:19,339 --> 00:02:21,842 line:0
训练的结果是已训练的参数


37
00:02:24,745 --> 00:02:27,080 line:0
已训练的参数是下一阶段的必备条件


38
00:02:27,147 --> 00:02:28,048 line:0
也就是推断阶段


39
00:02:28,782 --> 00:02:31,618 line:0
这个阶段中 模型会看到一张新图


40
00:02:31,685 --> 00:02:33,086 line:0
之前从未见过


41
00:02:33,153 --> 00:02:35,822 line:0
它需要对其分类
以已训练的参数为基础


42
00:02:36,223 --> 00:02:37,191 line:-1
这是只猫


43
00:02:38,292 --> 00:02:40,427 line:-1
GPU加速现在可以


44
00:02:40,494 --> 00:02:42,896 line:-1
同时用于训练阶段和推断阶段


45
00:02:45,832 --> 00:02:47,334 line:-1
但在讲训练之前


46
00:02:47,401 --> 00:02:51,371 line:-2
我要先谈谈CNN推断优化
这是我们今年添加的内容


47
00:02:51,939 --> 00:02:55,042 line:-1
现在FP16计算可以支持


48
00:02:55,108 --> 00:02:58,111 line:-1
卷积和卷积转置原语


49
00:02:58,946 --> 00:03:03,250 line:-2
Apple A11 Bionic
GPU有此新功能


50
00:03:04,351 --> 00:03:08,322 line:-1
我们发现FP16计算推断


51
00:03:08,655 --> 00:03:10,958 line:-1
就精度而言完全足够


52
00:03:11,892 --> 00:03:14,161 line:-1
适合常用的神经网络


53
00:03:15,562 --> 00:03:20,534 line:-1
FP16计算更为精确还十分省电


54
00:03:20,601 --> 00:03:24,204 line:-1
所以请一定要把它运用到推断中


55
00:03:25,572 --> 00:03:29,176 line:-2
这个例子展示了
如何将FP16计算


56
00:03:29,243 --> 00:03:30,744 line:-1
用于卷积原语


57
00:03:30,811 --> 00:03:34,181 line:-2
你只需设置
accumulatorPrecisionOption属性


58
00:03:36,617 --> 00:03:40,854 line:-2
现在我们开始深入讲解
本场演讲的主题


59
00:03:41,188 --> 00:03:42,422 line:-1
神经网络训练


60
00:03:43,156 --> 00:03:45,792 line:-1
我们从卷积神经网络讲起


61
00:03:48,929 --> 00:03:52,332 line:-2
这里有一个简单的
手写数字识别网络


62
00:03:53,233 --> 00:03:56,069 line:-1
以手写数字图像为输入


63
00:03:56,870 --> 00:03:59,373 line:-1
放入十个类中的一个


64
00:03:59,439 --> 00:04:00,507 line:-1
从0到9


65
00:04:01,608 --> 00:04:04,711 line:-2
这个例子中
图片被正确地归类为


66
00:04:04,778 --> 00:04:06,580 line:-1
数字7的图片


67
00:04:09,316 --> 00:04:13,120 line:0
推断时用已训练的参数
初始化网络


68
00:04:13,954 --> 00:04:16,557 line:0
已训练的参数添加权重


69
00:04:16,623 --> 00:04:19,293 line:0
到卷积和全连接原语


70
00:04:20,327 --> 00:04:23,730 line:0
训练算法的目的
是计算已训练的参数


71
00:04:23,797 --> 00:04:28,535 line:0
让网络可以用它们让输入数据
在推断时修正输出


72
00:04:30,370 --> 00:04:33,407 line:-2
训练进程开始的时候
没有任何权重


73
00:04:33,473 --> 00:04:34,608 line:-1
我们需要计算


74
00:04:35,075 --> 00:04:36,176 line:-1
所以第一步


75
00:04:36,543 --> 00:04:39,479 line:-2
初始化权重
用较小的随机的数字


76
00:04:40,013 --> 00:04:41,682 line:-2
现在可以开始
训练网络了


77
00:04:42,149 --> 00:04:45,319 line:-2
这里列出了
训练过程中的所有步骤


78
00:04:48,121 --> 00:04:49,957 line:-1
训练是一个迭代进程


79
00:04:50,023 --> 00:04:53,126 line:-2
每次训练的迭代
分为四步


80
00:04:53,994 --> 00:04:55,929 line:-1
第一步是正向传播


81
00:04:55,996 --> 00:04:59,166 line:-2
这时候将输入
传递给网络


82
00:04:59,233 --> 00:05:00,367 line:-1
产生输出


83
00:05:01,068 --> 00:05:02,536 line:-1
类似推断进程


84
00:05:04,238 --> 00:05:05,939 line:-1
然后计算缺失


85
00:05:06,573 --> 00:05:08,876 line:-1
损失直观地衡量了


86
00:05:08,942 --> 00:05:11,245 line:-2
网络输出值
与标准值之间的误差


87
00:05:13,313 --> 00:05:16,450 line:-2
训练算法的目标
是最小化损失


88
00:05:18,819 --> 00:05:20,854 line:0
下一步是梯度传播


89
00:05:21,488 --> 00:05:24,558 line:0
就是反向传播
网络输出相对


90
00:05:24,825 --> 00:05:27,361 line:0
标准值的误差
给神经网络


91
00:05:27,794 --> 00:05:29,096 line:0
再更新权重


92
00:05:29,963 --> 00:05:33,267 line:0
理念是随着训练不断进行


93
00:05:33,333 --> 00:05:35,202 line:0
网络会越来越准确


94
00:05:35,269 --> 00:05:38,906 line:0
所以最好能用
输入修正输出


95
00:05:39,806 --> 00:05:41,675 line:-1
从而最小化误差


96
00:05:43,210 --> 00:05:44,478 line:-1
以上是概述


97
00:05:44,778 --> 00:05:47,748 line:-2
下面分别看看
每个步骤的具体内容


98
00:05:50,350 --> 00:05:53,654 line:-2
正向传播指
向网络正向传递信息


99
00:05:54,054 --> 00:05:55,155 line:0
以计算输出


100
00:05:56,190 --> 00:05:58,692 line:0
如你所见
在这个训练场景下


101
00:05:59,092 --> 00:06:00,627 line:0
网络的表现不是很好


102
00:06:01,795 --> 00:06:03,764 line:0
结果明显是错误的


103
00:06:03,830 --> 00:06:05,098 line:0
为何这么糟糕？


104
00:06:05,566 --> 00:06:06,767 line:0
其实也不意外


105
00:06:06,834 --> 00:06:09,770 line:0
因为初始权重
只是随机的数字


106
00:06:09,837 --> 00:06:12,039 line:0
网络还没有被训练
所以表现不好


107
00:06:13,941 --> 00:06:16,476 line:0
现在要用权重来量化


108
00:06:16,844 --> 00:06:19,646 line:0
网络表现的好坏程度


109
00:06:20,247 --> 00:06:21,849 line:0
我们可以用这个信息


110
00:06:22,349 --> 00:06:25,552 line:0
来提高权重
希望经过多次迭代


111
00:06:25,619 --> 00:06:28,055 line:0
能训练网络
输出更准确的结果


112
00:06:30,257 --> 00:06:32,426 line:0
为了衡量表现如何


113
00:06:32,492 --> 00:06:34,127 line:0
我们需要一个正确答案


114
00:06:34,795 --> 00:06:37,631 line:0
就是标准值
之后我会叫它标签


115
00:06:38,098 --> 00:06:41,502 line:0
它会与图像
一同输入网络


116
00:06:42,236 --> 00:06:44,505 line:0
这个例子中
向量为10个值


117
00:06:44,571 --> 00:06:46,940 line:0
正确类的值为1
类7


118
00:06:47,274 --> 00:06:49,009 line:0
其他类均为0


119
00:06:51,645 --> 00:06:54,548 line:0
网络的输出
就是这十个概率值


120
00:06:54,882 --> 00:06:55,849 line:0
每类给一个值


121
00:06:56,517 --> 00:06:59,052 line:0
在这个训练场景下


122
00:06:59,119 --> 00:07:02,923 line:0
网络输出一个很低的值
给正确答案7


123
00:07:03,490 --> 00:07:06,860 line:0
而把最高值
分配给了9


124
00:07:07,394 --> 00:07:09,930 line:0
因此网络返回的
正确答案是9


125
00:07:11,465 --> 00:07:13,166 line:0
现在把所有信息


126
00:07:13,467 --> 00:07:15,669 line:0
传递给损失原语


127
00:07:18,705 --> 00:07:20,374 line:0
我之前讲过


128
00:07:21,441 --> 00:07:24,811 line:0
损失衡量的差值
是网络输出


129
00:07:25,145 --> 00:07:26,380 line:0
较之标准值的误差


130
00:07:27,548 --> 00:07:30,350 line:0
而训练算法的目标
是最小化误差


131
00:07:32,352 --> 00:07:34,488 line:-2
这时就要需要
图形的下半部分


132
00:07:36,590 --> 00:07:37,724 line:-1
下半部分图形


133
00:07:37,858 --> 00:07:40,060 line:-1
包括梯度原语


134
00:07:40,527 --> 00:07:42,262 line:-1
对应每个正向原语


135
00:07:43,330 --> 00:07:44,431 line:-1
梯度原语


136
00:07:45,098 --> 00:07:47,601 line:-1
计算更新权重所需的梯度


137
00:07:49,937 --> 00:07:51,038 line:-1
损失原语


138
00:07:52,506 --> 00:07:53,941 line:-1
计算第一梯度


139
00:07:54,508 --> 00:07:56,510 line:-2
就是选定的
损失函数的导数


140
00:07:56,577 --> 00:07:57,845 line:-1
基于输出


141
00:07:58,312 --> 00:07:59,646 line:-1
然后将这个梯度


142
00:07:59,980 --> 00:08:01,782 line:-1
反向传播


143
00:08:02,549 --> 00:08:03,717 line:-1
通过网络


144
00:08:04,184 --> 00:08:06,086 line:-1
通过第一个…


145
00:08:06,987 --> 00:08:09,489 line:-1
梯度原语向后传递


146
00:08:09,556 --> 00:08:12,826 line:-2
这个例子中
梯度原语为SoftMax


147
00:08:14,027 --> 00:08:15,495 line:-1
要用到链式法则


148
00:08:15,562 --> 00:08:18,065 line:-1
链式法则允许反向传播梯度


149
00:08:18,131 --> 00:08:19,333 line:-1
通过网络向后走


150
00:08:20,467 --> 00:08:22,302 line:-1
同时计算梯度


151
00:08:22,369 --> 00:08:23,737 line:-1
以更新权重


152
00:08:24,271 --> 00:08:27,374 line:-1
因此权重的增量很小


153
00:08:27,975 --> 00:08:29,276 line:-1
在每次迭代中


154
00:08:31,311 --> 00:08:33,480 line:-1
然后用更新后的权重


155
00:08:33,547 --> 00:08:35,115 line:-1
进行下次训练迭代


156
00:08:35,883 --> 00:08:38,184 line:-1
希望误差值会变小


157
00:08:38,251 --> 00:08:39,753 line:-1
这是我们努力的方向


158
00:08:43,557 --> 00:08:45,692 line:0
实际上
在任何训练场景中


159
00:08:46,326 --> 00:08:48,462 line:0
不可能只处理一张图像


160
00:08:49,062 --> 00:08:52,299 line:0
而是处理
一组或一批图像


161
00:08:52,366 --> 00:08:55,135 line:0
比如32或64的批大小


162
00:08:55,869 --> 00:08:59,439 line:0
还要有相应的一批标签


163
00:08:59,506 --> 00:09:00,674 line:0
用于计算损失


164
00:09:00,741 --> 00:09:03,277 line:0
这个例子里
我们有一批标签


165
00:09:03,343 --> 00:09:06,780 line:0
正确类的值为1
其他为0


166
00:09:09,550 --> 00:09:11,285 line:0
每个训练场景


167
00:09:11,351 --> 00:09:13,620 line:0
会使用不同的批图像


168
00:09:13,687 --> 00:09:16,056 line:0
和相应的一批标签


169
00:09:16,123 --> 00:09:18,859 line:0
现在就来运行
多次训练迭代


170
00:09:21,495 --> 00:09:23,630 line:0
对第一批图像


171
00:09:23,697 --> 00:09:25,032 line:0
做正向传播


172
00:09:25,098 --> 00:09:28,101 line:0
计算损失
然后梯度传播


173
00:09:28,936 --> 00:09:30,037 line:0
再更新权重


174
00:09:30,604 --> 00:09:32,372 line:0
那么第二批呢？


175
00:09:32,439 --> 00:09:34,208 line:0
完全一样的流程


176
00:09:34,274 --> 00:09:36,510 line:0
正向传播
然后计算损失


177
00:09:36,577 --> 00:09:38,679 line:0
梯度传播
再更新权重


178
00:09:40,080 --> 00:09:42,182 line:0
训练迭代过程中


179
00:09:43,016 --> 00:09:45,319 line:0
我们希望网络的损失


180
00:09:45,385 --> 00:09:46,320 line:0
能降低


181
00:09:46,653 --> 00:09:49,323 line:0
网络准确度能提高


182
00:09:49,590 --> 00:09:52,292 line:0
所以继续训练
直到损失降到


183
00:09:52,359 --> 00:09:53,827 line:0
某个阈值以下


184
00:09:54,228 --> 00:09:57,598 line:0
网络的准确度
就达到了理想水平


185
00:09:58,765 --> 00:10:00,834 line:0
这时我们就知道网络已训练


186
00:10:00,901 --> 00:10:03,070 line:0
我们可以用
已训练的参数


187
00:10:03,403 --> 00:10:04,338 line:0
去推断了


188
00:10:04,738 --> 00:10:07,674 line:-1
现在看几个必要步骤


189
00:10:07,741 --> 00:10:11,078 line:-2
Metal性能着色器框架(MPS)
训练神经网络


190
00:10:12,012 --> 00:10:15,549 line:-2
神经网络通常会用
图形抽象来表示


191
00:10:16,116 --> 00:10:19,353 line:-1
MPS中的神经网络就以图形描述


192
00:10:20,888 --> 00:10:23,223 line:-1
第一步就是创建训练图


193
00:10:24,424 --> 00:10:26,326 line:-1
我们要准备好输入数据


194
00:10:26,393 --> 00:10:27,928 line:-1
确定权重


195
00:10:27,995 --> 00:10:29,329 line:-1
然后执行训练图


196
00:10:29,396 --> 00:10:30,864 line:-1
运行正向路径


197
00:10:31,298 --> 00:10:34,768 line:-2
计算损失、梯度传播
再更新权重


198
00:10:35,903 --> 00:10:37,704 line:-1
训练是一个迭代进程


199
00:10:38,639 --> 00:10:41,108 line:-1
训练网络需要多次迭代


200
00:10:41,175 --> 00:10:43,844 line:-2
因此还要知道
什么时候停止训练


201
00:10:44,077 --> 00:10:45,979 line:-1
现在就来研究每个课题的


202
00:10:46,280 --> 00:10:47,314 line:-1
具体内容


203
00:10:47,814 --> 00:10:50,551 line:-1
首先是创建训练图


204
00:10:52,719 --> 00:10:55,956 line:-2
我说过MPS中
神经网络是


205
00:10:56,023 --> 00:10:58,425 line:-2
一个图形
通过神经网络图形API


206
00:10:59,193 --> 00:11:01,161 line:-1
这是可视化的


207
00:11:01,461 --> 00:11:04,031 line:-1
手写数字识别网络


208
00:11:04,665 --> 00:11:06,099 line:-1
这个图形里


209
00:11:06,166 --> 00:11:07,901 line:-1
你能看到图像节点


210
00:11:07,968 --> 00:11:09,303 line:-1
就是白色的小节点


211
00:11:10,904 --> 00:11:13,073 line:-1
图像节点用于数据


212
00:11:13,373 --> 00:11:16,677 line:-1
输入输出和所有中间结果


213
00:11:18,846 --> 00:11:21,949 line:-2
它们描述了不同操作时
数据的移动情况


214
00:11:22,716 --> 00:11:24,585 line:-1
然后处理数据


215
00:11:24,651 --> 00:11:26,220 line:-1
比如卷积或池化


216
00:11:27,087 --> 00:11:29,957 line:-1
以过滤节点表示


217
00:11:30,924 --> 00:11:33,193 line:-1
我们支持所有必要的节点


218
00:11:33,260 --> 00:11:35,829 line:-1
以创建常用的神经网络


219
00:11:37,231 --> 00:11:39,132 line:-1
现在看看怎么简单地


220
00:11:39,199 --> 00:11:40,767 line:-1
使用神经网络图形API


221
00:11:41,702 --> 00:11:46,440 line:0
这个例子就是
如何创建MPSImageNode


222
00:11:46,507 --> 00:11:48,141 line:0
通过神经网络图形API


223
00:11:48,675 --> 00:11:51,011 line:0
这是如何创建卷积节点


224
00:11:51,078 --> 00:11:52,346 line:0
通过图形API


225
00:11:53,380 --> 00:11:55,916 line:0
对于每个正向节点


226
00:11:55,983 --> 00:11:59,386 line:0
提供相应的训练梯度节点


227
00:11:59,720 --> 00:12:02,923 line:0
只要一行代码
就能创建梯度节点


228
00:12:02,990 --> 00:12:04,024 line:0
对应正向节点


229
00:12:04,091 --> 00:12:08,362 line:0
这个例子展示了
如何创建梯度卷积节点


230
00:12:08,428 --> 00:12:09,663 line:0
基于卷积节点


231
00:12:13,100 --> 00:12:14,735 line:-1
现在创建整个图形


232
00:12:16,203 --> 00:12:18,372 line:-1
这里有个很小的网络


233
00:12:18,438 --> 00:12:21,241 line:-2
一个卷积节点
接着一个池化节点


234
00:12:21,308 --> 00:12:22,943 line:-1
随后是另一个卷积节点


235
00:12:23,911 --> 00:12:25,679 line:-1
怎样连接这些节点


236
00:12:26,813 --> 00:12:27,681 line:-1
到图形中？


237
00:12:27,915 --> 00:12:28,949 line:-1
很简单


238
00:12:29,616 --> 00:12:31,685 line:-2
我们将结果节点
不对


239
00:12:32,352 --> 00:12:34,521 line:-1
一个节点的输出图像


240
00:12:34,588 --> 00:12:37,758 line:-2
以源图片形式
传递到后续节点


241
00:12:38,859 --> 00:12:41,528 line:-1
这就形成全连接图形


242
00:12:42,729 --> 00:12:44,731 line:-1
现在创建训练图形


243
00:12:45,766 --> 00:12:48,735 line:-2
首先在图形中
添加损失节点


244
00:12:50,037 --> 00:12:52,005 line:-1
再添加梯度节点


245
00:12:52,072 --> 00:12:54,274 line:-1
我说过 只要一行代码


246
00:12:54,341 --> 00:12:55,943 line:-1
就能创建梯度节点


247
00:12:56,210 --> 00:12:57,978 line:-1
对应正向节点


248
00:12:58,345 --> 00:13:00,380 line:-1
然后跟之前一样连接它们


249
00:13:00,447 --> 00:13:02,616 line:-1
完整的训练图就做好了


250
00:13:05,752 --> 00:13:07,588 line:-1
通过这个例子 你能看到


251
00:13:07,654 --> 00:13:10,524 line:-1
图形API简单易用


252
00:13:11,558 --> 00:13:13,393 line:-1
训练图可以自动做很多事


253
00:13:13,460 --> 00:13:15,495 line:-1
它能处理所有中间结果


254
00:13:16,797 --> 00:13:18,365 line:-1
甚至输出图像


255
00:13:19,166 --> 00:13:22,870 line:-1
它能最小化网络的内存占用


256
00:13:22,936 --> 00:13:26,607 line:-1
通过将所有的中间图像折叠


257
00:13:26,673 --> 00:13:27,808 line:-1
借助Metal堆


258
00:13:28,809 --> 00:13:30,410 line:-1
它还能融合图形节点


259
00:13:30,477 --> 00:13:34,181 line:-2
例如它可以融合
批标准化和网络节点


260
00:13:34,615 --> 00:13:36,416 line:-1
它还能优化away节点


261
00:13:36,717 --> 00:13:39,219 line:-2
比如优化切割
nation节点的方法


262
00:13:40,387 --> 00:13:43,156 line:-1
它还可以自动处理填充


263
00:13:43,223 --> 00:13:44,958 line:-1
管理状态对象


264
00:13:45,025 --> 00:13:46,727 line:-1
这些稍后会讲到


265
00:13:47,561 --> 00:13:49,930 line:-1
所以请好好利用图形API


266
00:13:54,868 --> 00:13:57,104 line:-1
了解如何创建训练图后


267
00:13:57,471 --> 00:14:01,308 line:-2
现在看看
要传递给训练图的输入


268
00:14:02,576 --> 00:14:04,878 line:-1
这里就要讲到编码命令


269
00:14:04,945 --> 00:14:07,414 line:-1
将图形编码到GPU


270
00:14:09,049 --> 00:14:11,818 line:0
我说过 我们不会只发送一张图像


271
00:14:11,885 --> 00:14:13,086 line:0
给每次训练


272
00:14:13,153 --> 00:14:16,323 line:0
我们要处理一组或一批图像


273
00:14:16,523 --> 00:14:18,192 line:0
那么输入数据之一


274
00:14:18,458 --> 00:14:19,760 line:0
就是一批图像


275
00:14:20,794 --> 00:14:23,664 line:0
你一定记得每批图像


276
00:14:23,730 --> 00:14:27,467 line:0
都对应一批标签 用于计算损失


277
00:14:29,770 --> 00:14:33,807 line:0
计算损失的标签
以状态形式传递给训练图


278
00:14:34,174 --> 00:14:37,978 line:0
代码命令也会把一批状态作为输入


279
00:14:38,779 --> 00:14:41,548 line:0
现在来讲讲批和状态


280
00:14:41,882 --> 00:14:43,584 line:0
是什么意思？
首先是批


281
00:14:44,484 --> 00:14:48,188 line:0
批是一组图像或状态


282
00:14:48,255 --> 00:14:51,091 line:0
这是我们今年特地为训练增加的支持


283
00:14:52,092 --> 00:14:56,029 line:0
现在有两个新的MPS类型可用
MPSImageBatch


284
00:14:56,096 --> 00:14:57,731 line:0
和MPSStateBatch


285
00:14:58,565 --> 00:15:01,568 line:0
下面这个例子
告诉你如何用我们的API


286
00:15:01,635 --> 00:15:02,769 line:0
创建单张图像


287
00:15:04,071 --> 00:15:06,773 line:0
用现有的Metal纹理创建图像


288
00:15:08,275 --> 00:15:10,277 line:0
这个例子展示了如何使用


289
00:15:10,577 --> 00:15:14,781 line:0
API创建批图像
再附加一张新图像


290
00:15:14,848 --> 00:15:16,283 line:0
传给训练图


291
00:15:18,485 --> 00:15:20,254 line:-1
状态对象是什么？


292
00:15:21,255 --> 00:15:24,791 line:-1
MPS状态是不透明的数据容器


293
00:15:25,792 --> 00:15:29,096 line:-1
训练中 常要用它捕捉


294
00:15:29,162 --> 00:15:30,264 line:-1
正向节点的状态


295
00:15:31,565 --> 00:15:32,399 line:-1
在调用时


296
00:15:32,766 --> 00:15:36,036 line:-1
所以它之后可以用作梯度节点


297
00:15:37,104 --> 00:15:39,706 line:-1
训练图会处理所有状态对象


298
00:15:39,773 --> 00:15:40,807 line:-1
所以作为开发者


299
00:15:40,908 --> 00:15:42,943 line:-1
你一般不用担心状态


300
00:15:43,010 --> 00:15:44,778 line:-1
但了解下工作原理也不错


301
00:15:44,845 --> 00:15:46,680 line:-1
我们用具体例子说明


302
00:15:49,049 --> 00:15:51,885 line:-1
回到上个手写数字识别网络


303
00:15:53,287 --> 00:15:55,722 line:-1
特别注意下退出


304
00:15:55,789 --> 00:15:57,391 line:-1
和退出梯度节点


305
00:16:00,761 --> 00:16:03,864 line:-2
正向退出节点
减少或清零


306
00:16:03,931 --> 00:16:06,533 line:-1
以某个特定概率输入值


307
00:16:07,334 --> 00:16:09,236 line:-1
退出状态对象


308
00:16:09,603 --> 00:16:12,606 line:-1
捕捉正向退出处理的信息


309
00:16:13,574 --> 00:16:16,343 line:0
之后可用于梯度节点


310
00:16:17,044 --> 00:16:18,612 line:0
因为它清零


311
00:16:19,913 --> 00:16:23,717 line:0
输出梯度值的位置


312
00:16:23,784 --> 00:16:25,786 line:0
与正向清零的位置一样


313
00:16:28,889 --> 00:16:31,458 line:-1
所以我说你不用担心状态


314
00:16:31,525 --> 00:16:32,960 line:-1
训练图都会帮你处理


315
00:16:33,794 --> 00:16:35,963 line:-1
但是由于计算损失的标签


316
00:16:36,330 --> 00:16:37,965 line:-1
以状态的形式传递给训练图


317
00:16:39,066 --> 00:16:40,701 line:-1
而且需要用户输入数据


318
00:16:40,767 --> 00:16:43,504 line:-1
就是标准值或正确结果


319
00:16:44,004 --> 00:16:47,007 line:-1
你需要创建一批标签用于计算损失


320
00:16:47,241 --> 00:16:49,209 line:-1
再输入给训练图


321
00:16:50,143 --> 00:16:53,046 line:-2
下面这个例子
将展示如何创建单个标签


322
00:16:53,480 --> 00:16:54,882 line:-1
用于计算损失


323
00:16:55,249 --> 00:16:57,584 line:-1
首先要创建损失数据描述符


324
00:16:57,985 --> 00:17:00,821 line:-1
描述标签数据在内存里的情况


325
00:17:01,722 --> 00:17:05,392 line:-2
然后创建
MPSCNNLossLabel对象


326
00:17:05,459 --> 00:17:06,593 line:-1
用这个描述符


327
00:17:08,161 --> 00:17:10,196 line:-1
然后创建批对象用于训练


328
00:17:10,897 --> 00:17:12,965 line:-1
GPU运行完图形后


329
00:17:13,467 --> 00:17:17,204 line:-1
批标签会包含每张图像的损失值


330
00:17:17,971 --> 00:17:18,839 line:-1
对这批图像


331
00:17:19,039 --> 00:17:20,440 line:-1
你检查这些值


332
00:17:20,507 --> 00:17:22,943 line:-1
或计算一个单一值给整个批


333
00:17:23,010 --> 00:17:24,178 line:-1
再检查那个值


334
00:17:27,714 --> 00:17:29,283 line:-1
那么现在有了训练图


335
00:17:29,349 --> 00:17:32,586 line:-1
下面就是如何输入数据


336
00:17:32,653 --> 00:17:34,755 line:-1
我们看看如何将权重


337
00:17:34,821 --> 00:17:36,523 line:-1
添加到需要权重的图形节点上


338
00:17:39,026 --> 00:17:42,696 line:-1
唯一能添加权重给卷积、全连接


339
00:17:42,763 --> 00:17:46,934 line:0
批归一化和实例正则化节点


340
00:17:47,000 --> 00:17:49,303 line:0
是通过数据源提供器协议


341
00:17:50,938 --> 00:17:53,841 line:0
这个例子就是如何创建卷积节点


342
00:17:53,907 --> 00:17:55,309 line:0
通过数据源提供器


343
00:17:56,176 --> 00:18:00,280 line:0
你需要部署一个符合协议规则的类


344
00:18:00,347 --> 00:18:02,216 line:0
这里就叫做MyWeights


345
00:18:04,685 --> 00:18:08,155 line:-1
数据源提供器在许多方面都很好用


346
00:18:08,589 --> 00:18:09,623 line:-1
比如


347
00:18:09,857 --> 00:18:12,593 line:-1
如果在网络里你有许多卷积节点


348
00:18:13,260 --> 00:18:16,396 line:-1
网络的整体权重会相当可观


349
00:18:16,964 --> 00:18:20,234 line:-1
但我们并不想让所有卷积节点的权重


350
00:18:20,300 --> 00:18:22,035 line:-1
同时存入内存


351
00:18:22,769 --> 00:18:25,506 line:-1
我们希望网络的内存占用


352
00:18:25,572 --> 00:18:26,673 line:-1
越低越好


353
00:18:27,407 --> 00:18:29,576 line:-1
数据源提供器就派上用场了


354
00:18:30,010 --> 00:18:32,679 line:-1
因为它们能及时载入


355
00:18:32,913 --> 00:18:34,681 line:-1
和清除权重数据


356
00:18:35,616 --> 00:18:38,118 line:-1
所以我们加载权重给一个卷积核


357
00:18:38,752 --> 00:18:39,987 line:-1
在处理时


358
00:18:40,053 --> 00:18:43,524 line:-2
清除它们后
才继续下一次卷积


359
00:18:46,260 --> 00:18:48,629 line:-1
MyWeights这样实施


360
00:18:49,429 --> 00:18:50,531 line:0
你要提供


361
00:18:51,198 --> 00:18:53,867 line:0
初始化方法


362
00:18:53,934 --> 00:18:56,103 line:0
拉入内存并做好准备


363
00:18:56,170 --> 00:18:58,672 line:-1
然后训练图会调用load函数


364
00:18:59,139 --> 00:19:01,408 line:0
当purge函数被调用时


365
00:19:01,608 --> 00:19:02,843 line:0
权重就被释放了


366
00:19:03,644 --> 00:19:06,580 line:0
数据源提供器对训练也很重要


367
00:19:06,647 --> 00:19:08,515 line:0
这个我们稍后讲


368
00:19:11,919 --> 00:19:13,654 line:-1
那么我们有了训练图


369
00:19:13,720 --> 00:19:16,423 line:-1
也准备好了输入和具体权重


370
00:19:16,490 --> 00:19:18,559 line:-1
就可以在GPU上执行图形了


371
00:19:20,360 --> 00:19:22,362 line:-1
要在GPU上执行训练图


372
00:19:22,429 --> 00:19:24,831 line:-1
首先要完成Metal设置


373
00:19:25,432 --> 00:19:27,501 line:-1
我们要初始化训练图


374
00:19:27,935 --> 00:19:29,469 line:-1
准备好输入


375
00:19:29,736 --> 00:19:32,072 line:-1
开始在GPU上训练网络吧


376
00:19:35,209 --> 00:19:36,944 line:-1
训练是迭代进程


377
00:19:38,011 --> 00:19:39,780 line:-1
因此要设置训练回路


378
00:19:40,581 --> 00:19:44,117 line:-2
通常我们要执行训练图
经过几个轮次


379
00:19:44,885 --> 00:19:47,287 line:-1
轮次次数是总次数…


380
00:19:48,088 --> 00:19:50,958 line:-1
是对整个数据集的迭代次数


381
00:19:51,792 --> 00:19:54,828 line:-1
每个轮次应该有多个迭代


382
00:19:54,895 --> 00:19:57,764 line:-1
所以迭代的次数是图像总数


383
00:19:57,831 --> 00:20:01,268 line:-2
在数据集中
除以批大小32或64


384
00:20:02,236 --> 00:20:04,805 line:-1
现在我们来看每次训练迭代


385
00:20:07,107 --> 00:20:08,609 line:-1
每次训练迭代中


386
00:20:09,910 --> 00:20:11,912 line:-1
我们对一批图像编码用于训练


387
00:20:13,146 --> 00:20:16,450 line:-1
但我们不想让CPU等GPU


388
00:20:16,517 --> 00:20:20,020 line:-1
跑完一次训练图


389
00:20:20,087 --> 00:20:21,421 line:-1
处理一批图像


390
00:20:21,755 --> 00:20:25,526 line:-2
然后CPU才开始编码
commandBuffer


391
00:20:25,592 --> 00:20:26,827 line:-1
给下一次图形运行


392
00:20:27,494 --> 00:20:29,830 line:-1
我们希望CPU和GPU


393
00:20:29,897 --> 00:20:31,031 line:-1
同时工作


394
00:20:31,331 --> 00:20:33,500 line:-1
为此我们要用到双缓冲


395
00:20:34,434 --> 00:20:37,070 line:-2
那么设置中
我们要创建


396
00:20:37,671 --> 00:20:40,474 line:-2
计数信号量
初始值为2


397
00:20:40,541 --> 00:20:44,344 line:-2
这是因为我们只要
2个编码同时运行


398
00:20:45,679 --> 00:20:48,715 line:-2
然后在输入
训练迭代函数时


399
00:20:48,782 --> 00:20:50,717 line:-1
就会调用信号量权重


400
00:20:50,784 --> 00:20:51,952 line:-1
进行自减


401
00:20:52,920 --> 00:20:56,323 line:-1
当计数值减到0


402
00:20:56,390 --> 00:20:58,225 line:-2
就等待
否则就继续


403
00:20:59,593 --> 00:21:00,928 line:-1
之后对图形编码


404
00:21:01,361 --> 00:21:03,564 line:-1
编码命令即刻返回


405
00:21:04,264 --> 00:21:06,333 line:-1
用户指定的回调函数会被调用


406
00:21:06,767 --> 00:21:08,602 line:-1
在GPU完成图形运行的时候


407
00:21:09,369 --> 00:21:11,705 line:-1
这样我们就知道GPU运行完了


408
00:21:12,105 --> 00:21:16,577 line:-1
CPU可以继续为GPU工作编码


409
00:21:17,711 --> 00:21:20,113 line:-2
就是之前在信号量上
等待处理的部分


410
00:21:21,315 --> 00:21:22,816 line:-1
为什么使用双缓冲呢？


411
00:21:22,883 --> 00:21:27,487 line:-2
为什么不能同时对GPU的
多次运行进行编码


412
00:21:28,822 --> 00:21:31,258 line:-1
因为编码命令用时少


413
00:21:31,325 --> 00:21:33,360 line:-1
命令缓冲比运行训练图快


414
00:21:33,660 --> 00:21:36,363 line:-2
所以不会编码
多次训练图执行


415
00:21:36,430 --> 00:21:38,465 line:-1
为了减少内存占用


416
00:21:41,268 --> 00:21:43,837 line:-1
我们讲过了如何执行训练图


417
00:21:43,904 --> 00:21:46,540 line:-1
执行图形时 我们做正向传播


418
00:21:46,607 --> 00:21:49,276 line:-1
计算损失 再梯度传播


419
00:21:49,343 --> 00:21:51,211 line:-1
然后图形会更新权重


420
00:21:51,545 --> 00:21:53,747 line:-1
现在说说权重更新


421
00:21:55,883 --> 00:21:59,353 line:-1
我说过数据源提供器很重要


422
00:21:59,987 --> 00:22:00,921 line:-1
对训练而言


423
00:22:01,488 --> 00:22:04,758 line:-1
所有权重更新都使用可选的更新方法


424
00:22:04,825 --> 00:22:06,527 line:0
通过数据源提供器


425
00:22:07,761 --> 00:22:10,497 line:0
图形自动调用更新函数


426
00:22:11,098 --> 00:22:13,567 line:0
那么更新权重的步骤都有哪些呢？


427
00:22:13,634 --> 00:22:14,635 line:0
来看一下


428
00:22:17,037 --> 00:22:19,940 line:-1
回想在梯度传播阶段的梯度计算


429
00:22:20,007 --> 00:22:22,643 line:-1
在每个训练场景


430
00:22:22,709 --> 00:22:24,077 line:-1
添加少许增量给权重


431
00:22:25,479 --> 00:22:27,481 line:-1
如何将增量分配给权重


432
00:22:27,548 --> 00:22:30,017 line:-1
由优化器决定


433
00:22:30,584 --> 00:22:33,520 line:-1
它只是个函数将原来的权重


434
00:22:33,587 --> 00:22:35,455 line:-1
和计算过的梯度作为输入


435
00:22:35,923 --> 00:22:39,193 line:-1
输出更新后的权重


436
00:22:41,228 --> 00:22:43,730 line:-1
优化器要在更新函数中使用


437
00:22:43,797 --> 00:22:45,032 line:-1
在数据源提供器内


438
00:22:45,999 --> 00:22:47,835 line:-1
我们也支持几种不同的变体


439
00:22:47,901 --> 00:22:51,371 line:-2
来更新GPU权重
包括Adam


440
00:22:51,438 --> 00:22:54,374 line:-2
StochasticGradientDescent
和RMSProp


441
00:22:54,842 --> 00:22:59,346 line:-2
你甚至可以自定义
权重更新步骤


442
00:22:59,913 --> 00:23:03,650 line:-2
那么就来看看
如何在MPS中使用优化器


443
00:23:06,320 --> 00:23:09,289 line:-2
你记得数据源提供器
有个init函数


444
00:23:09,656 --> 00:23:11,959 line:-1
这里就是创建优化器的地方


445
00:23:12,025 --> 00:23:13,894 line:-1
因为你只需要创建一次


446
00:23:15,295 --> 00:23:17,431 line:-1
现在看看如何执行


447
00:23:17,497 --> 00:23:18,498 line:-1
更新函数


448
00:23:19,533 --> 00:23:20,634 line:-1
更新函数


449
00:23:20,901 --> 00:23:24,104 line:-2
接收源状态
和梯度状态为输入


450
00:23:26,173 --> 00:23:28,509 line:-1
源状态包含原始权重


451
00:23:28,575 --> 00:23:31,078 line:-2
梯度状态
包含计算过的梯度


452
00:23:31,678 --> 00:23:34,081 line:-2
现在就能用这个数据
编码优化器


453
00:23:34,548 --> 00:23:37,484 line:-1
最后一步是将源状态返回


454
00:23:37,551 --> 00:23:39,253 line:-1
其中是更新后的权重


455
00:23:39,520 --> 00:23:40,554 line:-1
很简单吧


456
00:23:43,657 --> 00:23:45,926 line:-1
现在还有最后一步


457
00:23:46,360 --> 00:23:48,395 line:-1
我说过 训练时迭代进程


458
00:23:48,462 --> 00:23:51,198 line:-1
训练网络需要多次迭代


459
00:23:52,766 --> 00:23:54,701 line:-1
你要知道何时停止训练


460
00:23:55,202 --> 00:23:58,438 line:-2
现在就来讨论下
这个决定应该如何做


461
00:23:58,505 --> 00:24:00,140 line:-1
以训练循环为环境


462
00:24:03,343 --> 00:24:05,078 line:-1
这是训练回路


463
00:24:05,145 --> 00:24:07,681 line:-2
正在训练神经网络
包含几个轮次


464
00:24:09,149 --> 00:24:13,253 line:-2
为确定何时停止训练
需要一个测试图集


465
00:24:13,320 --> 00:24:18,025 line:-1
测试图集内的图像不是用于训练


466
00:24:18,091 --> 00:24:21,595 line:-2
只用于评估
网络的准确度


467
00:24:22,362 --> 00:24:26,066 line:-2
每个轮次后
你可以选择等待图形


468
00:24:26,133 --> 00:24:29,169 line:-2
…等待GPU
停止运行图形


469
00:24:29,803 --> 00:24:33,140 line:-1
然后使用当前的已训练的参数


470
00:24:33,740 --> 00:24:35,676 line:-1
初始化推断网络


471
00:24:36,877 --> 00:24:39,880 line:-2
然后在测试图集上
运行推断网络


472
00:24:40,380 --> 00:24:41,949 line:-1
你可以选择停止训练


473
00:24:42,249 --> 00:24:44,852 line:-2
当测试集显示
网络精确度


474
00:24:45,185 --> 00:24:46,453 line:-1
达到某个水平时


475
00:24:50,023 --> 00:24:52,359 line:-1
我们已经讨论过所有步骤


476
00:24:52,659 --> 00:24:55,596 line:-1
关于在MPS训练神经网络


477
00:24:56,063 --> 00:24:56,997 line:-1
是时候展示一下了


478
00:24:58,632 --> 00:25:01,768 line:-1
平台状态汇总中提过


479
00:25:02,736 --> 00:25:05,405 line:-1
Metal性能着色器框架可以驱动


480
00:25:06,340 --> 00:25:09,076 line:-2
Core ML、Create ML
和Turi Create


481
00:25:10,277 --> 00:25:13,180 line:-2
Turi Create
是一款简单易用


482
00:25:13,814 --> 00:25:17,718 line:-2
灵活且高性能的工具组
用于创建CoreML模型


483
00:25:18,352 --> 00:25:21,655 line:-2
以完成一些任务
如图像分类


484
00:25:21,722 --> 00:25:25,058 line:-1
对象检测和推荐等等


485
00:25:25,325 --> 00:25:27,127 line:-2
有关Turi Create的
更多信息


486
00:25:27,594 --> 00:25:30,731 line:-2
请查看“Turi Create
指南”的演讲视频


487
00:25:32,266 --> 00:25:33,534 line:-1
我们准备了一个演示


488
00:25:34,034 --> 00:25:38,505 line:-2
用一个…
训练一个对象检测网络


489
00:25:39,006 --> 00:25:41,942 line:-2
通过MPS驱动的
Turi Create完成


490
00:25:43,043 --> 00:25:45,479 line:-1
平台状态汇总中提到过


491
00:25:46,013 --> 00:25:49,116 line:-1
用MPS的速度比不用快9倍


492
00:25:50,117 --> 00:25:51,685 line:-1
对象检查网络


493
00:25:52,152 --> 00:25:55,155 line:-1
在被识别的对象周围绘制边框


494
00:26:01,328 --> 00:26:02,429 line:-1
这个演示中


495
00:26:04,865 --> 00:26:08,235 line:-2
我用的MacBook Pro
连接了外部GPU


496
00:26:09,870 --> 00:26:13,006 line:-2
Turi Create
在MacBook Pro上运行


497
00:26:13,407 --> 00:26:17,978 line:-1
外部GPU用MPS训练网络


498
00:26:18,946 --> 00:26:21,949 line:-2
这个例子可以很好地演示
如何使用外部GPU


499
00:26:22,015 --> 00:26:24,585 line:-2
提高MacBook Pro的
计算能力


500
00:26:25,285 --> 00:26:28,288 line:-2
我们使用的外部GPU
是AMD Vega GPU


501
00:26:29,356 --> 00:26:30,524 line:-1
在演示配置中


502
00:26:30,591 --> 00:26:32,526 line:-2
我已经导入
Turi Create


503
00:26:32,826 --> 00:26:36,129 line:-2
并提前加载了
对象检测网络


504
00:26:36,196 --> 00:26:37,464 line:-1
还有一个训练数据集


505
00:26:37,865 --> 00:26:39,066 line:-1
那么现在开始


506
00:26:40,501 --> 00:26:42,669 line:-1
训练网络用十次迭代


507
00:26:44,872 --> 00:26:46,940 line:-1
现在整个对象检测网络


508
00:26:47,007 --> 00:26:50,344 line:-2
所有的原语
优化器和权重更新方法


509
00:26:52,379 --> 00:26:54,748 line:-1
所有的都在外部GPU上运行


510
00:26:58,185 --> 00:27:00,554 line:-1
好了 十次训练迭代已完成


511
00:27:01,288 --> 00:27:03,724 line:-2
也许十次迭代不足以完成
该网络的训练


512
00:27:03,790 --> 00:27:05,559 line:-1
但在此我们就这样吧


513
00:27:06,059 --> 00:27:07,861 line:-1
我现在要做的


514
00:27:07,928 --> 00:27:11,131 line:-1
是加载一个提前训练过的网络


515
00:27:11,365 --> 00:27:12,966 line:-1
用来运行测试图集


516
00:27:13,033 --> 00:27:14,668 line:-1
展示部分结果


517
00:27:14,735 --> 00:27:15,869 line:-1
看一下


518
00:27:18,372 --> 00:27:20,274 line:-1
好了 这是香蕉


519
00:27:20,340 --> 00:27:22,276 line:-1
分类十分正确


520
00:27:22,576 --> 00:27:24,044 line:-1
而且画上了边框


521
00:27:24,945 --> 00:27:28,715 line:-2
这么美好的早餐
一杯咖啡和一个牛角包


522
00:27:29,216 --> 00:27:31,652 line:-1
还有一枚不好看的鸡蛋


523
00:27:34,321 --> 00:27:36,423 line:-2
以上就是
Turi Create的演示


524
00:27:43,463 --> 00:27:44,631 line:-1
谢谢大家


525
00:27:47,534 --> 00:27:51,371 line:-2
现在换个话题
谈谈递归神经网络的训练


526
00:27:52,339 --> 00:27:55,576 line:-2
首先简单讲讲
什么是递归神经网络


527
00:27:57,211 --> 00:28:00,247 line:0
卷积神经网络的一大缺陷


528
00:28:00,314 --> 00:28:04,384 line:0
是它们无法记忆之前发生的事情


529
00:28:05,319 --> 00:28:06,620 line:0
它们可以接收一个输入


530
00:28:06,687 --> 00:28:10,324 line:0
例如图像
然后产生一个输出


531
00:28:10,390 --> 00:28:13,527 line:0
例如一组概率值定义图像内容


532
00:28:16,630 --> 00:28:17,965 line:0
RNN就不一样


533
00:28:19,066 --> 00:28:19,900 line:0
它能记忆


534
00:28:19,967 --> 00:28:23,804 line:0
它们善于处理
连续的输入和输出


535
00:28:24,705 --> 00:28:27,107 line:0
比如它们可以用一组概率值


536
00:28:27,174 --> 00:28:28,709 line:0
也就是图像内容


537
00:28:29,243 --> 00:28:30,878 line:0
CNN产生的结果


538
00:28:31,345 --> 00:28:33,313 line:0
然后产生一序列输出


539
00:28:33,580 --> 00:28:36,683 line:0
就是一序列文字
作图片的说明


540
00:28:38,418 --> 00:28:40,787 line:0
它们也可用一组输入


541
00:28:40,854 --> 00:28:44,224 line:0
比如文字序列就是一个句子


542
00:28:44,525 --> 00:28:46,260 line:0
产生一组输出


543
00:28:46,860 --> 00:28:51,064 line:0
句子没变
但被翻译为另一种语言


544
00:28:51,131 --> 00:28:52,699 line:0
比如俄语或芬兰语


545
00:28:54,868 --> 00:28:57,704 line:-1
我们支持几个不同的RNN


546
00:28:58,438 --> 00:28:59,973 line:-1
最常用的一个


547
00:29:00,040 --> 00:29:02,376 line:-1
是长短期记忆RNN


548
00:29:02,442 --> 00:29:03,744 line:-1
简称LSTM


549
00:29:04,611 --> 00:29:06,847 line:-1
去年WWDC演讲中


550
00:29:06,914 --> 00:29:10,150 line:-2
我们讲过大量关于
LSTM门结构的内容


551
00:29:10,284 --> 00:29:13,153 line:-1
演示过LSTM推断过程


552
00:29:13,754 --> 00:29:17,991 line:-2
所以请查看那场演讲
了解更多关于LSTM推断的内容


553
00:29:19,593 --> 00:29:22,229 line:-1
今年新增的训练支持


554
00:29:22,296 --> 00:29:24,231 line:-1
所有这些RNN


555
00:29:25,165 --> 00:29:26,433 line:-1
本场演讲中


556
00:29:26,600 --> 00:29:29,303 line:-1
我会讲到LSTM的训练


557
00:29:32,606 --> 00:29:34,074 line:-1
看个具体例子


558
00:29:34,708 --> 00:29:37,110 line:-1
这是一个活动分类网络


559
00:29:37,744 --> 00:29:40,480 line:-1
以动作感官数据为输入


560
00:29:40,547 --> 00:29:44,985 line:-2
就是读取传感器数据
比如加速传感器或陀螺仪


561
00:29:45,619 --> 00:29:47,287 line:-1
网络然后使用这些数据


562
00:29:47,721 --> 00:29:50,691 line:-1
识别用户所做的运动


563
00:29:51,124 --> 00:29:54,061 line:-1
比如我们想确定用户是在骑行


564
00:29:54,361 --> 00:29:55,929 line:-1
滑雪还是散步


565
00:29:59,132 --> 00:30:01,201 line:-1
你看到网络的


566
00:30:02,135 --> 00:30:03,537 line:-1
配置很有趣


567
00:30:03,604 --> 00:30:08,175 line:-1
它含有一系列CNN原语


568
00:30:08,242 --> 00:30:10,244 line:-1
随后是LSTM原语


569
00:30:10,310 --> 00:30:12,312 line:-1
再后面是更多的CNN原语


570
00:30:12,579 --> 00:30:14,648 line:-2
为什么这样设置？
我们来一窥究竟


571
00:30:16,984 --> 00:30:19,553 line:-1
尽管输入的是感官数据


572
00:30:20,487 --> 00:30:23,156 line:-1
但显示的是一批1D图像


573
00:30:23,223 --> 00:30:24,291 line:-1
6个特征通道


574
00:30:24,358 --> 00:30:28,128 line:-2
一个特征通道
用于读取加速传感器


575
00:30:28,195 --> 00:30:29,663 line:-1
和陀螺仪上的数据


576
00:30:30,631 --> 00:30:33,967 line:-1
每张1D图像为2000像素


577
00:30:34,034 --> 00:30:37,171 line:-1
你可以将它们当作即时样本


578
00:30:37,738 --> 00:30:40,474 line:-1
因为我们要识别的动作


579
00:30:40,541 --> 00:30:41,775 line:-1
是随时发生的


580
00:30:44,645 --> 00:30:48,415 line:-2
然后通过1D卷积原语
传递这些图像


581
00:30:49,283 --> 00:30:53,820 line:-1
它将2000个样本压缩到20个


582
00:30:56,123 --> 00:30:58,292 line:-1
但它要占用几个特征通道


583
00:30:58,358 --> 00:31:01,328 line:-2
这样就不会丢失
数据中的任何特征


584
00:31:03,230 --> 00:31:05,832 line:-1
然后新的数据图像


585
00:31:06,133 --> 00:31:09,303 line:-2
被传递给LSTM原语
是长度为20的序列


586
00:31:10,404 --> 00:31:12,406 line:-1
然后运行20个LSTM迭代


587
00:31:12,906 --> 00:31:15,776 line:-2
于是LSTM处理的
是长度为20的序列


588
00:31:15,843 --> 00:31:17,077 line:-1
而不是2000


589
00:31:17,144 --> 00:31:20,514 line:-1
而且是更高级的数据特征表达


590
00:31:22,549 --> 00:31:24,685 line:-1
后面还有几个CNN原语


591
00:31:25,419 --> 00:31:28,355 line:-1
精细化数据特征


592
00:31:29,389 --> 00:31:32,893 line:-2
序列的最后一个原语
是SoftMax


593
00:31:33,193 --> 00:31:36,263 line:-1
分配概率值给不同的动作类别


594
00:31:36,330 --> 00:31:37,731 line:-1
这就是网络的输出


595
00:31:38,632 --> 00:31:40,901 line:-1
现在看看怎样训练它


596
00:31:42,202 --> 00:31:44,938 line:-1
我们还是需要一个损失原语


597
00:31:45,005 --> 00:31:46,507 line:-1
将网络的输出


598
00:31:46,573 --> 00:31:48,008 line:-1
和标签作为输入


599
00:31:48,542 --> 00:31:50,410 line:-1
然后是下半部分图形


600
00:31:51,111 --> 00:31:54,481 line:-1
在下半部分还是梯度原语


601
00:31:54,548 --> 00:31:56,350 line:-1
对应正向原语


602
00:31:56,416 --> 00:31:58,218 line:-1
包括LSTM原语


603
00:31:59,052 --> 00:32:00,287 line:-1
那么训练


604
00:32:01,722 --> 00:32:04,224 line:-1
先是运行网络正向传播


605
00:32:04,825 --> 00:32:06,527 line:-1
然后计算损失


606
00:32:07,594 --> 00:32:09,530 line:0
然后梯度传播


607
00:32:09,596 --> 00:32:12,132 line:0
计算梯度用于更新权重


608
00:32:12,633 --> 00:32:14,468 line:-1
这个设置很像


609
00:32:15,335 --> 00:32:17,037 line:-1
CNN训练的设置


610
00:32:17,104 --> 00:32:19,406 line:-1
最后一步当然也是更新权重


611
00:32:19,873 --> 00:32:22,176 line:-1
大家知道LSTM也有权重


612
00:32:22,242 --> 00:32:23,677 line:-1
也需要更新


613
00:32:26,079 --> 00:32:30,617 line:-2
现在看看在MPS中
如何训练这个网络


614
00:32:30,684 --> 00:32:33,620 line:-2
首先来看
如何创建LSTM 层


615
00:32:33,687 --> 00:32:35,522 line:-1
用我们的框架


616
00:32:36,657 --> 00:32:39,493 line:-1
第一步是创建LSTM层级描述符


617
00:32:40,594 --> 00:32:44,131 line:-2
用初始训练参数
初始化描述符


618
00:32:44,731 --> 00:32:46,066 line:-1
通过数据源提供器


619
00:32:46,400 --> 00:32:48,502 line:-1
初始的训练参数是


620
00:32:48,569 --> 00:32:51,305 line:-1
随机的小数字或检查点值


621
00:32:52,406 --> 00:32:54,208 line:-1
训练中描述符的设置


622
00:32:54,274 --> 00:32:56,810 line:-1
跟推断完全一样


623
00:32:58,612 --> 00:33:01,615 line:-1
我们以前讨论过层描述符的设置


624
00:33:01,915 --> 00:33:05,052 line:-2
在去年的WWDC演讲
内容十分详实


625
00:33:05,118 --> 00:33:08,255 line:-1
所以推荐大家去看那场演讲了解更多


626
00:33:08,322 --> 00:33:10,390 line:-2
关于LSTM
层描述符的设置


627
00:33:11,158 --> 00:33:12,626 line:-1
有了描述符之后


628
00:33:13,894 --> 00:33:17,798 line:-1
就要用它来创建LSTM训练层


629
00:33:19,766 --> 00:33:22,636 line:-1
MPS会添加训练权重


630
00:33:22,936 --> 00:33:25,572 line:-1
使用描述符定义的数据源


631
00:33:26,206 --> 00:33:28,141 line:-1
还需要一些矩阵


632
00:33:28,242 --> 00:33:29,710 line:-1
实现梯度计算


633
00:33:30,644 --> 00:33:33,747 line:-2
你要用
createWeightGradientMatrices


634
00:33:33,814 --> 00:33:34,648 line:-1
API


635
00:33:34,715 --> 00:33:37,217 line:-2
在训练层上
创建这些矩阵


636
00:33:37,751 --> 00:33:39,520 line:-1
然后训练权重


637
00:33:39,887 --> 00:33:42,389 line:-1
会被用于正向和梯度传播中


638
00:33:42,890 --> 00:33:44,658 line:-1
然后被传递给优化器


639
00:33:44,725 --> 00:33:47,194 line:-1
与计算好的梯度一起用于更新权重


640
00:33:49,396 --> 00:33:53,534 line:-2
现在要准备一些输入和输出
用于训练LSTM


641
00:33:54,535 --> 00:33:56,470 line:-1
这个例子展示了如何创建


642
00:33:56,937 --> 00:33:59,840 line:-1
矩阵去管理输入和输出序列


643
00:33:59,907 --> 00:34:02,276 line:-1
在正向和梯度传播中


644
00:34:02,342 --> 00:34:04,678 line:-1
每个需要20个矩阵


645
00:34:05,712 --> 00:34:09,149 line:-1
这是如何初始化矩阵数据


646
00:34:11,784 --> 00:34:14,855 line:-1
现在就可以训练活动分类网络了


647
00:34:15,255 --> 00:34:16,089 line:-1
用MPS


648
00:34:16,156 --> 00:34:17,157 line:-1
这个代码样本中


649
00:34:17,224 --> 00:34:19,760 line:-1
我只强调LSTM过滤器


650
00:34:20,127 --> 00:34:21,395 line:-1
因为时间有限


651
00:34:23,563 --> 00:34:26,600 line:-2
在正向传播中
运行20矩阵的序列


652
00:34:26,667 --> 00:34:28,835 line:-1
正向通过LSTM训练层


653
00:34:29,735 --> 00:34:31,170 line:-1
然后反向传播


654
00:34:31,237 --> 00:34:34,440 line:-2
运行20个矩阵的序列
经过LSTM层


655
00:34:34,507 --> 00:34:35,641 line:-1
计算梯度


656
00:34:36,577 --> 00:34:38,978 line:0
现在已有训练权重


657
00:34:39,246 --> 00:34:40,848 line:0
计算好的梯度


658
00:34:40,914 --> 00:34:44,016 line:0
就可以将它们传递到
优化器去更新权重


659
00:34:45,686 --> 00:34:47,754 line:0
最后我要补充一点


660
00:34:49,389 --> 00:34:52,726 line:-1
卷积神经网络对图像的处理


661
00:34:52,793 --> 00:34:55,062 line:-1
和对LSTM的运行是基于矩阵


662
00:34:56,063 --> 00:34:58,632 line:-1
我们会提供便利内核给这个框架


663
00:34:59,199 --> 00:35:02,236 line:-1
方便来回转换图像和矩阵


664
00:35:03,136 --> 00:35:04,438 line:-1
那么要复制


665
00:35:05,205 --> 00:35:06,607 line:0
一张图像到矩阵


666
00:35:06,673 --> 00:35:10,077 line:0
需要使用
MPSImageCopyToMatrix内核


667
00:35:10,143 --> 00:35:11,812 line:0
这是创建方法


668
00:35:12,145 --> 00:35:15,883 line:0
以及如何给一批图像编码


669
00:35:17,084 --> 00:35:21,955 line:0
目的矩阵的每行都含有一个源图像


670
00:35:23,056 --> 00:35:25,459 line:0
要从矩阵复制到图像


671
00:35:25,926 --> 00:35:29,162 line:0
需要内核
MPSMatrixCopyToImage


672
00:35:29,229 --> 00:35:30,697 line:0
这一部分是创建


673
00:35:30,998 --> 00:35:33,267 line:0
这部分是在GPU上编码


674
00:35:35,302 --> 00:35:40,807 line:-2
大家已经了解了如何使用MPS
训练CNN和RNN


675
00:35:41,808 --> 00:35:44,344 line:-2
也看过了
Turi Create的演示


676
00:35:44,411 --> 00:35:46,180 line:-1
现在由MPS驱动


677
00:35:46,246 --> 00:35:47,881 line:-1
现在再看一个演示


678
00:35:49,550 --> 00:35:51,218 line:-1
我们在与Google合作


679
00:35:51,285 --> 00:35:53,987 line:-1
添加Metal性能着色器框架


680
00:35:54,054 --> 00:35:56,323 line:-1
给TensorFlow…


681
00:35:57,090 --> 00:35:59,193 line:-1
以提升macOS机器学习的速度


682
00:35:59,259 --> 00:36:01,495 line:-1
也给大家带来了动态演示


683
00:36:01,562 --> 00:36:03,864 line:-1
具体来说 我们要演示的是


684
00:36:03,931 --> 00:36:07,034 line:-2
训练InceptionV3
对象分类网络


685
00:36:08,135 --> 00:36:10,737 line:-2
使用TensorFlow
驱动是MPS


686
00:36:11,638 --> 00:36:12,739 line:-1
这个演示中


687
00:36:14,608 --> 00:36:18,545 line:-2
我还是使用MacBook Pro
外接一个GPU


688
00:36:19,313 --> 00:36:22,883 line:-2
TensorFlow
在MacBook Pro上


689
00:36:23,317 --> 00:36:27,454 line:-2
外部GPU
用MPS训练网络


690
00:36:27,921 --> 00:36:29,056 line:-1
演示设置


691
00:36:29,623 --> 00:36:31,358 line:-2
我己安装了
TensorFlow


692
00:36:31,658 --> 00:36:34,761 line:-2
也预先加载了
InceptionV3网络


693
00:36:34,862 --> 00:36:36,196 line:-1
和训练数据集


694
00:36:36,263 --> 00:36:39,499 line:-1
现在训练网络30次迭代


695
00:36:41,001 --> 00:36:42,970 line:-1
你看速度多快


696
00:36:43,437 --> 00:36:44,705 line:-1
同样 整个网络


697
00:36:44,838 --> 00:36:47,808 line:-2
所有原语
优化器和权重更新步骤


698
00:36:48,075 --> 00:36:50,277 line:-1
都是在外部GPU上运行


699
00:36:50,777 --> 00:36:51,912 line:-1
这就完成了


700
00:36:52,479 --> 00:36:53,714 line:-1
大家看到


701
00:36:53,780 --> 00:36:57,117 line:-2
训练速度大概是
每秒100张图


702
00:36:57,784 --> 00:37:00,721 line:-1
平台状态汇总中说过


703
00:37:01,188 --> 00:37:03,557 line:-1
训练InceptionV3网络


704
00:37:04,157 --> 00:37:06,226 line:-2
用MPS驱动的
TensorFlow


705
00:37:06,727 --> 00:37:10,364 line:-2
要比不用MPS
快20倍


706
00:37:11,231 --> 00:37:13,367 line:-1
以上就是TensorFlow演示


707
00:37:16,203 --> 00:37:17,404 line:-1
谢谢大家


708
00:37:22,042 --> 00:37:23,710 line:-1
现在做个总结


709
00:37:24,845 --> 00:37:27,648 line:-2
今年新添加了
FP16计算


710
00:37:28,081 --> 00:37:30,984 line:-1
给卷积和卷积转置原语


711
00:37:31,552 --> 00:37:34,621 line:-1
提升CNN推断的性能


712
00:37:35,255 --> 00:37:37,691 line:-1
我们还添加了GPU加速原语


713
00:37:37,891 --> 00:37:39,359 line:-1
用于训练神经网络


714
00:37:39,426 --> 00:37:43,330 line:-2
这些原语都已优化
可用于iOS和macOS


715
00:37:44,765 --> 00:37:47,534 line:-2
我们还为训练添加了
神经网络图形API


716
00:37:48,468 --> 00:37:51,538 line:-1
简化了GPU上对神经网络的训练


717
00:37:51,839 --> 00:37:53,040 line:-1
并让我们可以


718
00:37:53,106 --> 00:37:56,243 line:-2
让不同的GPU
都达到最佳性能


719
00:37:58,745 --> 00:38:02,115 line:0
本场演讲的更多信息
相关资源的链接


720
00:38:02,182 --> 00:38:03,984 line:0
请访问开发者网站


721
00:38:05,586 --> 00:38:08,689 line:0
在明早9点的
Metal机器学习实验室


722
00:38:09,089 --> 00:38:12,092 line:0
希望能见到你们
欢迎参加


723
00:38:13,861 --> 00:38:17,965 line:-2
谢谢大家的到来
愿你们在WWDC中度过美好时光

