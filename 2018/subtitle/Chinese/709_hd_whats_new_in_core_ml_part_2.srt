1
00:00:17,017 --> 00:00:23,457 line:0
（Core ML新特性
第二部分）


2
00:00:24,858 --> 00:00:25,726 line:-1
大家好


3
00:00:31,398 --> 00:00:33,700 line:-2
欢迎来到Core ML
第二部分演讲


4
00:00:34,368 --> 00:00:37,971 line:-2
我是Aseem
Core ML团队的工程师


5
00:00:40,774 --> 00:00:43,243 line:-2
众所周知
Core ML是Apple


6
00:00:43,544 --> 00:00:46,413 line:-1
用于设备上推理的机器学习框架


7
00:00:48,348 --> 00:00:50,717 line:-1
而我最喜欢Core ML的原因


8
00:00:50,884 --> 00:00:53,754 line:-2
是它在所有Apple硬件上
都得到了优化


9
00:00:55,422 --> 00:00:56,657 line:-1
过去一年中


10
00:00:57,324 --> 00:01:02,429 line:-2
我们在所有Apple平台上看到了
许多令人惊叹的app


11
00:01:03,096 --> 00:01:04,464 line:-1
所以这真的很令人兴奋


12
00:01:05,232 --> 00:01:07,034 line:-1
而我们对今年推出的新功能


13
00:01:07,601 --> 00:01:09,803 line:-1
甚至更加兴奋


14
00:01:10,604 --> 00:01:11,438 line:-1
现在


15
00:01:12,039 --> 00:01:15,108 line:-1
你可以大幅缩减app的大小


16
00:01:16,577 --> 00:01:21,415 line:-2
通过使用新的批处理预测API
你可以使你的app运行更快


17
00:01:23,050 --> 00:01:27,588 line:-1
并且你可以轻松将最先进的研究成果


18
00:01:27,754 --> 00:01:29,990 line:-1
通过自定义机制整合到你的app中


19
00:01:31,725 --> 00:01:33,961 line:-1
这些是对第一次演讲的回顾


20
00:01:34,394 --> 00:01:35,662 line:-1
如果你错过了那次演讲


21
00:01:36,163 --> 00:01:38,932 line:-1
我强烈建议你回去看一下幻灯片


22
00:01:41,435 --> 00:01:43,837 line:-1
在这次演讲中 我们将会看到


23
00:01:44,238 --> 00:01:47,040 line:-1
如何实际使用这些特性


24
00:01:47,941 --> 00:01:51,211 line:-2
更具体地说
我们将通过几个例子向你展示


25
00:01:51,678 --> 00:01:55,148 line:-1
你如何通过简单的几步


26
00:01:55,682 --> 00:01:59,953 line:-2
使用Core ML Tools
来缩减模型的大小


27
00:02:00,220 --> 00:02:02,856 line:-1
以及你如何在模型中使用自定义特性


28
00:02:04,591 --> 00:02:06,126 line:-1
这是这次演讲的议程


29
00:02:07,060 --> 00:02:10,764 line:-2
我们从Core ML Tools
生态系统的最新进展开始


30
00:02:11,732 --> 00:02:17,304 line:-2
然后我们将深入并演示
量化和自定义转换


31
00:02:18,038 --> 00:02:19,640 line:-1
让我们先从生态系统开始


32
00:02:23,277 --> 00:02:25,312 line:-1
你如何得到一个ML模型呢？


33
00:02:26,046 --> 00:02:28,048 line:-1
最简单的是 如果你…


34
00:02:29,449 --> 00:02:30,384 line:-1
如果你可以…


35
00:02:32,286 --> 00:02:35,022 line:-2
如果你能在网上找到它
只需下载它 对吧？


36
00:02:36,023 --> 00:02:39,393 line:-1
一个下载ML模型的好地方


37
00:02:39,459 --> 00:02:42,362 line:-1
是Apple机器学习着陆页


38
00:02:42,696 --> 00:02:44,264 line:-1
那上面有许多模型


39
00:02:45,465 --> 00:02:48,468 line:-2
现在让我们假设你想
在你的数据集上训练一个模型


40
00:02:49,036 --> 00:02:51,104 line:-1
在这种情况下 你可以使用


41
00:02:52,739 --> 00:02:53,774 line:-1
Create ML


42
00:02:53,941 --> 00:02:56,977 line:-1
这是我们今年刚刚发布的一个新框架


43
00:02:57,845 --> 00:03:00,848 line:-1
你无需成为机器学习专家即可使用它


44
00:03:01,315 --> 00:03:03,784 line:-2
它非常易于使用
它就在Xcode中


45
00:03:04,451 --> 00:03:06,920 line:-1
所以去试试吧


46
00:03:08,488 --> 00:03:13,126 line:-2
你们中的一些人已经熟悉了
开源社区中的一些


47
00:03:13,193 --> 00:03:15,529 line:-1
令人惊叹的机器学习工具


48
00:03:16,029 --> 00:03:22,002 line:-2
为此我们去年发布了一个Python包
即Core ML Tools


49
00:03:22,536 --> 00:03:26,773 line:-1
此外我们还发布了一些转换器


50
00:03:28,375 --> 00:03:32,246 line:-1
去年这个领域有许多活动


51
00:03:32,946 --> 00:03:34,915 line:-1
这就是现在的样子


52
00:03:37,451 --> 00:03:42,422 line:-1
正如你所看到的 还有更多的转换器


53
00:03:42,890 --> 00:03:47,160 line:-2
现在确实有很多不同的
训练框架以供你选择


54
00:03:48,695 --> 00:03:52,533 line:-2
所有这些转换器都建立在
Core ML Tools之上


55
00:03:55,369 --> 00:03:59,072 line:-2
现在 我想在这里强调
几个不同的转换器


56
00:04:01,175 --> 00:04:06,346 line:-2
去年我们与Google合作
发布了TensorFlow转换器


57
00:04:07,414 --> 00:04:08,715 line:-1
这很令人兴奋


58
00:04:10,651 --> 00:04:15,322 line:-2
如你所知 TensorFlow
在爱尝试新层的研究人员中颇受欢迎


59
00:04:15,656 --> 00:04:19,625 line:-2
所以我们最近在转换器中添加了
对自定义层的支持


60
00:04:21,128 --> 00:04:25,832 line:-2
最近TensorFlow发布了
对在训练过程中进行量化的支持


61
00:04:26,200 --> 00:04:28,602 line:-2
这种支持是通过
Core ML 2实现的


62
00:04:29,102 --> 00:04:31,438 line:-1
这个特性很快就会添加到转换器中


63
00:04:33,173 --> 00:04:37,811 line:-2
另一个令人兴奋的是
我们与Facebook和Prisma的合作


64
00:04:38,312 --> 00:04:40,881 line:-1
这些合作的成果就是ONNX转换器


65
00:04:42,182 --> 00:04:43,951 line:-1
ONNX的优势在于


66
00:04:45,652 --> 00:04:49,857 line:-1
现在你可以使用许多不同的训练库了


67
00:04:50,290 --> 00:04:54,361 line:-2
通过使用新的ONNX转换器
它们都可以被转换为Core ML


68
00:04:56,230 --> 00:05:00,434 line:-2
这是对Core ML Tools
生态系统最新进展的快速总结


69
00:05:00,834 --> 00:05:02,569 line:-1
为了讨论量化


70
00:05:02,636 --> 00:05:05,472 line:-2
我想邀请我的朋友
Sohaib到舞台上来


71
00:05:14,147 --> 00:05:16,116 line:-2
大家早上好
我叫Sohaib


72
00:05:16,183 --> 00:05:17,985 line:-1
我是Core ML团队的工程师


73
00:05:18,051 --> 00:05:21,321 line:-2
今天 我们将看看
Core ML Tools 2.0中


74
00:05:21,388 --> 00:05:22,990 line:-1
新的量化功能


75
00:05:28,095 --> 00:05:29,763 line:-1
Core ML Tools 2.0支持


76
00:05:29,830 --> 00:05:32,432 line:-1
最新的Core ML模型格式规范


77
00:05:32,733 --> 00:05:33,867 line:-1
它也有一些实用工具


78
00:05:33,934 --> 00:05:36,904 line:-2
使你可以轻松地添加
弹性形状和量化功能


79
00:05:37,204 --> 00:05:39,740 line:-1
到你的神经网络机器学习模型中


80
00:05:40,240 --> 00:05:42,309 line:-2
在Core ML中
使用这些优秀新功能


81
00:05:42,376 --> 00:05:45,279 line:-1
你不仅可以缩减模型的大小


82
00:05:45,546 --> 00:05:48,949 line:-2
还可以减少app中模型的数量
并且减少app的占用空间


83
00:05:50,350 --> 00:05:53,320 line:-1
现在 我们先看一下量化


84
00:05:54,821 --> 00:05:57,257 line:-2
Core ML Tools
支持训练后量化


85
00:05:57,658 --> 00:06:00,194 line:-2
我们从Core ML
神经网络模型开始


86
00:06:00,594 --> 00:06:03,330 line:-1
它具有32位浮点权重参数


87
00:06:03,730 --> 00:06:07,467 line:-2
我们用Core ML Tools
来量化这个模型的权重


88
00:06:08,101 --> 00:06:10,037 line:-1
生成的模型体积较小


89
00:06:10,771 --> 00:06:13,340 line:-1
模型大小的缩减直接依赖于


90
00:06:13,407 --> 00:06:15,876 line:-1
我们量化模型的位数


91
00:06:17,811 --> 00:06:21,048 line:-2
现在 我们中的很多人可能会想
量化到底是什么？


92
00:06:21,281 --> 00:06:23,317 line:-1
它如何缩减模型的大小


93
00:06:23,984 --> 00:06:26,253 line:-1
让我们窥视一下幕后所发生的事情


94
00:06:30,357 --> 00:06:32,426 line:-1
神经网络由层组成


95
00:06:32,726 --> 00:06:35,495 line:-1
这些层可以被视为数学函数


96
00:06:36,063 --> 00:06:39,233 line:-1
这些数学函数有参数 称为权重


97
00:06:39,700 --> 00:06:42,803 line:-1
这些权重通常存储为32位浮点数


98
00:06:44,304 --> 00:06:47,074 line:-2
在我们之前的演讲中
我们谈到了ResNet50


99
00:06:47,641 --> 00:06:49,142 line:-1
这是一种流行的机器学习模型


100
00:06:49,209 --> 00:06:52,045 line:-1
可以用于图像分类等等


101
00:06:52,446 --> 00:06:56,283 line:-2
这个模型拥有
超过2500万个权重参数


102
00:06:57,050 --> 00:07:00,320 line:-2
所以你可以想象
如果你能以某种方式以更少的位数


103
00:07:00,521 --> 00:07:02,723 line:-1
来表示这些参数


104
00:07:03,090 --> 00:07:05,325 line:-1
我们就可以大大缩减这个模型的大小


105
00:07:06,927 --> 00:07:09,730 line:-1
实际上 这个过程被称为量化


106
00:07:10,464 --> 00:07:13,267 line:-1
在量化过程中 我们将


107
00:07:13,600 --> 00:07:16,003 line:-1
在最小值和最大值之间的层的权重


108
00:07:16,537 --> 00:07:17,638 line:-1
映射为


109
00:07:18,605 --> 00:07:19,773 line:-1
无符号整数


110
00:07:20,908 --> 00:07:22,576 line:-1
对于APIC量化


111
00:07:22,643 --> 00:07:26,680 line:-1
我们将这些值映射到0到55的范围


112
00:07:27,114 --> 00:07:28,382 line:-1
对于7位量化


113
00:07:28,448 --> 00:07:32,553 line:-2
我们将它们映射到0到127
一直到1位


114
00:07:32,786 --> 00:07:35,489 line:-1
即将这些权重映射为0或1


115
00:07:36,223 --> 00:07:37,491 line:-1
由于我们使用更少的位数


116
00:07:37,558 --> 00:07:40,594 line:-2
来表示相同的信息
因此我们缩减了模型的大小


117
00:07:42,362 --> 00:07:43,197 line:-1
真棒


118
00:07:43,530 --> 00:07:47,334 line:-2
你们中许多人可能已经注意到
我们正在将浮点数映射为整数


119
00:07:48,202 --> 00:07:51,171 line:-1
你可能已经得出结论 在这种映射中


120
00:07:51,638 --> 00:07:53,841 line:-1
可能会有一些精确度损失 这是对的


121
00:07:54,675 --> 00:07:55,642 line:-1
经验法则是


122
00:07:55,976 --> 00:07:58,278 line:-1
你用来量化模型的位数越少


123
00:07:58,545 --> 00:08:00,914 line:-2
我们的模型在准确性方面
所受到的影响越大


124
00:08:01,048 --> 00:08:02,683 line:-1
我们稍后还会谈到这一点


125
00:08:03,884 --> 00:08:05,619 line:-1
以上是对量化的概述


126
00:08:05,986 --> 00:08:08,755 line:-2
但问题依然存在
我们如何获得这种映射


127
00:08:09,489 --> 00:08:11,258 line:-1
有很多流行的算法


128
00:08:11,325 --> 00:08:13,694 line:-1
和技术能帮助你做到这一点


129
00:08:13,760 --> 00:08:16,530 line:-2
Core ML支持
其中两种最流行的


130
00:08:17,130 --> 00:08:19,700 line:-1
线性量化和查找表量化


131
00:08:20,634 --> 00:08:22,002 line:-1
让我们简要介绍一下


132
00:08:26,273 --> 00:08:28,008 line:-1
线性量化是一种


133
00:08:28,075 --> 00:08:31,778 line:-1
以均匀的方式映射参数的算法


134
00:08:32,880 --> 00:08:37,150 line:-2
这种量化是通过比例系数和偏差值
进行参数化的


135
00:08:37,217 --> 00:08:39,186 line:-1
这些值是通过计算得到的


136
00:08:39,553 --> 00:08:42,389 line:-1
该计算基于我们正在量化的层的参数


137
00:08:43,023 --> 00:08:46,393 line:-2
了解这种映射工作原理
的一种非常直观的方式


138
00:08:46,727 --> 00:08:48,195 line:-1
是我们退后一步


139
00:08:48,262 --> 00:08:50,497 line:-1
看看我们如何从位于底部的量化权重


140
00:08:50,564 --> 00:08:53,267 line:-1
恢复到原来的浮点数权重


141
00:08:53,834 --> 00:08:57,571 line:-2
在线性量化中
我们只需用量化权重


142
00:08:57,804 --> 00:08:59,973 line:-1
乘以比例系数再加上偏差


143
00:09:02,075 --> 00:09:04,778 line:-2
Core ML支持的
第二种量化技术


144
00:09:05,012 --> 00:09:06,513 line:-1
是查找表量化


145
00:09:07,147 --> 00:09:09,383 line:-1
顾名思义


146
00:09:09,683 --> 00:09:11,018 line:-1
我们构造一个查找表


147
00:09:11,952 --> 00:09:14,588 line:-1
再想象一下我们如何从量化后的权重


148
00:09:14,655 --> 00:09:17,024 line:-2
得到原来的权重
会很有帮助


149
00:09:17,257 --> 00:09:20,294 line:-1
在这种情况下 量化权重只是


150
00:09:20,594 --> 00:09:22,763 line:-1
查找表中的一些索引


151
00:09:24,031 --> 00:09:26,233 line:-2
现在 如果你注意到
与线性量化不同


152
00:09:26,300 --> 00:09:29,603 line:-2
我们现在可以自由移动
我们的量化权重


153
00:09:29,670 --> 00:09:32,039 line:-1
它们不必以线性方式间隔开


154
00:09:33,874 --> 00:09:37,811 line:-2
回顾一下
Core ML Tools支持


155
00:09:38,612 --> 00:09:40,781 line:-1
线性量化和查找表量化


156
00:09:40,848 --> 00:09:42,850 line:-1
我们从一个全精度神经网络模型开始


157
00:09:42,916 --> 00:09:45,652 line:-1
并使用这些工具来量化该模型的权重


158
00:09:46,220 --> 00:09:47,654 line:-1
现在你可能在想


159
00:09:47,988 --> 00:09:50,290 line:-2
太好了
我可以缩减我的模型的大小


160
00:09:50,824 --> 00:09:53,961 line:-1
但该如何找出量化的参数呢？


161
00:09:54,761 --> 00:09:57,965 line:-2
如果我正进行线性量化
我该如何计算出比例系数和偏差呢？


162
00:09:58,365 --> 00:10:02,035 line:-2
如果我正在执行查找表量化
我该如何构建查找表呢？


163
00:10:03,036 --> 00:10:06,206 line:-2
我在这里告诉你
你不必关心这其中任何一点


164
00:10:06,940 --> 00:10:10,611 line:-2
你所要做的就是决定
你想要量化模型的位数


165
00:10:10,844 --> 00:10:12,746 line:-1
并决定要使用的算法


166
00:10:13,046 --> 00:10:15,215 line:-2
剩下的工作交给
Core ML Tools来完成


167
00:10:16,083 --> 00:10:16,984 line:-1
事实上…


168
00:10:17,985 --> 00:10:18,819 line:-1
谢谢大家


169
00:10:22,656 --> 00:10:26,994 line:-2
事实上 量化一个
Core ML模型是如此简单


170
00:10:27,394 --> 00:10:29,796 line:-2
以至于我们可在几行
Python代码中完成它


171
00:10:30,397 --> 00:10:33,400 line:-2
既然我们可以在这里演示
何必继续浪费口舌呢？


172
00:10:40,507 --> 00:10:42,676 line:-1
为了演示


173
00:10:42,743 --> 00:10:46,013 line:-2
我需要一个
Core ML模型格式的神经网络


174
00:10:46,580 --> 00:10:48,248 line:-1
正如我的同事Aseem所说


175
00:10:48,315 --> 00:10:51,752 line:-2
Core ML机器学习主页是一个
找到这些模型的好地方


176
00:10:52,052 --> 00:10:55,189 line:-2
我已经提前下载了该页面中的
一个模型


177
00:10:55,522 --> 00:10:58,358 line:-2
这个模型叫做SqueezeNet
让我们打开它


178
00:11:00,627 --> 00:11:03,230 line:-2
正如我们所看到的
这个模型的大小是5兆字节


179
00:11:03,597 --> 00:11:08,268 line:-2
它有一个输入
是一个227*227像素的图像


180
00:11:08,669 --> 00:11:12,105 line:-2
它有两个输出
其中一个是类标签


181
00:11:12,639 --> 00:11:16,243 line:-2
由一个字符串表示
它代表该图片最有可能


182
00:11:16,610 --> 00:11:17,644 line:-1
属于的标签


183
00:11:17,711 --> 00:11:21,215 line:-1
第二个输出是这些字符串对应的概率


184
00:11:21,615 --> 00:11:23,951 line:-1
鉴于此 如果我们传入图像


185
00:11:24,017 --> 00:11:27,020 line:-2
我们会得到这个图像
可能是什么的概率列表


186
00:11:28,789 --> 00:11:30,457 line:-1
现在让我们开始量化这个模型


187
00:11:31,458 --> 00:11:34,761 line:-2
我首先要做的是
进入一个Python环境


188
00:11:34,928 --> 00:11:35,896 line:-1
我比较喜欢


189
00:11:35,963 --> 00:11:37,831 line:-1
Jupyter Notebook


190
00:11:38,098 --> 00:11:39,766 line:-1
现在我们打开它


191
00:11:46,673 --> 00:11:50,110 line:-1
让我们打开一个新的笔记本并放大


192
00:11:51,311 --> 00:11:54,915 line:-2
我们先导入
Core ML Tools


193
00:11:58,886 --> 00:12:01,221 line:-2
让我们来运行它
然后我想做的是


194
00:12:01,288 --> 00:12:03,724 line:-2
导入所有
在Core ML Tools中的


195
00:12:03,790 --> 00:12:07,261 line:-2
新量化工具
我们通过运行这句代码来达到目的


196
00:12:16,170 --> 00:12:19,106 line:-1
现在我们需要加载想要量化的模型


197
00:12:19,173 --> 00:12:21,175 line:-2
即我们刚看到的
SqueezeNet模型


198
00:12:21,241 --> 00:12:23,343 line:-1
我们需要获取该模型的一个实例


199
00:12:32,786 --> 00:12:34,288 line:-1
将参数设置为我的桌面


200
00:12:37,991 --> 00:12:38,825 line:-1
很好


201
00:12:39,026 --> 00:12:43,063 line:-2
现在 为了量化这个模型
我们只需要做一个简单的API调用


202
00:12:43,463 --> 00:12:47,267 line:-2
让我们尝试使用线性量化
来量化这个模型


203
00:12:51,572 --> 00:12:54,408 line:-2
它的API名称很简单
叫quantize_weights


204
00:12:54,808 --> 00:12:56,510 line:-1
我们传入的第一个参数


205
00:12:56,877 --> 00:12:59,079 line:-1
是你刚加载的原始模型


206
00:12:59,546 --> 00:13:02,149 line:-1
然后是我们想要量化模型的位数


207
00:13:02,216 --> 00:13:03,550 line:-1
这里我们将其设为8


208
00:13:04,685 --> 00:13:06,887 line:-1
以及我们想要使用的量化算法


209
00:13:07,054 --> 00:13:08,689 line:-1
让我们试试线性量化


210
00:13:10,157 --> 00:13:11,158 line:-1
现在所发生的事情是


211
00:13:11,225 --> 00:13:14,995 line:-1
这些工具会遍历线性网络的所有层


212
00:13:15,062 --> 00:13:17,731 line:-1
并量化这些层中的所有权重


213
00:13:18,165 --> 00:13:19,099 line:-1
我们完成了


214
00:13:20,467 --> 00:13:22,269 line:-1
如果你还记得


215
00:13:22,603 --> 00:13:25,272 line:-1
几分钟前我提到量化我们的模型


216
00:13:25,339 --> 00:13:27,274 line:-1
会造成精确度上的损失


217
00:13:27,941 --> 00:13:31,345 line:-2
所以我们想知道我们的量化模型
与原始模型相比效果如何


218
00:13:32,179 --> 00:13:35,883 line:-2
这样做的最简单方法是
将一些数据传给它


219
00:13:36,383 --> 00:13:39,953 line:-1
并使用我们的原始模型推理该数据


220
00:13:40,554 --> 00:13:42,956 line:-1
再使用我们的量化模型


221
00:13:43,023 --> 00:13:46,426 line:-2
对相同的数据进行相同的推理
并比较这两者的预测


222
00:13:47,094 --> 00:13:48,595 line:-1
来看看它们的一致程度


223
00:13:49,029 --> 00:13:51,465 line:-2
Core ML Tools
有帮助你做到这一点的工具


224
00:13:51,532 --> 00:13:55,636 line:-2
我们可以通过调用这个
称为compare_models函数来达到目的


225
00:13:56,236 --> 00:13:57,971 line:-1
我们传入全精度模型


226
00:13:58,472 --> 00:14:01,141 line:-1
然后是我们刚刚量化过的模型


227
00:14:01,942 --> 00:14:03,710 line:-1
由于这个模型是一个简单的


228
00:14:04,778 --> 00:14:07,381 line:-1
图像分类器 它只有一个图像输入


229
00:14:08,081 --> 00:14:09,416 line:-1
我们有一个方便的工具


230
00:14:09,483 --> 00:14:12,753 line:-2
我们只需传入一个
包含样本数据图像的文件夹


231
00:14:13,120 --> 00:14:14,221 line:-1
在我的桌面上


232
00:14:14,288 --> 00:14:17,824 line:-2
我有一个文件夹
里面有一组与我的app相关的图像


233
00:14:18,158 --> 00:14:23,063 line:-2
因此我将这个文件夹的路径
作为临时参数传入


234
00:14:27,968 --> 00:14:28,836 line:-1
很好


235
00:14:28,902 --> 00:14:31,805 line:-2
现在我们看到我们正在分析
该文件夹中的所有图像


236
00:14:31,872 --> 00:14:34,174 line:-1
我们正在推理…


237
00:14:34,241 --> 00:14:36,577 line:-1
我们先使用全精度模型


238
00:14:36,643 --> 00:14:38,512 line:-1
然后再用量化模型进行推理


239
00:14:38,579 --> 00:14:40,380 line:-1
最后比较这两个预测


240
00:14:41,348 --> 00:14:42,749 line:-1
我们似乎已经完成了


241
00:14:43,750 --> 00:14:46,954 line:-2
你可以看到我们的Top 1
Agreement值是94.8%


242
00:14:47,721 --> 00:14:51,058 line:-2
看起来不错 这个Top 1
Agreement是什么意思呢？


243
00:14:51,558 --> 00:14:53,894 line:-1
这意味着当我向原始模型输入


244
00:14:54,494 --> 00:14:56,763 line:-1
比如一只狗的图像时


245
00:14:57,297 --> 00:14:59,132 line:-1
它会预测这张图片是一只狗


246
00:14:59,199 --> 00:15:00,767 line:-1
而我的量化模型也作出同样预测


247
00:15:01,034 --> 00:15:04,137 line:-2
这种情况发生在
数据集中94.8%的图片上


248
00:15:05,839 --> 00:15:08,275 line:-1
我可以在我的app中使用此模型


249
00:15:08,675 --> 00:15:09,943 line:-1
但我想看看


250
00:15:10,177 --> 00:15:12,779 line:-2
其他量化技术
是否在这个模型上效果更好


251
00:15:13,480 --> 00:15:16,917 line:-2
正如我所提到的
Core ML支持两种量化技术


252
00:15:17,084 --> 00:15:19,553 line:-1
线性量化和查找表量化


253
00:15:19,887 --> 00:15:21,188 line:-1
所以让我们继续尝试


254
00:15:21,488 --> 00:15:24,124 line:-1
使用查找表量化来量化此模型


255
00:15:30,931 --> 00:15:32,466 line:-1
我们再次传入原始模型


256
00:15:32,766 --> 00:15:35,102 line:-1
和我们想要量化模型的位数


257
00:15:35,669 --> 00:15:37,404 line:-1
以及我们的量化技术


258
00:15:39,306 --> 00:15:40,474 line:-1
哎呀 这里有个错误


259
00:15:48,916 --> 00:15:50,217 line:-1
让我们运行它


260
00:15:50,651 --> 00:15:53,720 line:-2
K-means是一种
简单的聚类算法


261
00:15:53,787 --> 00:15:56,356 line:-1
能够逼近我们的权重分布


262
00:15:56,657 --> 00:15:58,192 line:-1
使用这种分布


263
00:15:58,392 --> 00:16:02,062 line:-1
我们可以为我们的权重构建查找表


264
00:16:02,529 --> 00:16:04,097 line:-1
我们在这里做的是


265
00:16:04,164 --> 00:16:07,000 line:-1
我们遍历神经网络中的所有层


266
00:16:07,267 --> 00:16:09,736 line:-1
对其执行量化过程


267
00:16:09,970 --> 00:16:11,438 line:-1
并为那个特顶层计算查找表


268
00:16:12,206 --> 00:16:15,409 line:-2
如果你是一位专家
并且你了解你的模型


269
00:16:15,576 --> 00:16:16,944 line:-1
你也知道你的模型架构


270
00:16:17,211 --> 00:16:19,580 line:-2
而且你知道K-means
不是最合适你的算法


271
00:16:19,813 --> 00:16:22,049 line:-1
你可以灵活地传入


272
00:16:22,216 --> 00:16:23,483 line:-1
你自己的自定义函数


273
00:16:24,585 --> 00:16:26,954 line:-2
而不是这里的这个算法
这个工具将使用


274
00:16:27,020 --> 00:16:29,790 line:-1
你的自定义函数来为你构造查找表


275
00:16:30,824 --> 00:16:34,661 line:-2
我们使用查找表方法
再次完成了对这个模型的量化


276
00:16:35,062 --> 00:16:38,298 line:-2
现在让我们看看这个模型
与我们的原始模型比较效果如何


277
00:16:38,632 --> 00:16:41,468 line:-2
所以我们再次调用
compare_models API


278
00:16:42,236 --> 00:16:46,373 line:-2
我们传入原始模型
接着传入查找表模型


279
00:16:46,974 --> 00:16:48,909 line:-1
我们再次传入


280
00:16:50,511 --> 00:16:51,645 line:-1
示例数据文件夹


281
00:16:54,681 --> 00:16:58,619 line:-1
我们再次使用原始模型和量化模型


282
00:16:59,586 --> 00:17:01,388 line:-1
对所有图像进行推理


283
00:17:01,688 --> 00:17:02,723 line:-1
我们看到这一次


284
00:17:02,789 --> 00:17:05,791 line:-2
我们得到了一个更好一点的
Top 1 Agreement


285
00:17:06,193 --> 00:17:07,261 line:-1
对于这个模型


286
00:17:07,694 --> 00:17:09,963 line:-1
我们看到查找表是正确的选择


287
00:17:10,364 --> 00:17:12,866 line:-1
但是这与模型有关 对于其他模型


288
00:17:13,066 --> 00:17:14,067 line:-1
可能是线性量化效果更好


289
00:17:14,635 --> 00:17:17,905 line:-2
现在我们对这个结果感到高兴
并且认为这对我的app来说


290
00:17:17,971 --> 00:17:20,773 line:-2
已经够好了
现在让我们保存此模型


291
00:17:23,410 --> 00:17:25,546 line:-1
我们通过调用save函数来保存


292
00:17:30,417 --> 00:17:34,254 line:-2
再给它起个有创意的名字
就叫QuantizedSqueezeNet


293
00:17:41,161 --> 00:17:43,263 line:-2
可以了
现在我们有了一个量化模型


294
00:17:43,964 --> 00:17:47,634 line:-2
这是一个原始模型
我们看到它的大小是5兆字节


295
00:17:48,168 --> 00:17:50,037 line:-1
让我们打开我们的量化模型


296
00:17:52,606 --> 00:17:54,274 line:-1
我们立即注意到的第一件事


297
00:17:54,341 --> 00:17:57,544 line:-1
是这个模型的大小只有1.3兆字节


298
00:18:04,117 --> 00:18:05,285 line:-1
如果你注意一下会发现


299
00:18:05,986 --> 00:18:10,858 line:-2
有关量化模型的所有细节
都与原始模型相同


300
00:18:11,225 --> 00:18:14,561 line:-2
它仍然需要一个图像输入
仍然有两个输出


301
00:18:15,229 --> 00:18:18,131 line:-2
若我有一个使用此模型的app
我可以做的是


302
00:18:18,198 --> 00:18:19,633 line:-1
如我们在演示中看到的那样


303
00:18:20,000 --> 00:18:22,536 line:-2
将这个量化模型直接
拖入我们的app


304
00:18:22,603 --> 00:18:23,937 line:-1
并开始使用它


305
00:18:24,137 --> 00:18:26,440 line:-2
只需这样 我们就缩减了
app的大小


306
00:18:32,379 --> 00:18:34,915 line:-2
这就是使用
Core ML Tools量化的过程


307
00:18:38,652 --> 00:18:43,590 line:-2
回顾一下 我们看到使用Core ML Tools
来量化我们的模型是多么容易


308
00:18:44,291 --> 00:18:48,328 line:-2
使用一个简单的API
传入我们的原始模型


309
00:18:48,795 --> 00:18:51,231 line:-1
我们想要量化模型的位数


310
00:18:51,498 --> 00:18:53,667 line:-1
和我们想要使用的量化算法


311
00:18:54,201 --> 00:18:56,436 line:-2
我们也看到Core ML Tools中
有一些实用工具


312
00:18:56,703 --> 00:18:59,039 line:-1
来帮助我们比较量化模型


313
00:18:59,373 --> 00:19:01,808 line:-2
从而了解它与我们的
原始模型相比较效果如何


314
00:19:03,510 --> 00:19:05,345 line:-1
正如我们在演示中看到的那样


315
00:19:05,712 --> 00:19:08,882 line:-2
量化我们的模型会导致
相应精度的损失


316
00:19:09,816 --> 00:19:10,817 line:-1
这个…


317
00:19:11,151 --> 00:19:13,754 line:-1
这种精度损失高度依赖于模型和数据


318
00:19:14,621 --> 00:19:18,759 line:-2
一些模型在量化之后
比其它模型表现更好


319
00:19:19,359 --> 00:19:20,994 line:-1
作为一般经验法则


320
00:19:21,161 --> 00:19:23,697 line:-1
我们量化模型的位数越少


321
00:19:24,364 --> 00:19:26,033 line:-1
我们精度所受的影响就越大


322
00:19:26,567 --> 00:19:28,235 line:-1
在演示中我们看到


323
00:19:28,669 --> 00:19:31,705 line:-2
我们能使用Core ML Tools中的
Top 1 Agreement指标


324
00:19:31,772 --> 00:19:34,575 line:-2
来比较我们的量化模型
和原始模型


325
00:19:35,442 --> 00:19:36,810 line:-1
但你必须弄清楚


326
00:19:37,411 --> 00:19:40,147 line:-2
你的模型和用例的
相关度量标准是什么


327
00:19:40,214 --> 00:19:42,850 line:-1
并验证你的量化模型是可接受的


328
00:19:44,017 --> 00:19:47,421 line:-2
在之前的演讲中
我们看了一个风格转换演示


329
00:19:48,155 --> 00:19:50,757 line:-1
这个网络输入一幅图像


330
00:19:51,158 --> 00:19:54,494 line:-1
然后输出一个风格化的图像


331
00:19:55,329 --> 00:19:57,297 line:-1
让我们来看看这个模型


332
00:19:57,364 --> 00:19:59,233 line:-1
在不同的量化级别下表现如何


333
00:20:00,133 --> 00:20:04,271 line:-1
在左上角


334
00:20:04,771 --> 00:20:10,210 line:-2
我们看到原始模型是32位
大小为6.7兆字节


335
00:20:10,677 --> 00:20:14,448 line:-2
我们的8位线性量化模型
只有1.7兆字节


336
00:20:14,781 --> 00:20:17,451 line:-1
而且我们发现 从视觉上来看


337
00:20:17,518 --> 00:20:19,753 line:-2
该效果对于我的风格转换演示来说
已经足够了


338
00:20:20,687 --> 00:20:23,924 line:-1
我们还可以看到 即使低至4位


339
00:20:24,024 --> 00:20:26,193 line:-1
我们也不会在效果方面损失太多


340
00:20:26,593 --> 00:20:27,961 line:-1
我甚至可能会说


341
00:20:28,028 --> 00:20:30,163 line:-2
对于我的app来说
即使3位也可以正常工作


342
00:20:30,664 --> 00:20:33,967 line:-2
从2位开始我们可以看到
这时出现了很多痕迹


343
00:20:34,401 --> 00:20:36,436 line:-1
这个模型可能不适合我们


344
00:20:38,906 --> 00:20:41,175 line:-2
以上就是如何使用
Core ML Tools进行量化的部分


345
00:20:41,975 --> 00:20:43,510 line:-1
接下来我将话筒交回给Aseem


346
00:20:43,577 --> 00:20:45,612 line:-1
他将会谈论自定义转换


347
00:20:45,779 --> 00:20:46,613 line:-1
谢谢


348
00:20:52,352 --> 00:20:53,387 line:-1
谢谢Sohaib


349
00:20:55,155 --> 00:20:58,659 line:-1
我想谈一下一个非常重要的特性


350
00:20:58,725 --> 00:21:01,728 line:-2
它让我们能够跟上
机器学习领域的发展


351
00:21:02,329 --> 00:21:03,397 line:-1
大家都知道


352
00:21:04,064 --> 00:21:07,134 line:-1
机器学习领域正在迅速发展


353
00:21:07,768 --> 00:21:10,304 line:-2
因此 为你提供必要的软件工具
来解决这个问题


354
00:21:10,771 --> 00:21:14,374 line:-2
对于我们Core ML团队来说
非常重要


355
00:21:15,876 --> 00:21:17,077 line:-1
现在举一个例子


356
00:21:17,911 --> 00:21:20,781 line:-1
假设你正在尝试一个


357
00:21:20,848 --> 00:21:22,349 line:-1
Core ML尚不支持的新模型


358
00:21:22,649 --> 00:21:27,321 line:-2
或者假设你有一个
运行在Core ML上的神经网络


359
00:21:27,387 --> 00:21:31,792 line:-2
但是也许其中有一两层
Core ML暂时无法提供


360
00:21:32,893 --> 00:21:38,432 line:-2
在这种情况下 你希望仍然能够使用
Core ML的强大功能 对吗？


361
00:21:39,333 --> 00:21:41,134 line:-2
对这个问题的回答是
是的


362
00:21:41,668 --> 00:21:44,938 line:-1
自定义机制将帮助你达到这点


363
00:21:46,173 --> 00:21:47,274 line:-1
在接下来的几分钟内


364
00:21:47,474 --> 00:21:50,644 line:-1
我想重点关注当我们有一个


365
00:21:50,711 --> 00:21:53,514 line:-1
新的神经网络层的情况


366
00:21:53,881 --> 00:21:56,984 line:-2
然后向你展示
你将如何将它转换为Core ML


367
00:21:57,284 --> 00:21:59,486 line:-1
以及如何在你的app中实现它


368
00:22:00,854 --> 00:22:02,956 line:-1
让我们先来看看模型转换


369
00:22:03,957 --> 00:22:07,261 line:-2
如果你使用过我们的转换器
或者即使你没有


370
00:22:07,661 --> 00:22:10,697 line:-2
它是一个非常简单的API
这只是对一个函数的调用


371
00:22:12,065 --> 00:22:15,068 line:-1
这是Keras转换器的样子


372
00:22:15,469 --> 00:22:17,638 line:-2
它与ONNX转换器
或TensorFlow转换器


373
00:22:17,704 --> 00:22:20,440 line:-1
都很相似


374
00:22:21,742 --> 00:22:25,612 line:-2
当你调用这个函数时
大多数情况下都是正常的


375
00:22:25,946 --> 00:22:29,149 line:0
但有时你可能会得到
类似这样的错误消息


376
00:22:30,751 --> 00:22:34,354 line:0
它可能会说
“嘿 不支持的某某操作”


377
00:22:35,088 --> 00:22:36,957 line:0
如果这件事发生在你身上


378
00:22:37,291 --> 00:22:40,894 line:0
你只需要多做一点事
就可以避开这个错误


379
00:22:41,628 --> 00:22:42,796 line:0
更具体地说


380
00:22:42,963 --> 00:22:47,668 line:0
这样的错误信息表明
你应该使用自定义层


381
00:22:48,969 --> 00:22:50,170 line:0
在我向你展示


382
00:22:50,237 --> 00:22:53,407 line:0
你需要做点什么才能成功转换之前


383
00:22:54,241 --> 00:22:57,778 line:-2
让我们先看几个
你需要使用到自定义层的例子


384
00:23:01,315 --> 00:23:05,853 line:-2
假设你有一个图像分类器
这是它在Xcode中的样子


385
00:23:06,220 --> 00:23:08,589 line:-1
这是一些关于该模型的高级描述


386
00:23:08,889 --> 00:23:12,593 line:-2
如果你能看到它的内部
很可能这是一个神经网络


387
00:23:13,026 --> 00:23:16,063 line:-1
而且很可能是一个卷积神经网络


388
00:23:16,129 --> 00:23:19,399 line:-2
所以它会有很多层
卷积层 激活层


389
00:23:20,367 --> 00:23:21,635 line:-1
现在可能会发生这种情况


390
00:23:21,702 --> 00:23:23,971 line:-1
即有一个新的激活层出现


391
00:23:24,037 --> 00:23:25,472 line:-1
而Core ML还不支持它


392
00:23:25,772 --> 00:23:26,607 line:-1
并且…


393
00:23:27,341 --> 00:23:30,277 line:-1
就像在每次机器学习会议上一样


394
00:23:30,344 --> 00:23:32,713 line:-1
研究人员总是在提出新的层


395
00:23:32,779 --> 00:23:34,214 line:-1
所以这是一个很常见的情况


396
00:23:35,048 --> 00:23:36,216 line:-1
如果发生这种情况


397
00:23:36,483 --> 00:23:40,888 line:-1
你只需要使用这个新层的自定义实现


398
00:23:41,321 --> 00:23:44,258 line:-2
然后你就准备好了
这就是这个模型的样子


399
00:23:44,324 --> 00:23:47,327 line:-1
唯一的区别是在底部的


400
00:23:47,394 --> 00:23:48,495 line:-1
这个依赖部分


401
00:23:49,363 --> 00:23:50,364 line:-1
其中…


402
00:23:51,431 --> 00:23:54,601 line:-2
具有这个模型所包含的
这个自定义层的描述


403
00:23:55,169 --> 00:23:56,837 line:-1
我们来看看另一个例子


404
00:23:57,004 --> 00:23:59,940 line:-2
假设我们有一个非常简单的
数字分类器


405
00:24:01,175 --> 00:24:02,342 line:-1
最近


406
00:24:02,943 --> 00:24:06,980 line:-2
我看到了一篇研究论文
它的题目是“空间变换网络”


407
00:24:07,548 --> 00:24:09,416 line:-1
它所做的事情是这样的


408
00:24:10,017 --> 00:24:13,687 line:-1
它在数字之后插入一个神经网络


409
00:24:14,154 --> 00:24:16,523 line:-1
用来定位数字的位置


410
00:24:17,291 --> 00:24:19,860 line:-1
然后将其传入一个网格采样器层


411
00:24:20,260 --> 00:24:22,229 line:-1
这会重新渲染这个数字


412
00:24:22,296 --> 00:24:25,265 line:-1
但这次它已经能够定位在数字本身上


413
00:24:25,566 --> 00:24:28,068 line:-1
然后你将它传递给你的旧分类方法


414
00:24:28,969 --> 00:24:32,339 line:-1
我们不关心这里的细节


415
00:24:32,406 --> 00:24:35,008 line:-1
但要注意的一点是


416
00:24:35,275 --> 00:24:36,944 line:-1
绿色部分是Core ML支持的


417
00:24:37,344 --> 00:24:40,581 line:-1
而红色部分是新的网格采样器层


418
00:24:40,948 --> 00:24:43,750 line:-1
是Core ML不支持的新实验层


419
00:24:44,418 --> 00:24:46,887 line:-1
我想通过这个特定模型的例子


420
00:24:47,354 --> 00:24:51,325 line:-2
来向你展示如何使用
Core ML Tools对其转换


421
00:24:51,959 --> 00:24:53,327 line:-1
现在我们来演示一下


422
00:25:00,000 --> 00:25:01,768 line:-1
我希望能够一次成功


423
00:25:03,504 --> 00:25:05,005 line:-1
好的


424
00:25:05,973 --> 00:25:06,974 line:-1
好


425
00:25:07,508 --> 00:25:09,977 line:-1
我先关闭这些窗口


426
00:25:14,648 --> 00:25:17,584 line:-1
让我清除这个


427
00:25:18,085 --> 00:25:22,856 line:-2
我也将使用
Jupyter Notebook来进行演示


428
00:25:29,930 --> 00:25:33,300 line:-1
导航到我的预训练网络的文件夹


429
00:25:34,334 --> 00:25:39,439 line:-2
你可以在这里看到我的
spatial_transformer文件


430
00:25:39,506 --> 00:25:41,441 line:-1
这是一个预训练的Keras模型


431
00:25:42,743 --> 00:25:46,380 line:-2
如果你想知道
我是如何得到这个模型的


432
00:25:48,182 --> 00:25:49,483 line:-1
基本上我做的是…


433
00:25:50,050 --> 00:25:51,418 line:-1
我可以轻松找到


434
00:25:51,485 --> 00:25:54,021 line:-1
空间变换器的开源实现


435
00:25:54,087 --> 00:25:57,057 line:-2
我刚在Keras中执行了该脚本
然后我就得到了这个模型


436
00:25:58,158 --> 00:26:02,429 line:-2
除此以外 我还有这个
网格采样器层的Python脚本


437
00:26:03,197 --> 00:26:05,866 line:-1
我正在谈论的这个网格采样器层


438
00:26:06,266 --> 00:26:08,669 line:-1
在Keras中也没有原生支持


439
00:26:09,303 --> 00:26:11,805 line:-1
所以我在网上找到的这个实现


440
00:26:12,105 --> 00:26:15,676 line:-1
使用Keras自定义层来实现该层


441
00:26:16,376 --> 00:26:20,614 line:-2
正如你所见 自定义概念
并不是Core ML独有的


442
00:26:20,914 --> 00:26:24,418 line:-2
实际上 在大多数机器学习框架中
这是非常普遍的


443
00:26:24,751 --> 00:26:27,087 line:-1
这就是人们在新层中进行实验的方法


444
00:26:27,955 --> 00:26:30,624 line:-2
好的 到目前为止
我只有一个Keras模型


445
00:26:30,824 --> 00:26:33,660 line:-2
现在我想专注于
如何获得Core ML模型


446
00:26:34,361 --> 00:26:36,230 line:-1
所以我将打开…


447
00:26:38,131 --> 00:26:39,099 line:-1
让我们看看…


448
00:26:40,000 --> 00:26:42,336 line:-2
在这里 让我启动一个
新的Python笔记本


449
00:26:44,137 --> 00:26:46,874 line:-1
我将从在Python环境中


450
00:26:46,940 --> 00:26:48,242 line:-1
导入Keras模型开始


451
00:26:51,879 --> 00:26:54,248 line:-1
先导入Keras


452
00:26:55,315 --> 00:26:57,751 line:-1
再导入我们的Keras自定义层


453
00:26:58,285 --> 00:27:00,921 line:-1
现在我将在Keras中加载模型


454
00:27:02,689 --> 00:27:04,658 line:-1
这就是你如何加载Keras模型


455
00:27:05,526 --> 00:27:07,494 line:-1
你将该部分提供给模型


456
00:27:07,561 --> 00:27:10,030 line:-2
如果有一个自定义层
就把它传给这部分


457
00:27:10,998 --> 00:27:14,468 line:-2
好的 现在我们有了这个模型
让我们将其转换为Core ML


458
00:27:15,669 --> 00:27:17,638 line:-1
我要先导入coremltools


459
00:27:18,372 --> 00:27:19,373 line:-1
执行它


460
00:27:19,907 --> 00:27:22,476 line:-1
现在 正如我之前展示给你的那样


461
00:27:22,543 --> 00:27:25,679 line:-1
只需要调用一个函数来转换它


462
00:27:26,079 --> 00:27:27,114 line:-1
我们来试试


463
00:27:28,415 --> 00:27:32,085 line:-2
这是我的调用
正如预期的那样 我得到一个错误


464
00:27:33,520 --> 00:27:35,822 line:-2
Python喜欢抛出
这些冗长的错误信息


465
00:27:36,123 --> 00:27:40,027 line:-1
但是我们真正关心的是最后一行


466
00:27:40,427 --> 00:27:41,361 line:-1
让我…


467
00:27:46,733 --> 00:27:49,002 line:0
正如我们在这最后一行所看到的那样


468
00:27:49,269 --> 00:27:51,338 line:0
采样器层不受支持


469
00:27:51,839 --> 00:27:55,142 line:0
现在我们看看怎样才能解决这个问题


470
00:27:55,742 --> 00:27:57,778 line:-1
我关掉这些以便你可以看到


471
00:27:58,445 --> 00:28:00,948 line:-1
现在我稍微改一下我的转换器调用


472
00:28:01,181 --> 00:28:03,050 line:-1
这是我的Core ML模型


473
00:28:06,019 --> 00:28:08,956 line:-1
现在我要传递一个额外的参数


474
00:28:09,223 --> 00:28:15,229 line:-2
它被称为
custom_convertions_functions


475
00:28:19,399 --> 00:28:20,801 line:-1
这是一个字典类型


476
00:28:21,401 --> 00:28:25,839 line:-2
它是从层的名称到一个
我稍后会定义的函数的映射


477
00:28:26,139 --> 00:28:27,774 line:-2
将其命名为
covert_grid_sampler


478
00:28:27,841 --> 00:28:30,511 line:-1
让我退后一步并解释这里发生的事情


479
00:28:30,577 --> 00:28:34,214 line:-1
转换器的工作方式是


480
00:28:34,281 --> 00:28:35,682 line:-1
它会遍历每个Keras层


481
00:28:36,817 --> 00:28:38,452 line:-1
先进入第一层


482
00:28:38,519 --> 00:28:40,754 line:-1
将其参数转换为Core ML


483
00:28:40,821 --> 00:28:43,857 line:-2
然后转到第二层继续转换它的参数
如此类推


484
00:28:44,625 --> 00:28:47,427 line:-2
当它碰到这个自定义层时
它不知道该怎么做


485
00:28:47,761 --> 00:28:51,398 line:-2
所以我传入的这个函数
convert_grid_sampler


486
00:28:51,965 --> 00:28:54,268 line:-1
将帮助我的转换器做到这一点


487
00:28:54,868 --> 00:28:57,171 line:-1
我们来看看这个函数长什么样


488
00:29:00,974 --> 00:29:01,975 line:-1
就是这个函数


489
00:29:02,843 --> 00:29:06,280 line:-2
这里有几行代码
但它所做的只有三件事


490
00:29:07,481 --> 00:29:11,318 line:-1
首先 它给出了一个类的名称


491
00:29:11,985 --> 00:29:13,353 line:-1
正如我们注意到的那样


492
00:29:13,420 --> 00:29:15,556 line:-1
该层的实现不在这里


493
00:29:15,889 --> 00:29:18,192 line:-1
实现将稍后在app中出现


494
00:29:18,725 --> 00:29:20,861 line:-1
它将被封装在一个类中


495
00:29:21,261 --> 00:29:24,431 line:-1
这是我们稍后将实现的类的名称


496
00:29:24,498 --> 00:29:27,768 line:-2
在转换过程中
我们只需要指定这个类名


497
00:29:28,068 --> 00:29:28,936 line:-1
就这么简单


498
00:29:29,136 --> 00:29:30,604 line:-1
然后设置其描述


499
00:29:30,804 --> 00:29:32,639 line:-1
你应该提供它


500
00:29:32,706 --> 00:29:34,541 line:-1
如果有其他人…


501
00:29:34,741 --> 00:29:38,278 line:-2
以便如果有人正在看你的模型
他们知道它是干什么的


502
00:29:39,246 --> 00:29:40,347 line:-1
第三件事基本上就是


503
00:29:40,414 --> 00:29:44,451 line:-2
将Keras层的任何参数
转换为Core ML


504
00:29:45,052 --> 00:29:47,221 line:-2
对于这个特定的层
它有两个参数


505
00:29:47,287 --> 00:29:51,091 line:-2
输出高度和输出权重
我只是把它转换成Core ML


506
00:29:51,792 --> 00:29:54,161 line:-1
如果你的自定义层没有任何参数


507
00:29:54,228 --> 00:29:57,631 line:-1
那么你不需要这样做


508
00:29:58,332 --> 00:30:01,401 line:-2
如果你的层有很多参数
它们都应该在这里


509
00:30:01,468 --> 00:30:05,072 line:-1
并且被封装在Core ML模型中


510
00:30:06,240 --> 00:30:08,509 line:-2
你可能已经注意到了
我在这里所做的一切


511
00:30:08,575 --> 00:30:11,478 line:-1
与你定义类的方式非常相似 对吗？


512
00:30:11,745 --> 00:30:13,614 line:-1
你给出一个类名 可能有一个描述


513
00:30:13,680 --> 00:30:16,817 line:-2
也许还有些参数
现在让我来执行它


514
00:30:19,853 --> 00:30:22,923 line:-1
现在我们看到转换进行得很顺利


515
00:30:25,692 --> 00:30:28,095 line:-1
让我……


516
00:30:28,929 --> 00:30:31,632 line:-1
不知道为什么 这里有点奇怪


517
00:30:35,769 --> 00:30:38,672 line:-1
如果你不介意 我把这些都删了


518
00:30:40,541 --> 00:30:42,409 line:-1
现在让我可视化这个模型


519
00:30:42,676 --> 00:30:47,147 line:-2
你可以简单的调用
Core ML Tools中的函数来做到这一点


520
00:30:47,581 --> 00:30:49,082 line:-2
这个函数叫
visualize_spec


521
00:30:50,751 --> 00:30:54,254 line:-1
这里你可以看到该模型的可视化效果


522
00:30:54,588 --> 00:30:58,458 line:-2
正如我们所看到的那样
这里是定位网络和一些层


523
00:30:58,792 --> 00:31:00,494 line:-1
这是我们的自定义层


524
00:31:00,561 --> 00:31:03,130 line:-2
如果我点击它
我可以看到它的参数


525
00:31:03,197 --> 00:31:05,699 line:-1
这是我给它的类名


526
00:31:06,700 --> 00:31:09,036 line:-1
这些是我设置的参数


527
00:31:10,037 --> 00:31:12,606 line:-2
可视化你的Core ML模型
总是一个好主意


528
00:31:13,240 --> 00:31:16,043 line:-1
在拖放之前 检查一下一切是否正常


529
00:31:17,277 --> 00:31:18,111 line:-1
好


530
00:31:19,613 --> 00:31:23,417 line:-2
不是这个笔记本
现在我要保存这个模型


531
00:31:31,158 --> 00:31:32,759 line:-1
现在我们来看看这个模型


532
00:31:34,094 --> 00:31:35,829 line:-1
让我关闭它


533
00:31:37,297 --> 00:31:38,298 line:-1
好的


534
00:31:42,669 --> 00:31:45,372 line:-1
让我导航到


535
00:31:46,807 --> 00:31:48,108 line:-1
这个目录


536
00:31:51,845 --> 00:31:54,348 line:-2
我的模型在这里
如果我点击并在Xcode中查看它


537
00:31:54,414 --> 00:31:58,352 line:-2
看看它是什么样的
我们可以看到它在这里有


538
00:31:59,119 --> 00:32:00,487 line:-1
一个自定义网格描述


539
00:32:01,522 --> 00:32:03,457 line:-1
让我们回到幻灯片


540
00:32:10,297 --> 00:32:14,768 line:-2
我们刚刚看到的是
只用几行简单的代码


541
00:32:14,835 --> 00:32:17,538 line:-2
我们就可以轻松将函数
转换为Core ML


542
00:32:17,804 --> 00:32:19,973 line:-2
这过程和你用TensorFlow
转换器或ONNX转换器


543
00:32:20,374 --> 00:32:23,944 line:-1
的过程几乎是一样的


544
00:32:25,245 --> 00:32:27,447 line:-1
左边是我们的模型


545
00:32:28,248 --> 00:32:30,083 line:-1
带参数的自定义层模型


546
00:32:30,484 --> 00:32:32,753 line:-1
当你将此模型拖放到Xcode中时


547
00:32:33,453 --> 00:32:36,023 line:-1
你需要在一个文件中提供该类的实现


548
00:32:36,423 --> 00:32:39,726 line:-2
比如gridSampler.swift
这就是这个文件的样子


549
00:32:40,260 --> 00:32:45,599 line:-1
这就是你的类 它有一个初始化函数


550
00:32:46,033 --> 00:32:47,100 line:-1
它将会


551
00:32:47,167 --> 00:32:50,103 line:-1
初始化模型中的任何参数


552
00:32:50,804 --> 00:32:52,840 line:-1
这个类的主要函数


553
00:32:54,741 --> 00:32:55,909 line:-1
是evaluate函数


554
00:32:58,111 --> 00:33:01,515 line:-1
这是该层需要执行的数学运算的


555
00:33:01,582 --> 00:33:04,384 line:-1
真正实现部分


556
00:33:05,185 --> 00:33:06,320 line:-1
还有另一个函数也会被调用


557
00:33:06,386 --> 00:33:08,088 line:-2
这个outputShapes
(forInputShapes)函数


558
00:33:08,155 --> 00:33:10,891 line:-1
它会指定该层产生的


559
00:33:10,958 --> 00:33:12,159 line:-1
输出区域的大小


560
00:33:12,526 --> 00:33:16,296 line:-2
这有助于Core ML在加载时
分配缓冲区大小


561
00:33:16,930 --> 00:33:19,633 line:-1
以便你的app在运行时更高效


562
00:33:21,969 --> 00:33:26,507 line:-2
我们刚刚看到你将如何处理
神经网络中的一个新层


563
00:33:27,174 --> 00:33:30,177 line:-1
有一个非常类似于自定义层的概念


564
00:33:30,244 --> 00:33:32,513 line:-1
它被称为自定义模型


565
00:33:33,280 --> 00:33:36,750 line:-1
它们的原理差不多 但它更具通用性


566
00:33:37,217 --> 00:33:41,555 line:-2
对于自定义模型
你可以处理任何类型的网络


567
00:33:41,755 --> 00:33:44,858 line:-1
它不一定是一个神经网络


568
00:33:45,292 --> 00:33:48,662 line:-1
并且在整体上能给你更多的灵活性


569
00:33:50,564 --> 00:33:53,300 line:-2
让我总结一下这次演讲
我们看到…


570
00:33:54,601 --> 00:33:58,939 line:-2
Core ML Tools的
这个生态系统有多丰富


571
00:33:59,006 --> 00:34:00,340 line:-1
这对你们来说很棒


572
00:34:00,407 --> 00:34:03,810 line:-2
因为现在你有更多的选择
来获得Core ML模型


573
00:34:04,478 --> 00:34:06,747 line:-2
我们看到量化Core ML模型
是多么容易


574
00:34:08,215 --> 00:34:12,485 line:-1
我们还看到只需几行代码


575
00:34:13,920 --> 00:34:18,257 line:-2
我们就可以很轻松地在模型中
集成一个新的自定义层


576
00:34:20,726 --> 00:34:23,429 line:-2
你可以在我们的文档页面
找到更多信息


577
00:34:23,597 --> 00:34:25,632 line:-1
欢迎来实验室并与我们交谈


578
00:34:26,166 --> 00:34:27,201 line:-1
好的 谢谢

