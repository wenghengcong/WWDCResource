1
00:00:17,384 --> 00:00:21,555 line:0
（Core Image：
性能、原型和Python）


2
00:00:21,622 --> 00:00:22,623 line:0
（演讲719）


3
00:00:23,524 --> 00:00:24,358 line:-1
好


4
00:00:24,791 --> 00:00:25,626 line:-1
谢谢


5
00:00:27,294 --> 00:00:28,395 line:-1
大家下午好


6
00:00:28,462 --> 00:00:31,098 line:-2
感谢今天参加
Core Image会议


7
00:00:31,398 --> 00:00:32,533 line:-1
我叫David Hayward


8
00:00:32,698 --> 00:00:35,802 line:-2
我很高兴能够向大家介绍
我们团队在最近一年


9
00:00:35,869 --> 00:00:39,373 line:-1
添加到Core Image的


10
00:00:39,439 --> 00:00:40,541 line:-1
新性能及原型功能


11
00:00:41,041 --> 00:00:43,744 line:-2
我们有很多内容
所以让我们进入议程


12
00:00:44,511 --> 00:00:46,713 line:-1
今天要谈的第一件事就是


13
00:00:46,780 --> 00:00:49,116 line:-2
我们添加到Core Image的
一些很棒的新API


14
00:00:49,183 --> 00:00:51,785 line:-1
用以提高app的性能


15
00:00:52,319 --> 00:00:55,122 line:-1
之后 我们将转入另一个话题


16
00:00:55,189 --> 00:00:56,657 line:-1
即如何使用Core Image


17
00:00:56,723 --> 00:00:58,792 line:-1
以帮助原型新算法的开发


18
00:00:59,193 --> 00:01:02,362 line:-2
最后 我们将讨论
如何使用Core Image


19
00:01:02,629 --> 00:01:05,632 line:-1
配合各种机器学习app


20
00:01:07,568 --> 00:01:09,803 line:-1
好 让我们开始


21
00:01:09,870 --> 00:01:11,505 line:-1
首先我们来说说性能API


22
00:01:11,572 --> 00:01:14,241 line:-1
今年 我们重点在两个领域


23
00:01:14,775 --> 00:01:15,676 line:-1
致力于提高性能


24
00:01:15,742 --> 00:01:18,278 line:-1
首先 我们新添了一些对插入


25
00:01:18,512 --> 00:01:19,813 line:-1
中间缓冲区的控制


26
00:01:19,980 --> 00:01:21,615 line:-1
我们将详细讨论这个问题


27
00:01:21,949 --> 00:01:23,684 line:-1
第二 我们将谈谈


28
00:01:23,750 --> 00:01:28,021 line:-2
你可以利用的
一些新CI内核语言功能


29
00:01:28,088 --> 00:01:31,358 line:-1
我们先来谈谈中间缓冲区


30
00:01:33,227 --> 00:01:35,495 line:-2
若你曾用过Core Image
那么你知道


31
00:01:35,562 --> 00:01:39,833 line:-2
Core Image让你轻松地
将过滤器序列连接在一起


32
00:01:40,167 --> 00:01:43,770 line:0
Core Image中每个过滤器
都由一个或多个内核组成


33
00:01:44,071 --> 00:01:46,173 line:0
Core Image的一项重要的


34
00:01:46,240 --> 00:01:49,376 line:0
提高性能的功能是连接内核


35
00:01:49,443 --> 00:01:51,979 line:0
以减少中间缓冲区的数量


36
00:01:52,145 --> 00:01:54,882 line:0
许多情况下
要获得你想要的最佳性能


37
00:01:54,948 --> 00:01:56,550 line:-1
你需要尽量减少缓冲区数


38
00:01:57,484 --> 00:01:59,486 line:-1
但是 有一些情况


39
00:01:59,786 --> 00:02:03,190 line:-1
你不希望最大量地连接


40
00:02:03,857 --> 00:02:06,793 line:-2
例如 你的app里
可能有一个昂贵的过滤器


41
00:02:06,860 --> 00:02:08,461 line:-1
在过滤器链的早期


42
00:02:09,329 --> 00:02:10,864 line:-1
你的app的用户


43
00:02:10,931 --> 00:02:13,333 line:-1
在某个时刻可能正在调整


44
00:02:13,400 --> 00:02:14,768 line:-1
在图中跟随它的过滤器


45
00:02:15,135 --> 00:02:16,703 line:-1
这是一个经典的情况


46
00:02:16,770 --> 00:02:19,173 line:-1
中间缓冲区是个好主意


47
00:02:20,007 --> 00:02:22,109 line:-1
在介于两者之间的位置


48
00:02:22,809 --> 00:02:25,913 line:0
通过设这个中间缓冲区


49
00:02:26,180 --> 00:02:28,182 line:0
调整辅助过滤器时


50
00:02:28,415 --> 00:02:30,551 line:0
无需两次付出


51
00:02:30,717 --> 00:02:33,554 line:0
昂贵的过滤器的成本


52
00:02:34,087 --> 00:02:35,956 line:0
那么如何在app中操作？


53
00:02:36,023 --> 00:02:38,325 line:0
我们有一个新的API 顾名思义


54
00:02:38,859 --> 00:02:40,027 line:0
insertingIntermediate


55
00:02:40,794 --> 00:02:43,664 line:-1
我们谈谈这会如何影响我们的结果


56
00:02:43,730 --> 00:02:45,432 line:-1
我们所做的不是


57
00:02:45,499 --> 00:02:46,500 line:-1
尽可能多地连接


58
00:02:46,667 --> 00:02:49,136 line:-1
我们会尊重中间缓冲区的位置


59
00:02:49,369 --> 00:02:51,772 line:0
并尽可能多地连接它


60
00:02:53,207 --> 00:02:54,241 line:-1
这里有几点说明


61
00:02:54,308 --> 00:02:55,442 line:-1
要记住一件事


62
00:02:55,709 --> 00:02:57,244 line:-1
默认情况下


63
00:02:57,311 --> 00:02:59,413 line:-2
Core Image
对所有中间缓冲区作缓存


64
00:02:59,479 --> 00:03:02,249 line:-1
为后续生成作准备


65
00:03:02,516 --> 00:03:03,717 line:-1
使之速度会更快


66
00:03:04,051 --> 00:03:05,986 line:-1
但是 有些时候


67
00:03:06,053 --> 00:03:08,856 line:-1
你会想关闭中间缓冲区的缓存


68
00:03:09,389 --> 00:03:13,093 line:-1
例如 如果你的app将要批量导出


69
00:03:13,160 --> 00:03:14,428 line:-1
100张图片


70
00:03:14,928 --> 00:03:17,364 line:-1
缓存第一个无益


71
00:03:17,431 --> 00:03:20,601 line:-1
因为后续生成的图像将完全不同


72
00:03:20,667 --> 00:03:22,669 line:-1
所以 你可以在你的app中实现它


73
00:03:22,736 --> 00:03:25,472 line:-2
使用上下文选项
cacheIntermediates


74
00:03:25,539 --> 00:03:27,040 line:-1
并将该值设置为false


75
00:03:28,542 --> 00:03:31,311 line:-1
但如果你也在使用这个我们刚谈到的


76
00:03:31,378 --> 00:03:32,279 line:-1
新API


77
00:03:32,713 --> 00:03:35,582 line:-1
你仍然可以打开中间缓冲区的缓存


78
00:03:35,649 --> 00:03:37,951 line:-1
即使此上下文选项是关闭的


79
00:03:38,318 --> 00:03:40,787 line:-1
所以 这可以让你真正确保


80
00:03:40,854 --> 00:03:42,756 line:-1
缓存需要的 不缓存任何其它内容


81
00:03:45,526 --> 00:03:47,461 line:-1
我想谈的下一个主题


82
00:03:47,528 --> 00:03:50,797 line:-1
是我们添加到内核语言的


83
00:03:51,732 --> 00:03:53,600 line:-1
一些应用图像处理的新功能


84
00:03:55,068 --> 00:03:57,304 line:-1
请记住 我们有两种方法


85
00:03:57,371 --> 00:03:59,706 line:-1
在Core Image中编写内核


86
00:04:00,307 --> 00:04:03,510 line:-1
传统的方法是CI内核语言


87
00:04:03,944 --> 00:04:06,813 line:-2
在这种情况下
源文件中有一个字符串


88
00:04:06,880 --> 00:04:09,249 line:-2
你的Swift代码
或你的objective C代码


89
00:04:09,583 --> 00:04:11,652 line:-1
在运行时 你调用


90
00:04:11,718 --> 00:04:13,754 line:-1
内核及源代码


91
00:04:14,688 --> 00:04:18,325 line:-1
稍后 当你基于该内核创建图像时


92
00:04:18,492 --> 00:04:21,228 line:-1
你可以生成任何类型的CI上下文


93
00:04:21,295 --> 00:04:25,566 line:-2
不论该上下文是由Metal
还是Open GL支持


94
00:04:26,934 --> 00:04:30,337 line:-1
然而 当生成时 需要翻译该源


95
00:04:30,404 --> 00:04:33,240 line:-2
需要将其翻译为
Metal或GLSL


96
00:04:33,607 --> 00:04:35,609 line:-1
并且这个步骤有成本


97
00:04:36,310 --> 00:04:40,113 line:0
最后 该代码被编译为GPU指令集


98
00:04:40,180 --> 00:04:41,181 line:-1
然后执行


99
00:04:42,616 --> 00:04:44,785 line:0
从去年的iOS 11开始


100
00:04:44,852 --> 00:04:46,987 line:0
我们添加了一种
编写CI内核的新方法


101
00:04:47,054 --> 00:04:48,956 line:0
具有一些显著优势


102
00:04:49,122 --> 00:04:52,059 line:0
这就是基于
Metal着色语言的CI内核


103
00:04:52,593 --> 00:04:55,596 line:0
这种情况下 你的项目中有源代码


104
00:04:55,662 --> 00:05:00,367 line:0
并且此源是在build时
而不是在运行时编译的


105
00:05:01,502 --> 00:05:05,606 line:0
和以前一样
你可以根据此代码建内核


106
00:05:06,106 --> 00:05:10,277 line:0
使用带有Metal函数名
和二进制数据的内核


107
00:05:12,012 --> 00:05:16,383 line:0
其优势点是可以应用此数据


108
00:05:16,450 --> 00:05:18,886 line:0
而无需耗用额外编译资源


109
00:05:19,486 --> 00:05:23,690 line:-2
需要注意的是
它适用Metal支持的CI上下文


110
00:05:24,258 --> 00:05:26,126 line:-1
但它带来了巨大的性能优势


111
00:05:27,928 --> 00:05:29,897 line:-1
所以 从这个版本开始


112
00:05:29,963 --> 00:05:33,333 line:-1
我们将把CI内核语言标为已弃用


113
00:05:33,700 --> 00:05:36,303 line:-1
因为 虽然我们会继续支持这种语言


114
00:05:37,237 --> 00:05:39,706 line:-2
我们认为编写
Metal内核的新方法


115
00:05:39,773 --> 00:05:42,142 line:-1
为作为开发人员的你提供了很多优势


116
00:05:42,376 --> 00:05:45,479 line:-2
首先 你获得了
我之前概述的性能优势


117
00:05:45,546 --> 00:05:50,083 line:-2
它同时还提供了
build时代码语法着色


118
00:05:50,150 --> 00:05:52,619 line:-1
和优秀的调试工具的优势


119
00:05:52,920 --> 00:05:55,489 line:-1
如果你使用Metal源的话


120
00:05:57,958 --> 00:05:59,092 line:-1
好


121
00:06:03,630 --> 00:06:06,900 line:-1
考虑到这一点 我想谈谈其它几个


122
00:06:06,967 --> 00:06:09,469 line:-1
我们添加到内核语言中的功能


123
00:06:09,536 --> 00:06:11,738 line:-1
首先 我们增加了半浮动支持


124
00:06:12,139 --> 00:06:14,541 line:-1
很多情况下


125
00:06:14,741 --> 00:06:17,778 line:-1
当你的CI内核可完全


126
00:06:18,278 --> 00:06:20,547 line:-1
满足于半浮动带来的精度


127
00:06:20,781 --> 00:06:22,816 line:-1
如果你使用RGB颜色值


128
00:06:22,883 --> 00:06:24,852 line:-1
半浮点精度绰绰有余


129
00:06:25,419 --> 00:06:27,421 line:-1
在内核中使用半浮点数的优点


130
00:06:27,487 --> 00:06:29,523 line:-1
是它使操作运行得更快


131
00:06:29,590 --> 00:06:31,258 line:-1
尤其是在A11设备上


132
00:06:31,491 --> 00:06:32,626 line:-1
如iPhone 10


133
00:06:33,360 --> 00:06:35,996 line:-1
在内核中用半浮点数的另一个优点


134
00:06:36,063 --> 00:06:37,764 line:-1
它允许更小的寄存器


135
00:06:37,831 --> 00:06:40,200 line:-1
增加了GPU的利用率


136
00:06:40,267 --> 00:06:41,635 line:-1
这也有助于提高性能


137
00:06:42,236 --> 00:06:45,038 line:-2
今年我们在内核语言中
加了另一个精彩的功能


138
00:06:45,105 --> 00:06:47,040 line:-1
即对组读取的支持


139
00:06:47,274 --> 00:06:49,443 line:-2
只用一条指令
你的着色器能够执行


140
00:06:49,510 --> 00:06:52,045 line:-1
来自输入图像的四个


141
00:06:52,412 --> 00:06:54,114 line:-1
单通道读取


142
00:06:54,181 --> 00:06:55,382 line:-1
这真的有很大帮助


143
00:06:56,517 --> 00:06:58,252 line:-1
作为补充


144
00:06:58,318 --> 00:07:00,721 line:-1
我们还可以写像素组


145
00:07:01,088 --> 00:07:04,157 line:0
即只需在着色器中一条指令
你就可以


146
00:07:04,458 --> 00:07:06,960 line:0
写入图像的四个像素


147
00:07:08,428 --> 00:07:10,264 line:-1
所有这三个功能


148
00:07:10,330 --> 00:07:15,302 line:-1
都可以用于着色器中极大地提高性能


149
00:07:15,369 --> 00:07:18,071 line:-1
我来谈一谈如何运作的例子


150
00:07:18,772 --> 00:07:22,976 line:-2
想象一下你有一个简单的
3乘3卷积内核


151
00:07:23,710 --> 00:07:26,547 line:-1
用于一个图像的一个通道


152
00:07:26,613 --> 00:07:28,315 line:-1
这是一种相当常见的操作


153
00:07:28,382 --> 00:07:31,084 line:-1
例如要锐化图像的亮度


154
00:07:31,485 --> 00:07:35,522 line:-2
在这样的内核中
通常每次调用内核时


155
00:07:35,923 --> 00:07:39,326 line:-1
它负责产生一个输出像素


156
00:07:39,860 --> 00:07:42,129 line:-1
但是因为这是一个三乘三的卷积


157
00:07:42,629 --> 00:07:45,132 line:-1
你的内核需要读取9个像素


158
00:07:45,699 --> 00:07:47,234 line:0
以达到这个效果


159
00:07:47,301 --> 00:07:50,103 line:0
因此 我们每写一个像素
就需读取个像素


160
00:07:51,371 --> 00:07:52,673 line:0
但我们通过新的组写功能


161
00:07:52,739 --> 00:07:55,909 line:0
改进这一点


162
00:07:56,310 --> 00:07:57,945 line:-1
使用新的组写功能


163
00:07:58,011 --> 00:08:02,950 line:-2
你的内核可以一次调用
写出二乘二的一组像素


164
00:08:03,383 --> 00:08:06,053 line:-1
当然这二乘二小组有点大


165
00:08:06,119 --> 00:08:07,788 line:-1
所以不再是三乘三


166
00:08:08,121 --> 00:08:11,124 line:-1
而是四乘四像素读取


167
00:08:11,191 --> 00:08:13,627 line:-1
以写出这四个像素


168
00:08:14,394 --> 00:08:15,529 line:-1
我们算一下


169
00:08:15,896 --> 00:08:19,700 line:0
这意味着我们有16像素读取
4像素写入


170
00:08:19,766 --> 00:08:22,135 line:-1
所以我们已经看到了这方面的优势


171
00:08:24,972 --> 00:08:28,642 line:-1
我们的另一个功能是收集


172
00:08:29,076 --> 00:08:33,547 line:-2
在这个例子中
我们读取4乘4或16像素


173
00:08:33,614 --> 00:08:34,615 line:-1
有了这个功能


174
00:08:34,780 --> 00:08:38,818 line:-2
我们只需要四条指令
即可完成这16个红色像素


175
00:08:39,753 --> 00:08:41,554 line:0
如果你计算一下


176
00:08:41,621 --> 00:08:43,490 line:0
这意味着我们每写入四个像素


177
00:08:43,557 --> 00:08:44,925 line:0
只进行了四次读取


178
00:08:45,259 --> 00:08:47,628 line:0
这确实有助于提高性能


179
00:08:47,794 --> 00:08:50,731 line:-2
我们通过实际内核代码
了解一下这个过程


180
00:08:51,932 --> 00:08:55,736 line:-1
这是一个简单卷积的例子


181
00:08:55,802 --> 00:08:57,037 line:-1
就像我刚才描述的


182
00:08:57,437 --> 00:08:59,673 line:-1
这里 我们从输入图像


183
00:08:59,740 --> 00:09:01,241 line:-1
做九个样本


184
00:09:01,441 --> 00:09:03,310 line:-1
我们只用它的红色通道


185
00:09:04,144 --> 00:09:05,879 line:-1
一旦我们得到这九个值


186
00:09:05,946 --> 00:09:07,514 line:-1
我们将对这九个值进行平均


187
00:09:07,581 --> 00:09:09,283 line:-1
并以传统方式写出来


188
00:09:09,349 --> 00:09:12,119 line:-1
返回单个vec4像素值


189
00:09:14,154 --> 00:09:17,024 line:-2
加速的第一步
是将其转换为Metal


190
00:09:17,090 --> 00:09:18,325 line:-1
这实际上很简单


191
00:09:18,392 --> 00:09:20,394 line:-1
我们从像这样的代码开始


192
00:09:20,460 --> 00:09:22,462 line:-1
这是我们传统的CI内核语言


193
00:09:22,529 --> 00:09:24,965 line:-1
如果在代码中进行一些搜索和替换


194
00:09:25,032 --> 00:09:29,203 line:-2
你可以将其更新为
基于Metal的CI内核语言


195
00:09:29,269 --> 00:09:31,371 line:-1
这里请注意几件重要的事情


196
00:09:31,438 --> 00:09:34,908 line:-1
我们为内核添加了一个目标参数


197
00:09:34,975 --> 00:09:35,876 line:-1
这对我们很重要


198
00:09:35,943 --> 00:09:39,680 line:-1
如果我们要检查着色器中的目标坐标


199
00:09:39,746 --> 00:09:42,216 line:-1
像这样的类似卷积的内核


200
00:09:42,983 --> 00:09:45,085 line:-1
我们用新的、更现代的语法


201
00:09:45,152 --> 00:09:49,990 line:-2
只需说s.sample和s.transform
即可从输入中进行采样


202
00:09:51,124 --> 00:09:53,327 line:-1
我们在更新此代码时做的最后一件事


203
00:09:53,393 --> 00:09:57,064 line:-2
是更改传统的vec4
和vec2参数类型


204
00:09:57,130 --> 00:09:59,233 line:-1
到float4和float2


205
00:10:00,701 --> 00:10:02,870 line:-1
但我们看到 代码的整体架构


206
00:10:02,936 --> 00:10:04,738 line:-1
内核的流程是一样的


207
00:10:06,773 --> 00:10:09,610 line:-1
好 第二步是使用半浮动


208
00:10:10,077 --> 00:10:12,579 line:-1
这个例子我们可以


209
00:10:12,646 --> 00:10:14,481 line:-1
只使用半浮点数的精度


210
00:10:14,548 --> 00:10:16,517 line:-1
因为我们只是处理颜色值


211
00:10:16,583 --> 00:10:19,786 line:-2
我们将再次对代码
进行一些非常简单的更改


212
00:10:20,220 --> 00:10:25,058 line:-1
基本上代码中曾使用浮点精度的位置


213
00:10:25,125 --> 00:10:27,227 line:-1
我们将使用半浮点精度


214
00:10:27,294 --> 00:10:30,397 line:-2
这表示sampler参数
和destination参数


215
00:10:30,464 --> 00:10:32,666 line:-1
有一个_h后缀


216
00:10:33,367 --> 00:10:37,237 line:-2
以及代码中的float4
全部变为half4


217
00:10:38,071 --> 00:10:39,973 line:-1
这很简单易行


218
00:10:40,040 --> 00:10:43,110 line:-2
还有一件事要注意
如果你的代码中有常数


219
00:10:43,177 --> 00:10:45,279 line:-1
确保在它们的末尾加h


220
00:10:45,345 --> 00:10:47,014 line:-1
比如除以9.0


221
00:10:48,849 --> 00:10:50,617 line:-1
这也很简单


222
00:10:51,084 --> 00:10:52,853 line:-1
为了获得此示例中的最佳性能


223
00:10:52,920 --> 00:10:55,088 line:-1
我们要做的最后一件事


224
00:10:55,155 --> 00:10:57,291 line:-1
是利用组读取和组写入


225
00:10:57,357 --> 00:10:59,726 line:-1
我们看看完成这个的代码


226
00:11:00,661 --> 00:11:03,897 line:-1
我们想写一个二乘二的像素组


227
00:11:03,964 --> 00:11:07,201 line:-1
并且我们需要从四乘四像素组中读取


228
00:11:08,101 --> 00:11:11,271 line:-1
首先我们想要指定一个组目的地


229
00:11:11,338 --> 00:11:13,807 line:-1
我们看一下函数声明


230
00:11:13,874 --> 00:11:15,576 line:-1
它现在有一个组目的地


231
00:11:16,143 --> 00:11:17,444 line:-1
h数据类型


232
00:11:18,345 --> 00:11:20,914 line:-1
我们将像以前一样获得目标坐标


233
00:11:20,981 --> 00:11:22,883 line:-1
指向像素的中心


234
00:11:22,950 --> 00:11:25,586 line:-1
但该坐标实际上代表了


235
00:11:25,953 --> 00:11:29,590 line:-1
一组二乘二像素的坐标


236
00:11:30,657 --> 00:11:32,025 line:-1
接下来为了填充这组


237
00:11:32,226 --> 00:11:35,395 line:-1
二乘二像素 我们要做的是


238
00:11:35,462 --> 00:11:37,164 line:-1
从图像中作一堆读取


239
00:11:37,965 --> 00:11:39,833 line:-1
所以 第一次收集读取


240
00:11:40,167 --> 00:11:42,736 line:-1
将从二乘二像素组中读


241
00:11:43,170 --> 00:11:46,440 line:-1
这里 我们16像素的左下角


242
00:11:47,074 --> 00:11:53,714 line:-2
它将以half4数组
返回红色通道的值


243
00:11:54,848 --> 00:11:57,618 line:-1
这四个参数将按此顺序存储


244
00:11:57,684 --> 00:12:02,456 line:-2
即x、y、z、w
以逆时针方向运行


245
00:12:02,623 --> 00:12:04,758 line:-1
如果你熟悉Metal中的收集操作


246
00:12:04,825 --> 00:12:08,896 line:-1
这与Metal中使用的方向相同


247
00:12:10,364 --> 00:12:11,832 line:-1
所以用一条指令


248
00:12:11,899 --> 00:12:14,668 line:-2
我们完成了四次读取
我们将为其它四像素组


249
00:12:14,735 --> 00:12:16,036 line:-1
重复此过程


250
00:12:16,103 --> 00:12:20,307 line:-2
我们可以得到第二
第三和第四组


251
00:12:20,774 --> 00:12:22,609 line:-1
现在我们完成了所有16次读取


252
00:12:22,676 --> 00:12:25,846 line:-1
我们需要弄清楚哪些值在哪些位置


253
00:12:26,146 --> 00:12:27,648 line:-1
所以我们首先要做的是


254
00:12:27,714 --> 00:12:31,685 line:-1
得到这个三乘三子组的适当通道


255
00:12:32,553 --> 00:12:34,121 line:-1
并将它们平均在一起


256
00:12:34,354 --> 00:12:36,456 line:-1
然后我们把这些频道


257
00:12:36,890 --> 00:12:38,792 line:-1
存入r1变量


258
00:12:39,526 --> 00:12:40,994 line:-1
我们将重复这一过程


259
00:12:41,061 --> 00:12:46,700 line:-2
写入其它四个结果像素：
r1、r2、r3和r4


260
00:12:47,501 --> 00:12:50,637 line:-1
我们要做的最后一件事就是目标写入


261
00:12:51,004 --> 00:12:53,740 line:-1
在一次操作中写入四个像素


262
00:12:54,274 --> 00:12:57,177 line:-1
注意 这与传统的CI内核略有不同


263
00:12:57,244 --> 00:13:00,147 line:-1
过去我们从内核返回一个值


264
00:13:00,214 --> 00:13:03,750 line:-1
而现在我们将调用目标写入


265
00:13:05,552 --> 00:13:08,422 line:-1
好 这一切的精彩之处是


266
00:13:08,722 --> 00:13:10,224 line:-1
只需很少的努力


267
00:13:10,290 --> 00:13:13,794 line:-2
我们可以在同样的着色器中
获得两倍的性能


268
00:13:13,861 --> 00:13:14,828 line:-1
这是一个非常简单的着色器


269
00:13:14,895 --> 00:13:16,797 line:-1
你可获得类似的结果


270
00:13:16,864 --> 00:13:18,065 line:-1
可在许多其它类型的着色器中实现


271
00:13:18,131 --> 00:13:20,200 line:-1
尤其是作卷积的那些


272
00:13:20,634 --> 00:13:24,304 line:-1
这是为内核提高性能的好方法


273
00:13:25,172 --> 00:13:27,441 line:0
我想告诉大家


274
00:13:27,508 --> 00:13:31,345 line:0
来看看这个很棒的内核语言新文档


275
00:13:31,645 --> 00:13:33,347 line:0
不论是传统的CI内核语言


276
00:13:33,413 --> 00:13:36,450 line:0
还是基于Metal的CI内核语言


277
00:13:36,517 --> 00:13:39,052 line:0
我强烈建议你阅读本文档


278
00:13:39,419 --> 00:13:41,655 line:0
现在我们讲过了为内核运行


279
00:13:41,722 --> 00:13:42,956 line:-1
提高性能的问题


280
00:13:43,490 --> 00:13:46,960 line:-1
我想请Emmanuel上台


281
00:13:47,027 --> 00:13:49,796 line:-1
来讲如何使你的新算法的


282
00:13:49,863 --> 00:13:50,864 line:-1
开发过程更快


283
00:13:55,702 --> 00:13:56,537 line:-1
谢谢 David


284
00:13:59,139 --> 00:14:00,307 line:-1
大家下午好


285
00:14:00,774 --> 00:14:01,775 line:-1
很高兴来到这里


286
00:14:01,842 --> 00:14:04,344 line:-2
我叫Emmanuel
Core Image团队的工程师


287
00:14:05,412 --> 00:14:07,447 line:-1
本场会议的下半场时间


288
00:14:07,648 --> 00:14:10,217 line:-2
我们将把注意力
从Core Image引擎移开


289
00:14:10,284 --> 00:14:14,154 line:-2
转而探索用Core Image
作原型设计的新方法


290
00:14:14,788 --> 00:14:16,657 line:-1
我们还会看看


291
00:14:16,723 --> 00:14:19,860 line:-2
如何在机器学习app中
利用Core Image


292
00:14:19,927 --> 00:14:20,894 line:-1
我们开始吧


293
00:14:22,329 --> 00:14:24,064 line:-1
既然我们谈到原型设计


294
00:14:24,131 --> 00:14:27,868 line:-2
我们先看看图像处理过滤器的
生命周期


295
00:14:30,137 --> 00:14:33,440 line:-1
比如我们想做


296
00:14:33,507 --> 00:14:35,742 line:-1
前景背景分割


297
00:14:35,809 --> 00:14:39,980 line:-1
这意味着我们想得到一个掩码


298
00:14:40,047 --> 00:14:43,717 line:-2
前景为1.0
背景为0.0


299
00:14:43,784 --> 00:14:45,485 line:-1
二者之间有连续值


300
00:14:46,753 --> 00:14:48,989 line:-1
实现此类过滤器的难度


301
00:14:49,056 --> 00:14:51,592 line:-1
很大程度上取决于数据的特性


302
00:14:51,658 --> 00:14:56,129 line:-2
例如 如果你有一个
额外的深度缓冲区


303
00:14:56,296 --> 00:14:58,298 line:-1
与你的RGB图像一起


304
00:14:58,565 --> 00:15:00,267 line:-1
事情可以变得更容易


305
00:15:00,534 --> 00:15:04,338 line:-2
如果你有兴趣将RGB图像
与深度信息相结合


306
00:15:04,872 --> 00:15:07,241 line:0
我强烈建议你查看


307
00:15:07,307 --> 00:15:09,243 line:0
用深度创建照片和视频效果的演讲


308
00:15:10,444 --> 00:15:14,114 line:-1
今天我不想专注于这些其它信息来源


309
00:15:14,181 --> 00:15:16,450 line:-1
我想专注于一般的原型设计


310
00:15:18,852 --> 00:15:23,290 line:-1
假设我们已经完成了这个过滤器


311
00:15:23,357 --> 00:15:25,559 line:-1
我们知道我们想要达到的效果


312
00:15:25,626 --> 00:15:28,395 line:-1
在这种特殊情况下 前景和背景掩码


313
00:15:28,462 --> 00:15:31,298 line:-1
下一步我们自然而然想实现它


314
00:15:31,465 --> 00:15:33,667 line:-1
选择你最喜欢的原型


315
00:15:33,934 --> 00:15:35,135 line:-1
然后就开始尝试了


316
00:15:35,736 --> 00:15:38,906 line:-1
并将不同的过滤器组合在一起并显示


317
00:15:38,972 --> 00:15:42,409 line:-1
以达到你寻找的过滤效果


318
00:15:43,877 --> 00:15:45,345 line:-1
假设你这么做了


319
00:15:45,412 --> 00:15:50,551 line:-2
这里我们有一个
前景到背景掩码的例子


320
00:15:51,552 --> 00:15:53,754 line:-1
如你在iOS或macOS环境中


321
00:15:54,054 --> 00:15:57,591 line:-1
下一个步骤自然而然是实施该算法


322
00:15:57,658 --> 00:16:01,295 line:-1
你可以使用各种生成后端


323
00:16:01,361 --> 00:16:02,196 line:-1
如Core Image


324
00:16:04,631 --> 00:16:06,466 line:-1
Metal及Metal性能着色器


325
00:16:06,700 --> 00:16:09,236 line:-2
及vImage
如果你想留在CPU上


326
00:16:10,337 --> 00:16:14,408 line:-2
从原型到产品的初始转换
可能非常耗时


327
00:16:14,474 --> 00:16:18,512 line:-2
第一次生成可能看起来
不像你期望的那样


328
00:16:19,313 --> 00:16:21,648 line:-1
有各种各样的原因


329
00:16:21,715 --> 00:16:23,584 line:-1
可能导致这些像素差异


330
00:16:23,650 --> 00:16:25,452 line:-1
其中一个就是


331
00:16:25,519 --> 00:16:28,021 line:-1
过滤器在不同框架的实现方式


332
00:16:28,088 --> 00:16:29,122 line:-1
可能完全不同


333
00:16:29,590 --> 00:16:31,458 line:-1
我们看左边这个例子


334
00:16:31,525 --> 00:16:34,328 line:-2
我们有一个恒定的模糊
适用于这个漂亮的羽化


335
00:16:34,595 --> 00:16:36,029 line:-1
从前台到背景


336
00:16:36,530 --> 00:16:39,733 line:-1
这个过滤器的示例


337
00:16:39,800 --> 00:16:42,336 line:-1
可以显示各种性能优化


338
00:16:42,402 --> 00:16:43,570 line:-1
使其加速


339
00:16:44,338 --> 00:16:47,508 line:-1
这些优化会引入数字误差


340
00:16:47,574 --> 00:16:49,476 line:-1
而在过滤器堆栈中传播


341
00:16:50,077 --> 00:16:53,981 line:-2
从而可能会对过滤器输出
产生重大变化


342
00:16:55,649 --> 00:16:58,785 line:-2
当你写代码时
通常会出现的另一个问题


343
00:16:58,852 --> 00:17:00,654 line:-1
是在原型环境中


344
00:17:00,721 --> 00:17:02,489 line:-1
很多内存管理都是自动发生的


345
00:17:02,556 --> 00:17:05,526 line:-1
因此你不会经常遇到内存压力


346
00:17:05,592 --> 00:17:08,161 line:-1
直到开发的后期


347
00:17:10,297 --> 00:17:15,736 line:-1
当然 另一个需要考虑的主题是性能


348
00:17:16,369 --> 00:17:18,972 line:-1
通常 原型已经在使用CPU代码


349
00:17:19,205 --> 00:17:23,143 line:-1
我们经常高估


350
00:17:23,210 --> 00:17:25,512 line:-1
将CP代码指向GP代码的性能提高


351
00:17:25,579 --> 00:17:27,681 line:-1
以为一切都会变得实时


352
00:17:28,482 --> 00:17:31,685 line:-1
如果我们能够尽早抓住这些问题呢？


353
00:17:31,752 --> 00:17:34,221 line:-1
早到原型设计和工作流程中？


354
00:17:35,522 --> 00:17:37,424 line:-1
我们相信有这个办法


355
00:17:37,491 --> 00:17:39,426 line:-1
它叫PyCoreImage


356
00:17:39,593 --> 00:17:41,228 line:-2
Core Image的
Python绑定


357
00:17:42,262 --> 00:17:46,366 line:-2
这是结合Core Image的
高性能生成


358
00:17:46,800 --> 00:17:50,270 line:-1
和Python编程语言的灵活性


359
00:17:51,038 --> 00:17:52,239 line:-1
用Core Image时


360
00:17:52,306 --> 00:17:55,676 line:-2
你还继承了对iOS
和macOS的支持


361
00:17:55,976 --> 00:17:58,245 line:-1
以及200多个内置过滤器


362
00:17:58,912 --> 00:18:02,282 line:-2
我们来看看
PyCoreImage的细节


363
00:18:04,184 --> 00:18:06,653 line:-2
PyCoreImage
由三个主要部分组成


364
00:18:07,754 --> 00:18:10,224 line:-2
它用Core Image
作为生成后端


365
00:18:10,891 --> 00:18:13,794 line:-1
用Python作为编程接口


366
00:18:14,862 --> 00:18:18,799 line:-1
它还有一层薄薄NumPy连接代码


367
00:18:18,866 --> 00:18:21,602 line:-1
以期与现有代码库互操作


368
00:18:23,170 --> 00:18:25,706 line:-2
我们相信
PyCoreImage可以减少


369
00:18:25,772 --> 00:18:28,375 line:-1
你的原型设计和产品代码之间的摩擦


370
00:18:29,209 --> 00:18:31,211 line:0
如你想留在
以Swift为中心的环境中


371
00:18:31,278 --> 00:18:33,780 line:0
使用Swift Playground
也可以做很多事情


372
00:18:33,847 --> 00:18:35,449 line:0
我们鼓励你查看


373
00:18:35,516 --> 00:18:38,919 line:0
创建自己的
Swift Playground订阅的演讲


374
00:18:41,822 --> 00:18:45,425 line:-2
我们来看看
PyCoreImage的主要组件


375
00:18:46,159 --> 00:18:50,297 line:-2
因此 PyCoreImage利用Python
绑定objective C和PyObjC


376
00:18:50,731 --> 00:18:51,865 line:-1
而且有趣的是


377
00:18:52,232 --> 00:18:55,202 line:-2
我们自macOS 10.5
Leopard以来一直在发行PyObjC


378
00:18:56,670 --> 00:18:58,972 line:-2
它最初是作为Python
和Objective C之间的


379
00:18:59,039 --> 00:19:00,440 line:-1
双向桥实现的


380
00:19:00,741 --> 00:19:03,310 line:-2
特别是在Coco app
开发的环境下


381
00:19:03,377 --> 00:19:06,847 line:-2
但从那以后扩展到
支持大多数Apple框架


382
00:19:09,383 --> 00:19:12,085 line:-1
PyObjC的调用语法非常简单


383
00:19:12,152 --> 00:19:15,489 line:-2
获取现有Objective C代码
并用_代替:


384
00:19:15,789 --> 00:19:17,157 line:-1
还有一些细节


385
00:19:17,224 --> 00:19:20,227 line:-2
如果你想了解更多
建议查看API


386
00:19:20,994 --> 00:19:23,830 line:-1
我们以CIVector类为例


387
00:19:24,331 --> 00:19:25,832 line:-2
这里有一些
Objective C代码


388
00:19:25,899 --> 00:19:27,534 line:-1
我们创建CIVector的实例


389
00:19:27,601 --> 00:19:28,735 line:-1
调用CIVector


390
00:19:29,703 --> 00:19:31,905 line:-1
带X、Y、Z、W的向量


391
00:19:32,840 --> 00:19:34,374 line:-1
我们来看看PyObjC代码


392
00:19:34,675 --> 00:19:36,577 line:0
这非常相似
我们从Quartz伞包


393
00:19:36,643 --> 00:19:38,178 line:0
导入CIVector


394
00:19:39,046 --> 00:19:42,349 line:0
我们可以直接调用带X、Y、Z、W
的向量和CIVector类


395
00:19:44,218 --> 00:19:45,786 line:0
你要注意的是这些代码


396
00:19:45,853 --> 00:19:47,454 line:0
并不完全像Python一样


397
00:19:47,921 --> 00:19:50,324 line:0
我们将在几分钟内谈这个问题


398
00:19:53,227 --> 00:19:55,896 line:-2
现在我们来看看
PyCoreImage的类图


399
00:19:56,230 --> 00:19:58,365 line:-1
生成后端用Core Image


400
00:19:58,432 --> 00:20:00,400 line:-1
Core Image非常接近硬件


401
00:20:00,667 --> 00:20:02,436 line:-1
因此可以重定向过滤的方程


402
00:20:02,503 --> 00:20:04,505 line:-1
到最合适的生成后端


403
00:20:04,571 --> 00:20:06,607 line:-1
为你提供尽可能高的性能


404
00:20:07,374 --> 00:20:09,343 line:0
PyObjC存在于
Core Image上层


405
00:20:09,409 --> 00:20:12,880 line:0
它可以通过Core Image的
Python绑定与它通信


406
00:20:13,180 --> 00:20:15,082 line:0
由Quartz伞包提供


407
00:20:15,649 --> 00:20:18,819 line:0
Quartz伞包同时包含


408
00:20:18,886 --> 00:20:21,788 line:0
各种其它图像处理框架
如Core Graphics


409
00:20:21,855 --> 00:20:23,991 line:0
以及使用
Core Image的所有类


410
00:20:24,057 --> 00:20:26,627 line:0
例如CIVector、CIImages
和CIContext


411
00:20:28,662 --> 00:20:35,235 line:-2
PyCoreImage位于PyObjC之上
它本质上利用PyObjC


412
00:20:35,669 --> 00:20:37,504 line:-1
与Core Image通信


413
00:20:37,571 --> 00:20:40,307 line:-1
并为你做了很多简化


414
00:20:40,741 --> 00:20:44,144 line:-2
以便你在用Core Image时
没有那么多设置代码


415
00:20:44,211 --> 00:20:46,046 line:-1
我们稍后会看一下这个


416
00:20:47,014 --> 00:20:49,349 line:-1
这里很多都是通过CIMG类完成的


417
00:20:49,416 --> 00:20:53,153 line:-2
你用它通过供应商方程
与NumPy解释


418
00:20:53,787 --> 00:20:56,223 line:-1
你也可以包装NumPy缓冲区


419
00:20:56,456 --> 00:20:58,325 line:-1
直接使用类构造函数


420
00:21:00,260 --> 00:21:01,895 line:-1
让我们举一个例子


421
00:21:01,962 --> 00:21:03,797 line:-2
看如何用
PyCoreImage应用过滤器


422
00:21:03,864 --> 00:21:06,567 line:-1
你会看到这个框架多么简单和强大


423
00:21:07,134 --> 00:21:08,402 line:-1
你首先要做的是


424
00:21:08,468 --> 00:21:11,271 line:-2
从PyCoreImage包
导入你的CIMG类


425
00:21:12,072 --> 00:21:14,208 line:0
我们可以用它从文件加载图像


426
00:21:15,409 --> 00:21:18,679 line:0
注意 此时我们没有像素缓冲区


427
00:21:19,012 --> 00:21:20,647 line:0
Core Image
为图片创建配方


428
00:21:20,714 --> 00:21:22,516 line:0
在这种特殊情况下


429
00:21:22,583 --> 00:21:26,320 line:0
这个配方只是提供
从文件加载图像的指令


430
00:21:27,754 --> 00:21:29,356 line:0
你可以用过滤器


431
00:21:29,423 --> 00:21:30,657 line:0
创建更复杂的图表


432
00:21:30,724 --> 00:21:32,960 line:0
只需在其上调用CI过滤器名称


433
00:21:33,026 --> 00:21:35,529 line:0
并传递输入原色
在本例中为标准差


434
00:21:35,696 --> 00:21:38,131 line:0
可看到我们正组装一个更复杂的图形


435
00:21:38,198 --> 00:21:39,299 line:0
如果我们放大它


436
00:21:39,533 --> 00:21:41,235 line:0
我们可以看到模糊处理器


437
00:21:41,301 --> 00:21:42,202 line:0
就在中间


438
00:21:43,670 --> 00:21:45,739 line:0
如果你想获得像素缓冲区表示


439
00:21:45,806 --> 00:21:47,608 line:0
你可以在CIMG实例上


440
00:21:47,674 --> 00:21:48,909 line:0
调用生成


441
00:21:48,976 --> 00:21:52,012 line:0
你会得到一个合适的
NumPy缓冲区


442
00:21:55,782 --> 00:21:56,984 line:-1
为了做到这一点


443
00:21:57,050 --> 00:22:00,120 line:-2
我们需要对Core Image的
调用方式进行简化


444
00:22:00,187 --> 00:22:01,922 line:-1
或为你做一些设置代码


445
00:22:02,489 --> 00:22:05,993 line:-2
对于已经熟悉
Core Image的人


446
00:22:06,727 --> 00:22:08,762 line:-1
这不会让人感到意外


447
00:22:08,829 --> 00:22:10,631 line:-1
但对于不熟悉它的人


448
00:22:10,964 --> 00:22:12,432 line:-1
我们一起看看步骤


449
00:22:12,499 --> 00:22:17,237 line:-2
你将看到我们作的一些简化
以更清楚地说明问题


450
00:22:18,805 --> 00:22:22,242 line:-2
Core Image是一个
高性能的GPU图像处理框架


451
00:22:22,309 --> 00:22:24,378 line:-1
同时支持iOS和macOS


452
00:22:24,444 --> 00:22:26,713 line:-1
以及各种生成后端


453
00:22:27,881 --> 00:22:29,583 line:-1
支持大多数像素格式


454
00:22:30,417 --> 00:22:32,319 line:-1
这当然意味着位图数据


455
00:22:32,386 --> 00:22:35,122 line:-1
以及来自各供应商的原始文件


456
00:22:36,590 --> 00:22:39,359 line:-1
支持大多数文件格式


457
00:22:40,694 --> 00:22:44,898 line:-2
就像刚才说的 来自各种供应商的
位图数据和原始数据


458
00:22:44,965 --> 00:22:46,400 line:-1
支持大多数像素格式


459
00:22:46,466 --> 00:22:49,903 line:-1
例如 你可以用无符号8位加载图像


460
00:22:50,237 --> 00:22:52,172 line:-1
通过计算和半浮动


461
00:22:52,339 --> 00:22:54,908 line:-2
并在最终生成期间
完全呈现32位浮点数


462
00:22:56,343 --> 00:22:58,879 line:-2
Core Image可以为你
提取图像元数据


463
00:22:58,946 --> 00:23:03,917 line:-2
例如 捕获时间
EXIF标记以及嵌入的元数据


464
00:23:03,984 --> 00:23:07,020 line:-1
例如人像地图和人像深度信息


465
00:23:09,356 --> 00:23:11,692 line:-2
Core Image
可以很好地处理色彩管理


466
00:23:11,758 --> 00:23:15,262 line:-2
这是一个高难度的问题
很多框架都不作处理


467
00:23:16,263 --> 00:23:18,498 line:-2
Core Image
支持许多电池状况


468
00:23:18,832 --> 00:23:20,100 line:-1
无限图像


469
00:23:20,334 --> 00:23:22,769 line:-1
并且有200多个内置过滤器供使用


470
00:23:22,836 --> 00:23:24,471 line:-1
你可以拿来即用


471
00:23:25,272 --> 00:23:26,773 line:-1
好 我不需要说服你


472
00:23:26,840 --> 00:23:28,275 line:-1
那是很多信息


473
00:23:28,342 --> 00:23:30,143 line:-2
并且如果你尝试
在原型和工作流程中


474
00:23:30,444 --> 00:23:32,079 line:-1
使用Core Image


475
00:23:33,614 --> 00:23:35,148 line:-1
学习曲线可能相当陡峭


476
00:23:35,215 --> 00:23:37,684 line:-2
所以我们所做的就是
在新功能列表中选出最好的一些


477
00:23:38,051 --> 00:23:39,453 line:-1
进行了一些简化


478
00:23:39,653 --> 00:23:41,221 line:-1
请记住 这些简化


479
00:23:41,288 --> 00:23:42,956 line:-1
都可以随时被覆盖


480
00:23:43,123 --> 00:23:44,925 line:-1
因为我们会给你加权代码


481
00:23:44,992 --> 00:23:46,693 line:-1
你其实可以对这些更改进行硬编码


482
00:23:46,760 --> 00:23:48,495 line:-1
如果这适合你的原型堆栈


483
00:23:49,696 --> 00:23:51,465 line:-1
我们做的第一件事就是我们还有


484
00:23:51,532 --> 00:23:54,401 line:-1
Core Image的高性能功能


485
00:23:54,468 --> 00:23:56,003 line:-1
我们仍生成到Metal后端


486
00:23:56,470 --> 00:23:58,639 line:-1
仍然支持几乎所有输入输出格式


487
00:23:59,072 --> 00:24:01,108 line:-1
我们仍然可以提取数据的捕获时间


488
00:24:01,175 --> 00:24:04,811 line:-1
以及纵向深度和褪光信息


489
00:24:05,512 --> 00:24:08,982 line:-2
最后一个重点
你可以用200多个内置过滤器


490
00:24:09,850 --> 00:24:11,952 line:-1
我们做的第一个更改是 默认情况下


491
00:24:12,019 --> 00:24:14,988 line:-2
所有生成都用
完整的32位浮点数完成


492
00:24:16,890 --> 00:24:20,260 line:-2
第二个更改
一切都用sRGB颜色空间完成


493
00:24:21,662 --> 00:24:25,032 line:-2
第三 所有的边界条件都将
通过钳制和裁剪来处理


494
00:24:25,098 --> 00:24:28,869 line:-1
这意味着 如果你正在应用卷积运算


495
00:24:29,536 --> 00:24:31,672 line:-1
例如你的图片无限重复


496
00:24:32,172 --> 00:24:33,340 line:-1
将应用过滤器


497
00:24:33,540 --> 00:24:36,376 line:-1
并将生成的图像裁剪回输入尺寸


498
00:24:36,977 --> 00:24:40,480 line:-1
这也是一个可以一次覆盖的设置


499
00:24:42,282 --> 00:24:44,685 line:-1
最后 无限的图像变得有限


500
00:24:44,852 --> 00:24:47,487 line:-1
这样我们可以获取其像素缓冲区表示


501
00:24:49,590 --> 00:24:53,026 line:-2
这就是为何PyCoreImage
在幕后细节里


502
00:24:54,061 --> 00:24:54,895 line:-1
所以…


503
00:24:55,495 --> 00:24:58,932 line:-2
我们将作精彩演示
在实践中查看所有这些


504
00:24:58,999 --> 00:25:02,703 line:-2
在此之前 我想快速过一下
PyCoreImage的备忘单


505
00:25:02,769 --> 00:25:04,204 line:-1
我们来看看API


506
00:25:04,872 --> 00:25:07,875 line:-2
正如你之前看到的
我们从pycoreimage包


507
00:25:07,941 --> 00:25:09,309 line:-1
导入了CIMG类


508
00:25:10,143 --> 00:25:13,180 line:-2
我们可以调用fromFile
来用它加载文件中的图像


509
00:25:14,114 --> 00:25:16,517 line:-2
你如果想知道的话
这是等同于Swift的


510
00:25:16,583 --> 00:25:18,585 line:-2
你可以用
CIImage(contentsOfFile:)


511
00:25:20,821 --> 00:25:23,857 line:-2
你可以使用fromFile
直接加载纵向褪光信息


512
00:25:23,924 --> 00:25:25,259 line:-1
以及肖像深度


513
00:25:25,325 --> 00:25:28,762 line:-2
只需使用可选参数
useDepth和useMatte


514
00:25:31,298 --> 00:25:35,435 line:-2
你可以通过把NumPy缓冲区
包裹CIImage于构造函数中


515
00:25:35,502 --> 00:25:37,037 line:-1
来解释NumPy


516
00:25:37,404 --> 00:25:40,007 line:-2
或直接在CIImage实例下
调用生成


517
00:25:40,073 --> 00:25:41,241 line:-1
此为另一个选择


518
00:25:43,443 --> 00:25:44,344 line:0
如果你用Swift


519
00:25:44,411 --> 00:25:45,879 line:0
还有一些代码要写


520
00:25:45,946 --> 00:25:48,115 line:0
你需要先创建一个
CIRenderDestination


521
00:25:48,549 --> 00:25:50,851 line:0
确保你预先分配了缓冲区


522
00:25:51,718 --> 00:25:53,820 line:0
和提供正确的缓冲区属性


523
00:25:53,887 --> 00:25:58,292 line:0
创建CIContext
的实例并提示测试生成


524
00:25:59,626 --> 00:26:01,728 line:-1
这些都是在幕后处理的


525
00:26:02,829 --> 00:26:05,165 line:-2
Core Image
也支持过程图像


526
00:26:05,232 --> 00:26:07,201 line:-1
例如从颜色创建图像


527
00:26:07,768 --> 00:26:09,469 line:-1
或从生成器创建图像


528
00:26:11,805 --> 00:26:13,774 line:-1
现在我们看一下如何应用过滤器


529
00:26:14,942 --> 00:26:16,677 line:-1
应用过滤器再简单不过了


530
00:26:16,743 --> 00:26:18,078 line:-1
拿一个CIImage实例


531
00:26:18,345 --> 00:26:22,282 line:-2
直接在上调用过滤器名
称并传递输入原色列表


532
00:26:22,916 --> 00:26:27,721 line:-2
每个CIImage实例都增加了
200多个lambda表达式


533
00:26:28,121 --> 00:26:30,991 line:-2
直接映射到
Core Image过滤器


534
00:26:31,925 --> 00:26:32,826 line:-1
如果你用Swift


535
00:26:32,893 --> 00:26:34,962 line:-1
这是你之前看到的语法


536
00:26:35,028 --> 00:26:39,499 line:-2
应用过滤器
传入过滤器名称以及输入参数列表


537
00:26:39,566 --> 00:26:41,568 line:-1
以键值对的字典方式


538
00:26:43,604 --> 00:26:47,441 line:-2
要应用内核 可以在CIMG实例中
使用applyKernel


539
00:26:47,908 --> 00:26:50,677 line:-1
传入包含内核代码的源字符串


540
00:26:51,345 --> 00:26:53,847 line:-1
以及输入参数列表到该内核


541
00:26:53,914 --> 00:26:55,949 line:-1
我们等会儿再看一看


542
00:26:57,417 --> 00:26:59,820 line:-1
然后你只需指定应用该内核的范围


543
00:26:59,887 --> 00:27:03,957 line:-1
以及你在缓冲区中采样的感兴趣区域


544
00:27:04,024 --> 00:27:05,292 line:-1
采样源


545
00:27:07,160 --> 00:27:11,031 line:-2
PyCoreImage
提供了一些有用的API


546
00:27:11,098 --> 00:27:12,666 line:-1
如复合操作


547
00:27:12,733 --> 00:27:13,867 line:-1
这是一个来源…


548
00:27:14,368 --> 00:27:17,271 line:-1
以及翻译等几何操作


549
00:27:17,604 --> 00:27:19,673 line:-1
缩放 旋转…


550
00:27:20,240 --> 00:27:21,074 line:-1
和裁剪


551
00:27:23,410 --> 00:27:28,415 line:-1
我想在GPU内核上再花一点时间


552
00:27:28,482 --> 00:27:31,652 line:-2
因为这是一个非常强大的功能
尤其对于原型


553
00:27:31,718 --> 00:27:33,554 line:-1
我们这里有一个字符串


554
00:27:33,620 --> 00:27:36,156 line:-1
包含GPU片段着色器的代码


555
00:27:36,690 --> 00:27:39,326 line:0
我们所拥有的基本上是一种方式


556
00:27:39,393 --> 00:27:41,995 line:0
让你实时原型化那种效果


557
00:27:43,664 --> 00:27:45,599 line:0
这是5抽头拉普拉斯算子的一个例子


558
00:27:45,832 --> 00:27:48,135 line:0
我们将使用它进行锐化


559
00:27:48,502 --> 00:27:51,305 line:0
我们在每个像素的邻域中
制作五个样本


560
00:27:51,772 --> 00:27:53,941 line:0
以计算局部导数的方式组合它们


561
00:27:54,007 --> 00:27:55,409 line:0
这将成为我们的细节


562
00:27:55,475 --> 00:27:58,045 line:0
我们添加回中心像素的顶部


563
00:27:58,779 --> 00:28:01,782 line:0
我不想太过关注过滤器本身
而是集中在如何调用它


564
00:28:02,149 --> 00:28:05,719 line:0
所以 我们称之为
CIMG实例上的黑色内核


565
00:28:06,520 --> 00:28:08,021 line:0
低音源代码


566
00:28:08,088 --> 00:28:11,091 line:0
只是在那里的
用三引号python字符串


567
00:28:12,459 --> 00:28:15,262 line:0
传递我们将要应用内核的范围


568
00:28:17,164 --> 00:28:18,565 line:0
并定义感兴趣的区域


569
00:28:18,632 --> 00:28:21,335 line:0
和我们将要采样的表达式


570
00:28:21,802 --> 00:28:24,972 line:-1
如果你不熟悉目标域的概念


571
00:28:25,038 --> 00:28:26,607 line:-1
以及感兴趣的地区


572
00:28:26,840 --> 00:28:29,476 line:-2
我建议你查看
Core Image在线文档


573
00:28:29,543 --> 00:28:31,612 line:-1
以及之前的WWDC演讲


574
00:28:32,112 --> 00:28:34,181 line:-1
但这是卷积内核


575
00:28:34,348 --> 00:28:36,250 line:-1
我们正在距离边界一个像素读取


576
00:28:36,316 --> 00:28:39,253 line:-2
我们需要指示Core Image
我们是否要这样做


577
00:28:39,319 --> 00:28:41,655 line:-1
以便它可以正确处理边界条件


578
00:28:43,023 --> 00:28:43,857 line:-1
好


579
00:28:43,924 --> 00:28:45,125 line:-1
这里有很多信息


580
00:28:45,192 --> 00:28:48,495 line:-1
并且看API总是有点枯燥


581
00:28:48,562 --> 00:28:51,765 line:-2
所以我们来看一个演示
把所有这些付诸实践


582
00:29:01,808 --> 00:29:02,876 line:-1
好 在演示期间


583
00:29:02,943 --> 00:29:04,811 line:-2
我将用
Jupiter Notebook


584
00:29:05,112 --> 00:29:08,682 line:-2
这是一个基于浏览器的
实时Python解释器


585
00:29:09,449 --> 00:29:11,585 line:-1
你将看到的所有结果


586
00:29:11,652 --> 00:29:14,755 line:-2
都是用后端的
Core Image实时生成的


587
00:29:14,821 --> 00:29:16,356 line:-1
而不是预先计算过


588
00:29:16,423 --> 00:29:17,658 line:-1
这一切都是现场完成的


589
00:29:18,292 --> 00:29:19,927 line:-1
我想在这里做的第一件事


590
00:29:19,993 --> 00:29:23,530 line:-1
导入我们将要用的实用程序类


591
00:29:23,730 --> 00:29:25,632 line:-1
这里最重要的是CIMG类


592
00:29:25,699 --> 00:29:27,034 line:-1
用于我的PyCoreImage包


593
00:29:27,968 --> 00:29:29,336 line:-1
然后我们只需一些设置代码


594
00:29:29,403 --> 00:29:32,306 line:-1
以便我们可视化该笔记本中的图像


595
00:29:32,906 --> 00:29:33,774 line:-1
我们开始


596
00:29:35,342 --> 00:29:37,911 line:-1
第一是如何加载图像


597
00:29:38,512 --> 00:29:39,813 line:-1
在此用fromFile


598
00:29:40,214 --> 00:29:45,619 line:-2
我们看到我的对象类型是
PyCoreImage CIMG


599
00:29:46,053 --> 00:29:47,387 line:-1
我们可以看到它后面的支持


600
00:29:47,454 --> 00:29:50,691 line:-2
是一个正确的
Core Image对象


601
00:29:51,558 --> 00:29:54,661 line:-2
我们可以对图像进行生成并
用Matplotlib


602
00:29:56,697 --> 00:29:59,833 line:-1
查看实际的像素表示


603
00:30:00,133 --> 00:30:01,401 line:-1
这是我们的输入图片


604
00:30:02,436 --> 00:30:05,405 line:-1
现在我想在其上应用过滤器


605
00:30:05,472 --> 00:30:07,741 line:-2
我们来看看这200多个
Core Image支持的


606
00:30:07,808 --> 00:30:09,710 line:-1
过滤器


607
00:30:13,046 --> 00:30:15,949 line:-1
比如说我想在这里应用高斯模糊


608
00:30:16,016 --> 00:30:17,451 line:-1
我想知道哪些参数


609
00:30:17,518 --> 00:30:18,685 line:-1
被该过滤器支持


610
00:30:18,752 --> 00:30:20,988 line:-1
所以我在我的CIMG类上调用输入


611
00:30:21,555 --> 00:30:23,991 line:-1
我看到它支持输入图像


612
00:30:24,324 --> 00:30:26,660 line:-1
不奇怪的是 还有标准差


613
00:30:27,327 --> 00:30:28,795 line:-1
所以 我将在这里做


614
00:30:29,763 --> 00:30:30,864 line:-1
拍摄输入图像


615
00:30:31,365 --> 00:30:34,701 line:-2
在其上应用高斯模糊过滤器
标准差为100像素


616
00:30:35,135 --> 00:30:36,703 line:-1
然后并排显示两个图像


617
00:30:38,739 --> 00:30:41,808 line:-1
非常简单 对吧？


618
00:30:42,075 --> 00:30:43,911 line:-1
好 我们继续吧


619
00:30:45,112 --> 00:30:47,281 line:0
如我之前提到 你可以生成过程图像


620
00:30:47,347 --> 00:30:48,182 line:0
用Core Image


621
00:30:48,248 --> 00:30:50,617 line:0
我们来看看
Core Image生成器


622
00:30:51,485 --> 00:30:54,621 line:-2
第一件事是我们调用
fromGenerator


623
00:30:54,688 --> 00:30:56,256 line:0
指定生成器的名称


624
00:30:56,323 --> 00:30:57,691 line:0
在这里CIQRCode


625
00:30:58,358 --> 00:31:01,562 line:0
并在我们尝试编码的消息中传递它们


626
00:31:02,296 --> 00:31:03,397 line:0
这是实时的


627
00:31:03,463 --> 00:31:06,333 line:0
所以我可以对该消息进行更改


628
00:31:06,400 --> 00:31:09,570 line:0
并查看它如何影响正在生成的QR码


629
00:31:11,605 --> 00:31:13,974 line:0
Core Image
还支持标记图像


630
00:31:14,041 --> 00:31:16,210 line:0
你可以用
CI文本图像生成器来做到


631
00:31:16,977 --> 00:31:18,345 line:-1
这里有个例子


632
00:31:18,912 --> 00:31:21,849 line:0
WWDC并使用SFLO字体


633
00:31:23,050 --> 00:31:24,518 line:0
好 我们继续


634
00:31:25,385 --> 00:31:29,356 line:-2
刚才提到过
我们支持与NumPy间的互操作性


635
00:31:29,423 --> 00:31:31,525 line:-1
这是我们要做的第一件事


636
00:31:32,159 --> 00:31:34,962 line:-1
我们将从图像开始并应用一些有趣的


637
00:31:35,028 --> 00:31:36,096 line:-1
且有明显影响的变化


638
00:31:36,163 --> 00:31:37,698 line:-1
这种情况下 是一个涡旋畸变


639
00:31:39,299 --> 00:31:40,534 line:0
接下来我们要做的


640
00:31:40,601 --> 00:31:41,902 line:0
我们将生成该缓冲区


641
00:31:44,271 --> 00:31:46,139 line:0
从中获取NumPy区域


642
00:31:46,206 --> 00:31:47,441 line:0
这里我们看到它的类型


643
00:31:47,808 --> 00:31:48,842 line:0
和它的形状


644
00:31:49,443 --> 00:31:50,377 line:0
它的深度


645
00:31:51,144 --> 00:31:52,613 line:0
以及一些统计数据


646
00:31:52,679 --> 00:31:54,181 line:0
这是最小值 中值


647
00:31:54,481 --> 00:31:55,949 line:0
以及它的最大值


648
00:31:58,719 --> 00:32:00,254 line:0
我们也可以走另一条路


649
00:32:00,320 --> 00:32:02,022 line:0
从NumPy到CoreImage


650
00:32:03,090 --> 00:32:05,225 line:-1
让我们从NumPy数组开始


651
00:32:05,292 --> 00:32:06,260 line:-1
这不是件小事情


652
00:32:06,326 --> 00:32:08,829 line:-1
这里 一个随机缓冲区


653
00:32:08,896 --> 00:32:11,899 line:-1
其中75%的值已经渐变为黑色


654
00:32:13,634 --> 00:32:17,337 line:0
我首先将我的NuPy数组
包装到我的CIMG构造函数中


655
00:32:17,671 --> 00:32:20,407 line:0
可以看到我们又有了
一个CIMG类实例


656
00:32:20,741 --> 00:32:22,409 line:-1
和支持它的CIImage


657
00:32:24,711 --> 00:32:26,113 line:0
现在我有了CIImage


658
00:32:26,180 --> 00:32:27,848 line:0
我可以在其上应用各种过滤器


659
00:32:28,182 --> 00:32:30,918 line:0
我首先应用这个模糊化


660
00:32:31,351 --> 00:32:33,453 line:0
我将使用电线滤波器
一条光隧道


661
00:32:34,188 --> 00:32:35,622 line:0
改变图像的对比度


662
00:32:35,956 --> 00:32:38,859 line:0
调整曝光及伽玛值


663
00:32:39,860 --> 00:32:42,062 line:0
我们一起看看这些过滤器


664
00:32:42,896 --> 00:32:46,099 line:-2
在模糊化、光隧道
曝光调整、伽玛调整后


665
00:32:46,500 --> 00:32:47,668 line:-1
这是我们的最终效果


666
00:32:48,368 --> 00:32:50,137 line:-1
非常有趣 非常易用


667
00:32:52,406 --> 00:32:53,674 line:-1
我们把它们放在一起


668
00:32:53,740 --> 00:32:55,709 line:-1
这里我开始一个新的图像


669
00:32:56,343 --> 00:32:58,946 line:-1
我在下面这个演示中向你展示的是


670
00:32:59,012 --> 00:33:00,547 line:-1
如何做弯曲处理


671
00:33:01,014 --> 00:33:02,950 line:-1
如果你熟悉Python的切片操作


672
00:33:03,016 --> 00:33:05,118 line:-1
这正是我们要做的


673
00:33:05,185 --> 00:33:08,822 line:-2
我们将在图像中定义带或切片
水平切片


674
00:33:09,223 --> 00:33:11,658 line:-1
我们只对这些切片应用过滤器


675
00:33:12,492 --> 00:33:14,494 line:-1
让我们先来看一下代码


676
00:33:15,429 --> 00:33:16,964 line:-1
这是我们的添加带功能


677
00:33:17,531 --> 00:33:19,666 line:-1
我们可以看到它的最底层


678
00:33:20,400 --> 00:33:22,102 line:0
我们用两种复合材料生成图像


679
00:33:22,169 --> 00:33:23,637 line:0
这是实际的NumPy缓冲区


680
00:33:23,704 --> 00:33:25,672 line:0
但右边是CIImage


681
00:33:26,507 --> 00:33:27,708 line:0
通过使用这样的切片


682
00:33:27,774 --> 00:33:30,577 line:0
我们强制Core Image
只在该带进行生成


683
00:33:30,644 --> 00:33:31,778 line:0
而不是整个图片


684
00:33:32,045 --> 00:33:35,382 line:0
因此效率更高


685
00:33:37,551 --> 00:33:40,721 line:-2
我们这样做并在我们的图像中
创建五个不同的带


686
00:33:40,787 --> 00:33:42,222 line:-1
并显示最终的合成


687
00:33:45,092 --> 00:33:47,794 line:-2
非常棒
在顶上还有其它标签


688
00:33:48,996 --> 00:33:51,298 line:-1
对应于应用的过滤器


689
00:33:51,865 --> 00:33:54,101 line:-2
使用PyCoreImage
真的很简单


690
00:33:54,434 --> 00:33:56,370 line:0
好的
我之前提到过性能


691
00:33:56,436 --> 00:33:58,505 line:0
所以让我们快速看看这个


692
00:33:59,306 --> 00:34:00,240 line:0
我想给你看的第一个是


693
00:34:00,307 --> 00:34:03,377 line:0
每当你在CIImage实例上
调用生成时


694
00:34:03,710 --> 00:34:06,547 line:0
NumPy被预处理并缓存


695
00:34:07,047 --> 00:34:08,649 line:0
例如 我们在这里创建一个图像


696
00:34:08,715 --> 00:34:11,251 line:0
我们按比例缩小
并应用GaussianBlur


697
00:34:11,585 --> 00:34:13,520 line:0
第一次调用历时56毫秒


698
00:34:13,587 --> 00:34:15,088 line:0
第二次只需两毫秒


699
00:34:15,989 --> 00:34:18,725 line:0
让我们来看看大卷积


700
00:34:18,792 --> 00:34:20,494 line:0
Core Image非常快


701
00:34:20,960 --> 00:34:23,096 line:0
并且能够处理大型卷积


702
00:34:23,163 --> 00:34:24,264 line:0
轻松搞定


703
00:34:24,531 --> 00:34:26,466 line:-1
这里我们用CIBlur


704
00:34:26,766 --> 00:34:32,005 line:-2
一个CIGaussianBlur
西格玛值为200


705
00:34:32,072 --> 00:34:32,906 line:-1
这很大


706
00:34:33,206 --> 00:34:34,741 line:-1
这里给大家一个概念


707
00:34:34,808 --> 00:34:36,643 line:-1
我向你展示这个图像时


708
00:34:36,909 --> 00:34:40,179 line:0
我实际用scikit-image
执行equivalent


709
00:34:40,480 --> 00:34:42,549 line:0
我们的运行时间是16秒


710
00:34:42,949 --> 00:34:45,052 line:0
但这次使用
CoreImage做同样的事


711
00:34:45,351 --> 00:34:46,954 line:0
一百三十毫秒


712
00:34:47,221 --> 00:34:48,388 line:0
是的 就是这么快


713
00:34:48,455 --> 00:34:49,755 line:-1
200倍 耶


714
00:34:50,324 --> 00:34:51,158 line:-1
谢谢


715
00:34:52,525 --> 00:34:53,560 line:-1
好吧 我们继续


716
00:34:53,627 --> 00:34:56,663 line:-2
PyCoreImage
最强大的功能之一


717
00:34:56,730 --> 00:35:00,200 line:-1
是内联创建自定义GP内核的能力


718
00:35:00,267 --> 00:35:01,535 line:-1
并在动态中执行


719
00:35:01,602 --> 00:35:02,936 line:-1
并动态修改


720
00:35:03,303 --> 00:35:04,571 line:-1
我们来看看


721
00:35:08,842 --> 00:35:09,676 line:-1
好


722
00:35:10,544 --> 00:35:12,980 line:-2
我首先想要展示的是
如何使用颜色内核


723
00:35:13,313 --> 00:35:16,216 line:-1
因此颜色内核是仅输入一个像素


724
00:35:16,283 --> 00:35:17,518 line:-1
并输出一个像素的内核


725
00:35:17,818 --> 00:35:20,854 line:-1
并且不围绕该像素制作任何其它样本


726
00:35:21,455 --> 00:35:23,657 line:0
这是我们的输入图像
这是我们的内核


727
00:35:23,724 --> 00:35:27,561 line:0
所以我们实际得到的是一种颜色
我们将颜色显示


728
00:35:28,228 --> 00:35:30,998 line:-1
我们来看看这个效果


729
00:35:31,064 --> 00:35:33,267 line:-1
我要把我的红色和蓝色通道


730
00:35:33,333 --> 00:35:34,835 line:-1
与我的蓝色和红色频道互换


731
00:35:34,902 --> 00:35:36,270 line:-1
我要反转它们


732
00:35:36,703 --> 00:35:38,172 line:-1
不是太令人兴奋的效果


733
00:35:38,238 --> 00:35:40,574 line:-1
但我要告诉你的是我可以


734
00:35:42,676 --> 00:35:45,679 line:-2
开始打字 然后说
也许我想扩展红色频道


735
00:35:45,746 --> 00:35:46,780 line:0
用蓝色频道


736
00:35:47,347 --> 00:35:51,618 line:-1
我想尝试这里的缩放量


737
00:35:51,685 --> 00:35:53,320 line:-1
我们可以从.25开始


738
00:35:53,921 --> 00:35:56,089 line:-1
随意提到相当高的值


739
00:35:56,423 --> 00:35:58,225 line:-1
并生成有趣的效果


740
00:35:59,026 --> 00:36:01,395 line:-2
它非常强大
而这一切都是实时完成的


741
00:36:01,461 --> 00:36:03,530 line:-2
所以你可通过这种方式
对过滤器进行微调


742
00:36:03,597 --> 00:36:06,300 line:-1
并确保达到你正在寻找的效果


743
00:36:08,635 --> 00:36:11,405 line:0
我们来看一个更复杂的内核


744
00:36:11,471 --> 00:36:12,873 line:0
我们来看一下通用内核


745
00:36:12,940 --> 00:36:15,609 line:0
这有点像我之前展示的
拉普拉斯锐化


746
00:36:15,676 --> 00:36:18,979 line:-2
这是一个在每个像素附近
进行额外点击的内核


747
00:36:19,446 --> 00:36:21,148 line:-1
所以从文件中的图像开始


748
00:36:21,215 --> 00:36:22,916 line:-1
这是我们之前看到的同一图像


749
00:36:23,116 --> 00:36:25,219 line:-1
这里有我们的内核代码


750
00:36:25,285 --> 00:36:26,386 line:-1
我们略去细节


751
00:36:26,453 --> 00:36:27,654 line:-1
这是一个双边过滤器


752
00:36:27,721 --> 00:36:29,656 line:-1
是模糊滤镜的边缘


753
00:36:30,891 --> 00:36:32,793 line:-1
我们把代码放进去


754
00:36:33,193 --> 00:36:35,262 line:-2
并带有一些参数调用
applyKernel


755
00:36:36,897 --> 00:36:42,302 line:-1
可以获得非常好的效果


756
00:36:42,369 --> 00:36:43,904 line:-1
我们在这里做的 基本上


757
00:36:44,137 --> 00:36:48,342 line:-1
是剪切图像中的无冗余高频


758
00:36:48,408 --> 00:36:49,409 line:-1
如果我们看看…


759
00:36:50,043 --> 00:36:51,945 line:0
我们更仔细地看一下


760
00:36:53,213 --> 00:36:54,047 line:-1
看看这里的剪切


761
00:36:54,114 --> 00:36:56,650 line:-1
我们可以看到强边缘还存在


762
00:36:56,717 --> 00:36:58,919 line:-1
但是非冗余的精细频率


763
00:36:58,986 --> 00:37:00,020 line:-1
被冲走了


764
00:37:00,721 --> 00:37:04,258 line:-1
双边滤波器可用于许多不同目的


765
00:37:04,324 --> 00:37:06,527 line:-2
在这种情况下
我们将用它来进行锐化


766
00:37:06,927 --> 00:37:08,896 line:-1
并使用此过滤器实现锐化


767
00:37:09,196 --> 00:37:10,898 line:-1
我们可以简单地拿左边的图像


768
00:37:11,164 --> 00:37:12,633 line:-1
并减去右边的图像


769
00:37:12,699 --> 00:37:15,669 line:-2
为我们提供了图像中
高频或细节的地图


770
00:37:15,736 --> 00:37:16,870 line:-1
我们这样做


771
00:37:17,905 --> 00:37:20,073 line:0
我在这里做的是生成我的图像


772
00:37:20,307 --> 00:37:21,375 line:0
它是一个NumPy缓冲区


773
00:37:21,675 --> 00:37:26,146 line:0
生成我过滤后的图片


774
00:37:26,713 --> 00:37:29,716 line:0
并且用运算符重载将它们一起减去


775
00:37:29,783 --> 00:37:31,151 line:0
这是随NumPy提供的操作


776
00:37:31,718 --> 00:37:33,353 line:0
让我们来看一下细节层


777
00:37:34,922 --> 00:37:37,691 line:-1
如果你的左侧有整个图像的细节


778
00:37:37,758 --> 00:37:39,626 line:-1
和图像中心的裁剪


779
00:37:40,727 --> 00:37:43,730 line:-1
现在 我们可以做的就是将它添加到


780
00:37:43,797 --> 00:37:44,932 line:-1
原始图像的顶部


781
00:37:45,866 --> 00:37:47,334 line:0
这正是我们要做的


782
00:37:47,401 --> 00:37:49,169 line:0
我们将两次加它


783
00:37:50,170 --> 00:37:52,206 line:-1
通过这样做 我们实现了形成锐化


784
00:37:52,940 --> 00:37:54,041 line:-1
就是这么简单


785
00:37:54,408 --> 00:37:57,444 line:-2
如果我想
我可以回到我的过滤器内核字符串


786
00:37:58,078 --> 00:38:00,981 line:-1
并开始任意实时进行更改


787
00:38:03,250 --> 00:38:07,221 line:-1
我还想演示如何从图像中加载元数据


788
00:38:07,788 --> 00:38:09,456 line:-1
这里我有一张图片


789
00:38:09,523 --> 00:38:11,124 line:0
加载了人像效果褪光


790
00:38:11,191 --> 00:38:12,893 line:0
以及纵向深度数据


791
00:38:14,094 --> 00:38:15,829 line:-1
以下是并排的l图片


792
00:38:16,763 --> 00:38:18,665 line:-1
左侧的图像是RGB图像


793
00:38:18,732 --> 00:38:20,100 line:-1
中心是深度数据


794
00:38:20,167 --> 00:38:22,503 line:-1
右侧是高质量的人像效果图


795
00:38:22,569 --> 00:38:24,838 line:-1
我们今天在另一个演讲上介绍了


796
00:38:26,006 --> 00:38:27,474 line:0
我们还可以查看EXIF标记


797
00:38:27,541 --> 00:38:30,344 line:0
直接通过查看下层的CIImage


798
00:38:31,545 --> 00:38:34,081 line:0
来自相同的G实例和调用属性


799
00:38:35,215 --> 00:38:38,018 line:0
这里 我们获得有关捕获本身的信息


800
00:38:39,953 --> 00:38:42,389 line:-1
像我说的 我们介绍了人像效果褪光


801
00:38:42,456 --> 00:38:44,224 line:-1
在另一个演讲 演讲503


802
00:38:44,291 --> 00:38:45,993 line:-1
我强烈建议你去看看那个演讲


803
00:38:46,293 --> 00:38:48,028 line:-1
所以这里我们略去细节


804
00:38:48,662 --> 00:38:50,230 line:-1
我将要实现这个过滤器


805
00:38:50,297 --> 00:38:52,833 line:-1
如果你有兴趣了解如何做到的


806
00:38:53,333 --> 00:38:55,869 line:-1
我强烈建议你查看本次演讲


807
00:38:57,137 --> 00:38:58,138 line:-1
非常有意思的东西


808
00:39:00,641 --> 00:39:01,475 line:-1
谢谢


809
00:39:05,879 --> 00:39:06,713 line:-1
好


810
00:39:07,080 --> 00:39:08,615 line:-1
让我们回到本次演讲


811
00:39:08,682 --> 00:39:10,851 line:-1
我想在这里稍微换档


812
00:39:11,351 --> 00:39:16,490 line:-2
谈谈将CoreImage
和CoreML结合在一起


813
00:39:23,363 --> 00:39:27,968 line:0
如果你想获得
有关使用人像褪光的更多信息


814
00:39:28,302 --> 00:39:30,737 line:-1
和人像深度信息


815
00:39:30,804 --> 00:39:33,774 line:-2
我鼓励你仔细查看有关
创建照片和视频效果的演讲


816
00:39:35,008 --> 00:39:37,744 line:-2
我们看看将Core Image
和CoreML结合在一起


817
00:39:38,846 --> 00:39:41,248 line:-1
今年 我们非常高兴地宣布


818
00:39:41,315 --> 00:39:43,016 line:-1
我们推出了一个新的过滤器


819
00:39:43,584 --> 00:39:45,252 line:-1
CICoreMLModelFilter


820
00:39:45,719 --> 00:39:47,988 line:-2
这是一个非常简单
但非常强大的过滤器


821
00:39:48,055 --> 00:39:49,089 line:-1
需要两个输入


822
00:39:49,957 --> 00:39:53,360 line:-1
第一个输入是带有滤镜的图像本身


823
00:39:54,361 --> 00:39:55,729 line:-1
并输入CoreML模型


824
00:39:58,465 --> 00:40:00,501 line:0
并且你获得了一个输出


825
00:40:00,567 --> 00:40:01,735 line:0
已被潜在神经网络处理的输出


826
00:40:01,802 --> 00:40:04,037 line:-1
这真的很简单 很强大


827
00:40:04,438 --> 00:40:07,708 line:-2
为了展示代码有多简单
让我们来看看Swift


828
00:40:09,142 --> 00:40:10,978 line:0
我们在左侧有一个输入图像


829
00:40:11,044 --> 00:40:12,913 line:0
你要做的就是调用过滤器


830
00:40:13,413 --> 00:40:15,782 line:0
传入我们今年推出的新过滤器


831
00:40:16,216 --> 00:40:18,385 line:0
并提供预编译的ML模型


832
00:40:18,452 --> 00:40:19,586 line:0
就是这么简单


833
00:40:20,053 --> 00:40:21,855 line:0
如果你想看看其它方式


834
00:40:21,922 --> 00:40:24,658 line:0
在图像处理app中利用机器学习


835
00:40:24,725 --> 00:40:27,594 line:0
我鼓励你看看其它演讲


836
00:40:27,661 --> 00:40:30,531 line:0
关于Turi Create指南
和Visionwith CoreML


837
00:40:33,000 --> 00:40:34,401 line:-1
一个相关的话题


838
00:40:34,735 --> 00:40:37,804 line:-1
我们在训练数据集中的常见操作之一


839
00:40:37,871 --> 00:40:39,840 line:-1
是机器学习中的数据增强


840
00:40:40,541 --> 00:40:42,109 line:-1
而数据增强


841
00:40:42,643 --> 00:40:46,213 line:-1
可以显着提高神经网络的稳健性


842
00:40:46,280 --> 00:40:49,716 line:-2
在这种情况下
假设我们正在进行对象分类


843
00:40:50,250 --> 00:40:51,818 line:-1
我们正在努力确定


844
00:40:51,885 --> 00:40:54,421 line:-1
该图像是桥还是有水


845
00:40:56,890 --> 00:41:01,161 line:-1
对原始趋势数据集进行扩充


846
00:41:01,395 --> 00:41:04,064 line:-1
将增加该数据集中的图像数量


847
00:41:04,131 --> 00:41:06,767 line:-1
而无需收集新图片


848
00:41:07,301 --> 00:41:08,836 line:-1
你基本上可以免费得到


849
00:41:09,403 --> 00:41:11,305 line:-1
所以 你可以携带很多操作


850
00:41:11,371 --> 00:41:13,073 line:-1
其中一个只是改变它的外观


851
00:41:13,140 --> 00:41:14,808 line:-1
例如 色调 温度


852
00:41:14,875 --> 00:41:16,343 line:-1
和图像的白点


853
00:41:17,110 --> 00:41:19,980 line:-1
通过添加噪声改变图像的光谱属性


854
00:41:21,348 --> 00:41:24,151 line:-2
或通过应用变换
改变图像的几何图形


855
00:41:24,985 --> 00:41:28,188 line:-2
事实证明 用Core Image
实现所有这些都是易如反掌


856
00:41:28,856 --> 00:41:30,290 line:-1
让我们来看几个过滤器


857
00:41:30,357 --> 00:41:33,193 line:-1
以及如何将它们用于数据增强


858
00:41:34,695 --> 00:41:36,597 line:-1
我们在左侧有输入图像


859
00:41:37,798 --> 00:41:39,333 line:-1
我们可以改变温度和色调


860
00:41:39,399 --> 00:41:40,901 line:-1
用CITemperatureAndTint


861
00:41:41,702 --> 00:41:43,770 line:-1
我们可以调整亮度 对比度


862
00:41:43,837 --> 00:41:47,875 line:-2
及用CIColorControls
调整的图像饱和度


863
00:41:48,942 --> 00:41:51,578 line:-1
用CIDither更改图像的频谱


864
00:41:51,645 --> 00:41:53,046 line:-1
还有CIGaussianBlur


865
00:41:54,648 --> 00:41:57,718 line:-1
还有用仿射变换更改图像的几何图形


866
00:41:59,186 --> 00:42:00,754 line:-1
我们来看看实践中的所有这些


867
00:42:08,996 --> 00:42:11,231 line:-2
好 我们回到
Jupiter Notebook


868
00:42:11,298 --> 00:42:13,100 line:-1
与之前相同的设置


869
00:42:13,467 --> 00:42:15,502 line:-2
我想向你展示的是
如何用Core Image


870
00:42:15,569 --> 00:42:16,436 line:-1
作批量增强


871
00:42:17,037 --> 00:42:18,572 line:-1
我们正在加载图片


872
00:42:19,239 --> 00:42:21,775 line:-1
我们将在这里定义我们的增强功能


873
00:42:21,842 --> 00:42:23,510 line:-1
我们要做的主要是


874
00:42:23,577 --> 00:42:24,645 line:0
来自随机空间的


875
00:42:24,912 --> 00:42:26,713 line:0
为我在这里定义的每个过滤器的抽样


876
00:42:27,181 --> 00:42:30,851 line:0
我们将用GaussianBlur
缩放旋转


877
00:42:31,251 --> 00:42:33,287 line:0
一些调整 曝光调整


878
00:42:33,554 --> 00:42:35,856 line:0
纤维以及噪音抖动


879
00:42:37,758 --> 00:42:39,660 line:0
好了？让我们缓存该功能


880
00:42:40,460 --> 00:42:41,328 line:-1
再来看看


881
00:42:41,395 --> 00:42:44,531 line:-1
对该增强的一些实现


882
00:42:46,567 --> 00:42:47,968 line:-1
所以我的滑块在这里控制


883
00:42:48,035 --> 00:42:50,337 line:-1
我在后端使用的数字生成器种子


884
00:42:52,673 --> 00:42:53,807 line:-1
好 非常酷


885
00:42:53,874 --> 00:42:55,309 line:0
我不确定效率如何


886
00:42:55,375 --> 00:42:58,612 line:0
所以这里我将实时处理
200个这样的增强


887
00:42:58,979 --> 00:43:01,148 line:-1
我们将在这里看看它们如何


888
00:43:01,481 --> 00:43:03,183 line:0
实时保存到硬盘


889
00:43:03,250 --> 00:43:04,218 line:0
我们来试试吧


890
00:43:04,685 --> 00:43:06,453 line:-1
让你了解它有多快


891
00:43:10,390 --> 00:43:11,558 line:-1
这真的很厉害


892
00:43:15,128 --> 00:43:15,963 line:-1
好


893
00:43:16,864 --> 00:43:21,068 line:-2
下面我想展示的是如何通过
Core Image来使用CoreML


894
00:43:21,935 --> 00:43:25,072 line:-1
首先是加载Core ML模型


895
00:43:25,272 --> 00:43:26,139 line:-1
我们在这里做的


896
00:43:27,341 --> 00:43:29,710 line:0
我们有一个玻璃模型
我们将要用它


897
00:43:30,277 --> 00:43:32,045 line:0
产生一个有趣的效果


898
00:43:32,112 --> 00:43:34,014 line:-1
让我们从过程图像开始


899
00:43:34,348 --> 00:43:35,549 line:-1
我们之前见过这个


900
00:43:36,850 --> 00:43:38,252 line:-1
然后让它变得更有趣


901
00:43:38,318 --> 00:43:39,586 line:-1
我们为它添加一些纹理


902
00:43:40,787 --> 00:43:42,956 line:0
我们在上面添加多频段噪音


903
00:43:45,425 --> 00:43:46,727 line:0
以及一些羽化


904
00:43:47,327 --> 00:43:48,762 line:0
和一些小插图


905
00:43:50,631 --> 00:43:51,732 line:0
好 这是输入图像


906
00:43:51,798 --> 00:43:53,367 line:0
我们把它喂给我们的神经网络


907
00:43:53,433 --> 00:43:57,804 line:-2
和另一个我们预先训练过的
CoreML模型


908
00:43:59,106 --> 00:44:00,774 line:-1
好吗？让我们来运行吧


909
00:44:05,279 --> 00:44:06,113 line:-1
和…


910
00:44:09,683 --> 00:44:12,519 line:0
就这样
2018年WWDC是为你而举办的


911
00:44:13,720 --> 00:44:15,722 line:-1
好 说到这儿


912
00:44:16,323 --> 00:44:19,059 line:-1
我要感谢大家今天参加这个会议


913
00:44:19,693 --> 00:44:22,062 line:-1
我希望你们喜欢这个演讲


914
00:44:22,129 --> 00:44:23,697 line:-1
就像我们享受为你准备演讲的过程


915
00:44:24,431 --> 00:44:26,767 line:0
我强烈建议你明天来和我们谈谈


916
00:44:26,834 --> 00:44:28,969 line:0
下午三点
在Core Image技术实验室


917
00:44:30,103 --> 00:44:31,672 line:0
非常感谢

